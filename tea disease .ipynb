{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mahotas as mt\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import count\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "### A set of 202 diseased(1- algal leaf spot, 2- blister blight, 3- grey spot) and healthy(0) tea leaves are collected as dataset from High Field Tea Estate, Coonoor, Tamil Nadu, India.\n",
    "\n",
    "## The Next Step is Image Segmentation.\n",
    "\n",
    "#### A python script file is used for background removal and extraction of area of interest.\n",
    "\n",
    "## The Next Step is the Feature Extraction. \n",
    "\n",
    "#### 13 Texture Features( Haralick features are used).\n",
    "#### Color Features\n",
    "#### Shape Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(image):\n",
    "\t\n",
    "\t##Color Feature\n",
    "\t(mean,std) = cv.meanStdDev(image)\n",
    "\t\n",
    "\tprint(len(mean), type(mean))\n",
    "\t\n",
    "\tprint(len(std), type(std))\n",
    "\t\n",
    "\tcolor_feature = np.array(mean)\n",
    "\t\n",
    "\tcolor_feature = np.concatenate([color_feature,std]).flatten()\n",
    "\t\n",
    "\tprint(len(color_feature))\n",
    "\t\n",
    "\t##Texture Feature\n",
    "\tgray = cv.cvtColor(image,cv.COLOR_BGR2GRAY)\n",
    "\t\n",
    "\ttextures = mt.features.haralick(gray)\n",
    "\t\n",
    "\tht_mean = textures.mean(axis = 0)\n",
    "\t\n",
    "\tprint(len(ht_mean), type(ht_mean))\n",
    "\t\n",
    "\t\n",
    "\t## Shape Features\n",
    "\tret,thresh = cv.threshold(gray,127,255,0)\n",
    "\t\n",
    "\tx,contours, hierarchy =   cv.findContours(thresh.copy(),1,2)\n",
    "\t\n",
    "\tcnt = contours[0]\n",
    "\t\n",
    "\tarea = cv.contourArea(cnt)\n",
    "\tprint(type(area))\n",
    "\t\n",
    "\tperimeter = cv.arcLength(cnt,True)\n",
    "\tprint(type(perimeter))\n",
    "\t\n",
    "\tshape = np.array([])\n",
    "\tshape = np.append(shape,area)\n",
    "\tshape = np.append(shape,perimeter)\n",
    "\tprint(len(shape))\n",
    "\t\n",
    "\t\n",
    "\tprint(len(ht_mean) + len(std) + len(mean) + len(shape))\n",
    "\t\n",
    "\tht_mean = np.concatenate([ht_mean,color_feature]).flatten()\n",
    "\t\n",
    "\tht_mean = np.concatenate([ht_mean,shape]).flatten()\n",
    "\t\n",
    "\tprint(len(ht_mean),ht_mean.shape)\n",
    "\t\n",
    "\treturn(ht_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Comma-Seperating file\n",
    "\n",
    "#### A CSV file, having 21 features (13 texture features, 6 color features and 2 shape featrures) and appropriate label(0- Healthy, 1- Algal Leaf Spot, 2- blister blight, 3- Grey Spot), is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv():\t\n",
    "\t\n",
    "\tfiles = count.images()\n",
    "\tmydata = [['energy','contrast','correlation','variance','inverse difference moment','sum average','sum variance','sum entropy','entropy','difference variance','difference entropy','info_corr',\n",
    "\t\t\t   'maximal_corr_coeff','mean_B','mean_G','mean_R','std_B','std_G','std_R','area','perimeter','label']]\n",
    "\t\n",
    "\tpath = '/home/ln-2/Desktop/Alok/SVM/alok1/results'\n",
    "\tfor file in files:\t\n",
    "\t\tprint(path+ file)\n",
    "\t\timage = cv.imread(path + '/' + file)\n",
    "\t\tprint(file)\n",
    "\t\t#gray = cv.cvtColor(image,cv.COLOR_BGR2GRAY)\n",
    "\t\t#means = cv.mean(image)\n",
    "\t\t#print(len(means))\n",
    "\t\tprint(image.shape)\n",
    "\t\tdim = (512,512)\n",
    "\t\tr_img = cv.resize(image,dim)\n",
    "\t\tprint(r_img.shape)\n",
    "\t\tfeature = extract_feature(r_img)\n",
    "\t\tlabel = 0\n",
    "\t\t\n",
    "\t\t## Healthy leaf is labeled as 0.\n",
    "\t\tif(re.search('test[1-9]+',file)):\n",
    "\t\t\tlabel = 0\n",
    "\t\telse:\n",
    "\t\t\t## Algal leaf spot is labeled as 1.\n",
    "\t\t\tif(re.search('algal[1-9]+',file)):\n",
    "\t\t\t\tlabel = 1\n",
    "\t\t\t## Blister Blight is labeled as 2.\t\n",
    "\t\t\telif(re.search('blister[1-9]+',file)):\n",
    "\t\t\t\tlabel = 2\n",
    "\t\t\t## Grey Spot is labled as 3.\t\n",
    "\t\t\telif(re.search('grey[1-9]+',file)):\n",
    "\t\t\t\tlabel = 3\n",
    "\t\t\n",
    "\t\tfeature = np.append(feature,label)\n",
    "\t\tprint()\n",
    "\t\tprint(len(feature))\n",
    "\t\tfeature = feature.tolist()\n",
    "\t\tmydata.append(feature)\n",
    "\t\t\n",
    "\tmyfile = open('mycsv.csv','w')\n",
    "\twith myfile:\n",
    "\t\twriter = csv.writer(myfile)\n",
    "\t\twriter.writerows(mydata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey34.jpg\n",
      "grey34.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest69.jpg\n",
      "test69.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest119.jpg\n",
      "test119.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest28.jpg\n",
      "test28.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey1.jpg\n",
      "grey1.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey11.jpg\n",
      "grey11.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsalgal4.jpg\n",
      "algal4.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey7.jpg\n",
      "grey7.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest66.jpg\n",
      "test66.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest64.jpg\n",
      "test64.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest44.jpg\n",
      "test44.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest110.jpg\n",
      "test110.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey9.jpg\n",
      "grey9.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest94.jpg\n",
      "test94.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest109.jpg\n",
      "test109.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest27.jpg\n",
      "test27.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsblister2.jpg\n",
      "blister2.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsalgal3.jpg\n",
      "algal3.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey12.jpg\n",
      "grey12.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest136.jpg\n",
      "test136.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest134.jpg\n",
      "test134.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest101.jpg\n",
      "test101.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey3.jpg\n",
      "grey3.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest85.jpg\n",
      "test85.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest10.jpg\n",
      "test10.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest25.jpg\n",
      "test25.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey22.jpg\n",
      "grey22.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest63.jpg\n",
      "test63.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest3.jpg\n",
      "test3.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest36.jpg\n",
      "test36.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest149.jpg\n",
      "test149.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest153.jpg\n",
      "test153.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest125.jpg\n",
      "test125.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest59.jpg\n",
      "test59.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest72.jpg\n",
      "test72.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest74.jpg\n",
      "test74.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest141.jpg\n",
      "test141.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest117.jpg\n",
      "test117.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest114.jpg\n",
      "test114.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey10.jpg\n",
      "grey10.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest24.jpg\n",
      "test24.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey4.jpg\n",
      "grey4.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey21.jpg\n",
      "grey21.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest51.jpg\n",
      "test51.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest144.jpg\n",
      "test144.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsblister6.jpg\n",
      "blister6.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest45.jpg\n",
      "test45.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest131.jpg\n",
      "test131.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest113.jpg\n",
      "test113.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest61.jpg\n",
      "test61.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest41.jpg\n",
      "test41.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest84.jpg\n",
      "test84.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest111.jpg\n",
      "test111.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest73.jpg\n",
      "test73.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest60.jpg\n",
      "test60.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest143.jpg\n",
      "test143.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest54.jpg\n",
      "test54.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey14.jpg\n",
      "grey14.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest146.jpg\n",
      "test146.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest17.jpg\n",
      "test17.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest142.jpg\n",
      "test142.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest96.jpg\n",
      "test96.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest11.jpg\n",
      "test11.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest22.jpg\n",
      "test22.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest58.jpg\n",
      "test58.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest115.jpg\n",
      "test115.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey16.jpg\n",
      "grey16.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest122.jpg\n",
      "test122.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest100.jpg\n",
      "test100.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest13.jpg\n",
      "test13.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest106.jpg\n",
      "test106.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest57.jpg\n",
      "test57.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest127.jpg\n",
      "test127.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey28.jpg\n",
      "grey28.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest40.jpg\n",
      "test40.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest1.jpg\n",
      "test1.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest16.jpg\n",
      "test16.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest8.jpg\n",
      "test8.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest97.jpg\n",
      "test97.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsalgal6.jpg\n",
      "algal6.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey18.jpg\n",
      "grey18.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest87.jpg\n",
      "test87.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest7.jpg\n",
      "test7.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest42.jpg\n",
      "test42.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest120.jpg\n",
      "test120.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsblister8.jpg\n",
      "blister8.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest32.jpg\n",
      "test32.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest37.jpg\n",
      "test37.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest83.jpg\n",
      "test83.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest56.jpg\n",
      "test56.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest50.jpg\n",
      "test50.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest49.jpg\n",
      "test49.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey24.jpg\n",
      "grey24.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest123.jpg\n",
      "test123.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest89.jpg\n",
      "test89.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsblister3.jpg\n",
      "blister3.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest132.jpg\n",
      "test132.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest79.jpg\n",
      "test79.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest129.jpg\n",
      "test129.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest140.jpg\n",
      "test140.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest98.jpg\n",
      "test98.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey13.jpg\n",
      "grey13.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest46.jpg\n",
      "test46.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest78.jpg\n",
      "test78.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey23.jpg\n",
      "grey23.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest14.jpg\n",
      "test14.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest9.jpg\n",
      "test9.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest65.jpg\n",
      "test65.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest104.jpg\n",
      "test104.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest34.jpg\n",
      "test34.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest52.jpg\n",
      "test52.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest86.jpg\n",
      "test86.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest151.jpg\n",
      "test151.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey15.jpg\n",
      "grey15.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest48.jpg\n",
      "test48.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest116.jpg\n",
      "test116.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest108.jpg\n",
      "test108.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest21.jpg\n",
      "test21.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsalgal5.jpg\n",
      "algal5.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest2.jpg\n",
      "test2.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest103.jpg\n",
      "test103.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsalgal2.jpg\n",
      "algal2.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey8.jpg\n",
      "grey8.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest124.jpg\n",
      "test124.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey27.jpg\n",
      "grey27.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest118.jpg\n",
      "test118.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsalgal7.jpg\n",
      "algal7.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest152.jpg\n",
      "test152.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest138.jpg\n",
      "test138.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest93.jpg\n",
      "test93.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest135.jpg\n",
      "test135.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest81.jpg\n",
      "test81.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest150.jpg\n",
      "test150.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest23.jpg\n",
      "test23.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey19.jpg\n",
      "grey19.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest75.jpg\n",
      "test75.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest39.jpg\n",
      "test39.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest4.jpg\n",
      "test4.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest31.jpg\n",
      "test31.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest62.jpg\n",
      "test62.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest20.jpg\n",
      "test20.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest139.jpg\n",
      "test139.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsblister5.jpg\n",
      "blister5.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest126.jpg\n",
      "test126.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey20.jpg\n",
      "grey20.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest77.jpg\n",
      "test77.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey6.jpg\n",
      "grey6.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey5.jpg\n",
      "grey5.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsblister4.jpg\n",
      "blister4.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey29.jpg\n",
      "grey29.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest29.jpg\n",
      "test29.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest145.jpg\n",
      "test145.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest92.jpg\n",
      "test92.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey26.jpg\n",
      "grey26.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest35.jpg\n",
      "test35.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey30.jpg\n",
      "grey30.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest112.jpg\n",
      "test112.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest68.jpg\n",
      "test68.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest5.jpg\n",
      "test5.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey17.jpg\n",
      "grey17.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey31.jpg\n",
      "grey31.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest121.jpg\n",
      "test121.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest82.jpg\n",
      "test82.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest130.jpg\n",
      "test130.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest99.jpg\n",
      "test99.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest91.jpg\n",
      "test91.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest30.jpg\n",
      "test30.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest18.jpg\n",
      "test18.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey33.jpg\n",
      "grey33.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest102.jpg\n",
      "test102.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey2.jpg\n",
      "grey2.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest105.jpg\n",
      "test105.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest95.jpg\n",
      "test95.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest147.jpg\n",
      "test147.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest80.jpg\n",
      "test80.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest38.jpg\n",
      "test38.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest128.jpg\n",
      "test128.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest43.jpg\n",
      "test43.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest88.jpg\n",
      "test88.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest148.jpg\n",
      "test148.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest67.jpg\n",
      "test67.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest107.jpg\n",
      "test107.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest19.jpg\n",
      "test19.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey32.jpg\n",
      "grey32.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey25.jpg\n",
      "grey25.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest90.jpg\n",
      "test90.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest6.jpg\n",
      "test6.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest26.jpg\n",
      "test26.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest53.jpg\n",
      "test53.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest55.jpg\n",
      "test55.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsblister1.jpg\n",
      "blister1.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest33.jpg\n",
      "test33.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest137.jpg\n",
      "test137.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest71.jpg\n",
      "test71.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest70.jpg\n",
      "test70.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsblister7.jpg\n",
      "blister7.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest15.jpg\n",
      "test15.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsalgal1.jpg\n",
      "algal1.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest47.jpg\n",
      "test47.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest12.jpg\n",
      "test12.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest76.jpg\n",
      "test76.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest133.jpg\n",
      "test133.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "create_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Panda Library and matplotlib library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile = pd.read_csv('mycsv.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy</th>\n",
       "      <th>contrast</th>\n",
       "      <th>correlation</th>\n",
       "      <th>variance</th>\n",
       "      <th>inverse difference moment</th>\n",
       "      <th>sum average</th>\n",
       "      <th>sum variance</th>\n",
       "      <th>sum entropy</th>\n",
       "      <th>entropy</th>\n",
       "      <th>difference variance</th>\n",
       "      <th>...</th>\n",
       "      <th>maximal_corr_coeff</th>\n",
       "      <th>mean_B</th>\n",
       "      <th>mean_G</th>\n",
       "      <th>mean_R</th>\n",
       "      <th>std_B</th>\n",
       "      <th>std_G</th>\n",
       "      <th>std_R</th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.151255</td>\n",
       "      <td>83.682817</td>\n",
       "      <td>0.992531</td>\n",
       "      <td>5602.660453</td>\n",
       "      <td>0.524024</td>\n",
       "      <td>166.271382</td>\n",
       "      <td>22326.958994</td>\n",
       "      <td>5.860651</td>\n",
       "      <td>8.105537</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.994969</td>\n",
       "      <td>29.549824</td>\n",
       "      <td>94.431873</td>\n",
       "      <td>80.634457</td>\n",
       "      <td>37.648830</td>\n",
       "      <td>84.138807</td>\n",
       "      <td>74.804819</td>\n",
       "      <td>2.5</td>\n",
       "      <td>12.242641</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.701767</td>\n",
       "      <td>42.595679</td>\n",
       "      <td>0.992800</td>\n",
       "      <td>2957.291822</td>\n",
       "      <td>0.891638</td>\n",
       "      <td>41.561557</td>\n",
       "      <td>11786.571609</td>\n",
       "      <td>1.974422</td>\n",
       "      <td>2.473410</td>\n",
       "      <td>0.002914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.941292</td>\n",
       "      <td>21.951992</td>\n",
       "      <td>27.125298</td>\n",
       "      <td>7.671936</td>\n",
       "      <td>57.780391</td>\n",
       "      <td>69.075932</td>\n",
       "      <td>34.431439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.531359</td>\n",
       "      <td>58.631216</td>\n",
       "      <td>0.990318</td>\n",
       "      <td>3027.364926</td>\n",
       "      <td>0.816442</td>\n",
       "      <td>56.930850</td>\n",
       "      <td>12050.828487</td>\n",
       "      <td>3.107701</td>\n",
       "      <td>3.969937</td>\n",
       "      <td>0.002338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.980912</td>\n",
       "      <td>28.331081</td>\n",
       "      <td>37.507488</td>\n",
       "      <td>10.485035</td>\n",
       "      <td>56.147817</td>\n",
       "      <td>69.558627</td>\n",
       "      <td>32.493657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.021569</td>\n",
       "      <td>168.613335</td>\n",
       "      <td>0.979423</td>\n",
       "      <td>4100.030050</td>\n",
       "      <td>0.400747</td>\n",
       "      <td>240.799945</td>\n",
       "      <td>16231.506865</td>\n",
       "      <td>7.509348</td>\n",
       "      <td>10.394752</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998087</td>\n",
       "      <td>25.628231</td>\n",
       "      <td>148.881607</td>\n",
       "      <td>99.524345</td>\n",
       "      <td>45.078397</td>\n",
       "      <td>75.205177</td>\n",
       "      <td>61.267747</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.130438</td>\n",
       "      <td>72.451101</td>\n",
       "      <td>0.974628</td>\n",
       "      <td>1427.872261</td>\n",
       "      <td>0.550085</td>\n",
       "      <td>84.710300</td>\n",
       "      <td>5639.037943</td>\n",
       "      <td>5.681062</td>\n",
       "      <td>7.755388</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.994639</td>\n",
       "      <td>17.876900</td>\n",
       "      <td>47.727833</td>\n",
       "      <td>40.773682</td>\n",
       "      <td>20.793650</td>\n",
       "      <td>42.261234</td>\n",
       "      <td>38.057497</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.828427</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     energy    contrast  correlation     variance  inverse difference moment  \\\n",
       "0  0.151255   83.682817     0.992531  5602.660453                   0.524024   \n",
       "1  0.701767   42.595679     0.992800  2957.291822                   0.891638   \n",
       "2  0.531359   58.631216     0.990318  3027.364926                   0.816442   \n",
       "3  0.021569  168.613335     0.979423  4100.030050                   0.400747   \n",
       "4  0.130438   72.451101     0.974628  1427.872261                   0.550085   \n",
       "\n",
       "   sum average  sum variance  sum entropy    entropy  difference variance  \\\n",
       "0   166.271382  22326.958994     5.860651   8.105537             0.000905   \n",
       "1    41.561557  11786.571609     1.974422   2.473410             0.002914   \n",
       "2    56.930850  12050.828487     3.107701   3.969937             0.002338   \n",
       "3   240.799945  16231.506865     7.509348  10.394752             0.000551   \n",
       "4    84.710300   5639.037943     5.681062   7.755388             0.000977   \n",
       "\n",
       "   ...    maximal_corr_coeff     mean_B      mean_G     mean_R      std_B  \\\n",
       "0  ...              0.994969  29.549824   94.431873  80.634457  37.648830   \n",
       "1  ...              0.941292  21.951992   27.125298   7.671936  57.780391   \n",
       "2  ...              0.980912  28.331081   37.507488  10.485035  56.147817   \n",
       "3  ...              0.998087  25.628231  148.881607  99.524345  45.078397   \n",
       "4  ...              0.994639  17.876900   47.727833  40.773682  20.793650   \n",
       "\n",
       "       std_G      std_R  area  perimeter  label  \n",
       "0  84.138807  74.804819   2.5  12.242641    3.0  \n",
       "1  69.075932  34.431439   0.0   0.000000    0.0  \n",
       "2  69.558627  32.493657   0.0   0.000000    0.0  \n",
       "3  75.205177  61.267747   2.0   5.656854    0.0  \n",
       "4  42.261234  38.057497   4.0  10.828427    3.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy</th>\n",
       "      <th>contrast</th>\n",
       "      <th>correlation</th>\n",
       "      <th>variance</th>\n",
       "      <th>inverse difference moment</th>\n",
       "      <th>sum average</th>\n",
       "      <th>sum variance</th>\n",
       "      <th>sum entropy</th>\n",
       "      <th>entropy</th>\n",
       "      <th>difference variance</th>\n",
       "      <th>...</th>\n",
       "      <th>maximal_corr_coeff</th>\n",
       "      <th>mean_B</th>\n",
       "      <th>mean_G</th>\n",
       "      <th>mean_R</th>\n",
       "      <th>std_B</th>\n",
       "      <th>std_G</th>\n",
       "      <th>std_R</th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.029560</td>\n",
       "      <td>88.591990</td>\n",
       "      <td>0.959792</td>\n",
       "      <td>1102.015195</td>\n",
       "      <td>0.577856</td>\n",
       "      <td>103.310454</td>\n",
       "      <td>4319.468789</td>\n",
       "      <td>6.757758</td>\n",
       "      <td>8.729105</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998881</td>\n",
       "      <td>35.178432</td>\n",
       "      <td>52.905010</td>\n",
       "      <td>54.959171</td>\n",
       "      <td>27.326199</td>\n",
       "      <td>33.259695</td>\n",
       "      <td>36.639568</td>\n",
       "      <td>23.5</td>\n",
       "      <td>43.213203</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.109290</td>\n",
       "      <td>105.497714</td>\n",
       "      <td>0.990920</td>\n",
       "      <td>5810.045547</td>\n",
       "      <td>0.573776</td>\n",
       "      <td>196.124179</td>\n",
       "      <td>23134.684474</td>\n",
       "      <td>6.207205</td>\n",
       "      <td>8.071277</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998546</td>\n",
       "      <td>54.409065</td>\n",
       "      <td>118.513771</td>\n",
       "      <td>73.734535</td>\n",
       "      <td>66.565131</td>\n",
       "      <td>90.355411</td>\n",
       "      <td>60.412988</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.234705</td>\n",
       "      <td>152.098099</td>\n",
       "      <td>0.983940</td>\n",
       "      <td>4735.327389</td>\n",
       "      <td>0.599432</td>\n",
       "      <td>128.114749</td>\n",
       "      <td>18789.211456</td>\n",
       "      <td>4.912750</td>\n",
       "      <td>6.854427</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987966</td>\n",
       "      <td>23.898781</td>\n",
       "      <td>86.202984</td>\n",
       "      <td>35.382290</td>\n",
       "      <td>44.373544</td>\n",
       "      <td>89.599111</td>\n",
       "      <td>48.247114</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.766612</td>\n",
       "      <td>43.470814</td>\n",
       "      <td>0.987879</td>\n",
       "      <td>1792.762001</td>\n",
       "      <td>0.921410</td>\n",
       "      <td>27.683495</td>\n",
       "      <td>7127.577188</td>\n",
       "      <td>1.515934</td>\n",
       "      <td>1.856504</td>\n",
       "      <td>0.003492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.908212</td>\n",
       "      <td>15.858822</td>\n",
       "      <td>19.659817</td>\n",
       "      <td>1.515675</td>\n",
       "      <td>50.281453</td>\n",
       "      <td>60.100835</td>\n",
       "      <td>9.040244</td>\n",
       "      <td>11927.0</td>\n",
       "      <td>851.033612</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.625702</td>\n",
       "      <td>56.327930</td>\n",
       "      <td>0.991809</td>\n",
       "      <td>3437.573504</td>\n",
       "      <td>0.865713</td>\n",
       "      <td>55.309109</td>\n",
       "      <td>13693.966084</td>\n",
       "      <td>2.409132</td>\n",
       "      <td>3.005656</td>\n",
       "      <td>0.003102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964397</td>\n",
       "      <td>21.811867</td>\n",
       "      <td>34.595039</td>\n",
       "      <td>15.985023</td>\n",
       "      <td>46.840741</td>\n",
       "      <td>72.178082</td>\n",
       "      <td>43.275999</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.414214</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       energy    contrast  correlation     variance  \\\n",
       "197  0.029560   88.591990     0.959792  1102.015195   \n",
       "198  0.109290  105.497714     0.990920  5810.045547   \n",
       "199  0.234705  152.098099     0.983940  4735.327389   \n",
       "200  0.766612   43.470814     0.987879  1792.762001   \n",
       "201  0.625702   56.327930     0.991809  3437.573504   \n",
       "\n",
       "     inverse difference moment  sum average  sum variance  sum entropy  \\\n",
       "197                   0.577856   103.310454   4319.468789     6.757758   \n",
       "198                   0.573776   196.124179  23134.684474     6.207205   \n",
       "199                   0.599432   128.114749  18789.211456     4.912750   \n",
       "200                   0.921410    27.683495   7127.577188     1.515934   \n",
       "201                   0.865713    55.309109  13693.966084     2.409132   \n",
       "\n",
       "      entropy  difference variance  ...    maximal_corr_coeff     mean_B  \\\n",
       "197  8.729105             0.001050  ...              0.998881  35.178432   \n",
       "198  8.071277             0.001130  ...              0.998546  54.409065   \n",
       "199  6.854427             0.001165  ...              0.987966  23.898781   \n",
       "200  1.856504             0.003492  ...              0.908212  15.858822   \n",
       "201  3.005656             0.003102  ...              0.964397  21.811867   \n",
       "\n",
       "         mean_G     mean_R      std_B      std_G      std_R     area  \\\n",
       "197   52.905010  54.959171  27.326199  33.259695  36.639568     23.5   \n",
       "198  118.513771  73.734535  66.565131  90.355411  60.412988      2.0   \n",
       "199   86.202984  35.382290  44.373544  89.599111  48.247114      2.0   \n",
       "200   19.659817   1.515675  50.281453  60.100835   9.040244  11927.0   \n",
       "201   34.595039  15.985023  46.840741  72.178082  43.275999      0.5   \n",
       "\n",
       "      perimeter  label  \n",
       "197   43.213203    1.0  \n",
       "198    5.656854    0.0  \n",
       "199    5.656854    0.0  \n",
       "200  851.033612    0.0  \n",
       "201    3.414214    0.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfile.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile = myfile.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy</th>\n",
       "      <th>contrast</th>\n",
       "      <th>correlation</th>\n",
       "      <th>variance</th>\n",
       "      <th>inverse difference moment</th>\n",
       "      <th>sum average</th>\n",
       "      <th>sum variance</th>\n",
       "      <th>sum entropy</th>\n",
       "      <th>entropy</th>\n",
       "      <th>difference variance</th>\n",
       "      <th>...</th>\n",
       "      <th>maximal_corr_coeff</th>\n",
       "      <th>mean_B</th>\n",
       "      <th>mean_G</th>\n",
       "      <th>mean_R</th>\n",
       "      <th>std_B</th>\n",
       "      <th>std_G</th>\n",
       "      <th>std_R</th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.192417</td>\n",
       "      <td>72.897108</td>\n",
       "      <td>0.993289</td>\n",
       "      <td>5431.398748</td>\n",
       "      <td>0.614740</td>\n",
       "      <td>149.330414</td>\n",
       "      <td>21652.697885</td>\n",
       "      <td>5.561483</td>\n",
       "      <td>7.304616</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997275</td>\n",
       "      <td>24.334641</td>\n",
       "      <td>94.499355</td>\n",
       "      <td>54.225159</td>\n",
       "      <td>41.756239</td>\n",
       "      <td>92.422277</td>\n",
       "      <td>56.412872</td>\n",
       "      <td>5.5</td>\n",
       "      <td>9.071068</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.228674</td>\n",
       "      <td>22.062686</td>\n",
       "      <td>0.997575</td>\n",
       "      <td>4547.956061</td>\n",
       "      <td>0.684219</td>\n",
       "      <td>121.122067</td>\n",
       "      <td>18169.761557</td>\n",
       "      <td>5.376793</td>\n",
       "      <td>6.793665</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998274</td>\n",
       "      <td>38.379612</td>\n",
       "      <td>65.333393</td>\n",
       "      <td>59.050583</td>\n",
       "      <td>46.733073</td>\n",
       "      <td>71.787567</td>\n",
       "      <td>68.684190</td>\n",
       "      <td>5.5</td>\n",
       "      <td>12.242641</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.153598</td>\n",
       "      <td>63.630726</td>\n",
       "      <td>0.992953</td>\n",
       "      <td>4514.795818</td>\n",
       "      <td>0.531286</td>\n",
       "      <td>145.546529</td>\n",
       "      <td>17995.552545</td>\n",
       "      <td>5.825308</td>\n",
       "      <td>8.031944</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995106</td>\n",
       "      <td>79.750870</td>\n",
       "      <td>93.388336</td>\n",
       "      <td>28.942642</td>\n",
       "      <td>74.961494</td>\n",
       "      <td>84.473642</td>\n",
       "      <td>37.316142</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.242641</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.769301</td>\n",
       "      <td>34.285448</td>\n",
       "      <td>0.992006</td>\n",
       "      <td>2143.851081</td>\n",
       "      <td>0.928766</td>\n",
       "      <td>30.900895</td>\n",
       "      <td>8541.118877</td>\n",
       "      <td>1.511281</td>\n",
       "      <td>1.812599</td>\n",
       "      <td>0.003550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.915109</td>\n",
       "      <td>16.005070</td>\n",
       "      <td>21.314579</td>\n",
       "      <td>3.576118</td>\n",
       "      <td>48.680908</td>\n",
       "      <td>62.979935</td>\n",
       "      <td>18.673438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.256946</td>\n",
       "      <td>75.104632</td>\n",
       "      <td>0.995231</td>\n",
       "      <td>7873.304376</td>\n",
       "      <td>0.688725</td>\n",
       "      <td>151.374337</td>\n",
       "      <td>31418.112874</td>\n",
       "      <td>5.162098</td>\n",
       "      <td>6.603945</td>\n",
       "      <td>0.001497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997585</td>\n",
       "      <td>24.964520</td>\n",
       "      <td>87.532627</td>\n",
       "      <td>71.131737</td>\n",
       "      <td>59.350869</td>\n",
       "      <td>100.544815</td>\n",
       "      <td>86.047213</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.034585</td>\n",
       "      <td>211.007311</td>\n",
       "      <td>0.977193</td>\n",
       "      <td>4627.618620</td>\n",
       "      <td>0.404178</td>\n",
       "      <td>233.767679</td>\n",
       "      <td>18299.467171</td>\n",
       "      <td>7.301754</td>\n",
       "      <td>10.246600</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997454</td>\n",
       "      <td>27.689655</td>\n",
       "      <td>144.590858</td>\n",
       "      <td>95.801785</td>\n",
       "      <td>47.251831</td>\n",
       "      <td>80.248106</td>\n",
       "      <td>63.827009</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.772205</td>\n",
       "      <td>32.265973</td>\n",
       "      <td>0.993166</td>\n",
       "      <td>2360.266368</td>\n",
       "      <td>0.908587</td>\n",
       "      <td>32.436979</td>\n",
       "      <td>9408.799500</td>\n",
       "      <td>1.552231</td>\n",
       "      <td>1.978297</td>\n",
       "      <td>0.003104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.900063</td>\n",
       "      <td>15.597744</td>\n",
       "      <td>19.756485</td>\n",
       "      <td>9.349380</td>\n",
       "      <td>46.795882</td>\n",
       "      <td>58.779602</td>\n",
       "      <td>31.145390</td>\n",
       "      <td>99.5</td>\n",
       "      <td>53.556349</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.651938</td>\n",
       "      <td>44.382059</td>\n",
       "      <td>0.991639</td>\n",
       "      <td>2653.426582</td>\n",
       "      <td>0.883038</td>\n",
       "      <td>46.206624</td>\n",
       "      <td>10569.324269</td>\n",
       "      <td>2.183957</td>\n",
       "      <td>2.708647</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954167</td>\n",
       "      <td>22.975254</td>\n",
       "      <td>29.661224</td>\n",
       "      <td>10.041504</td>\n",
       "      <td>51.726987</td>\n",
       "      <td>65.063372</td>\n",
       "      <td>29.985131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.146658</td>\n",
       "      <td>50.129835</td>\n",
       "      <td>0.996713</td>\n",
       "      <td>7626.291149</td>\n",
       "      <td>0.658985</td>\n",
       "      <td>198.008494</td>\n",
       "      <td>30455.034760</td>\n",
       "      <td>5.977753</td>\n",
       "      <td>7.546238</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998951</td>\n",
       "      <td>74.070999</td>\n",
       "      <td>109.381493</td>\n",
       "      <td>87.345341</td>\n",
       "      <td>74.873640</td>\n",
       "      <td>95.165669</td>\n",
       "      <td>78.769876</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.485281</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.040459</td>\n",
       "      <td>148.225557</td>\n",
       "      <td>0.986774</td>\n",
       "      <td>5605.183896</td>\n",
       "      <td>0.420295</td>\n",
       "      <td>237.118255</td>\n",
       "      <td>22272.510027</td>\n",
       "      <td>7.397180</td>\n",
       "      <td>10.134563</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998695</td>\n",
       "      <td>29.388966</td>\n",
       "      <td>141.190071</td>\n",
       "      <td>107.218483</td>\n",
       "      <td>52.567308</td>\n",
       "      <td>85.176159</td>\n",
       "      <td>72.846905</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.790151</td>\n",
       "      <td>29.335108</td>\n",
       "      <td>0.991579</td>\n",
       "      <td>1741.422062</td>\n",
       "      <td>0.929646</td>\n",
       "      <td>26.289397</td>\n",
       "      <td>6936.353138</td>\n",
       "      <td>1.366241</td>\n",
       "      <td>1.678061</td>\n",
       "      <td>0.003232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.889809</td>\n",
       "      <td>15.375862</td>\n",
       "      <td>18.196686</td>\n",
       "      <td>2.246880</td>\n",
       "      <td>49.031662</td>\n",
       "      <td>57.354588</td>\n",
       "      <td>14.433809</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.624685</td>\n",
       "      <td>45.789648</td>\n",
       "      <td>0.993797</td>\n",
       "      <td>3690.458582</td>\n",
       "      <td>0.874884</td>\n",
       "      <td>57.013833</td>\n",
       "      <td>14716.044680</td>\n",
       "      <td>2.389257</td>\n",
       "      <td>2.962654</td>\n",
       "      <td>0.002748</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964616</td>\n",
       "      <td>30.256279</td>\n",
       "      <td>39.078838</td>\n",
       "      <td>6.807224</td>\n",
       "      <td>66.388570</td>\n",
       "      <td>82.963680</td>\n",
       "      <td>26.472614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.694144</td>\n",
       "      <td>45.875700</td>\n",
       "      <td>0.992168</td>\n",
       "      <td>2928.179448</td>\n",
       "      <td>0.895989</td>\n",
       "      <td>43.435683</td>\n",
       "      <td>11666.842094</td>\n",
       "      <td>2.002402</td>\n",
       "      <td>2.469971</td>\n",
       "      <td>0.002945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947141</td>\n",
       "      <td>23.631935</td>\n",
       "      <td>30.025379</td>\n",
       "      <td>4.466053</td>\n",
       "      <td>60.617565</td>\n",
       "      <td>74.391924</td>\n",
       "      <td>21.000358</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.644294</td>\n",
       "      <td>41.037713</td>\n",
       "      <td>0.995397</td>\n",
       "      <td>4457.005257</td>\n",
       "      <td>0.877984</td>\n",
       "      <td>60.466947</td>\n",
       "      <td>17786.983314</td>\n",
       "      <td>2.283116</td>\n",
       "      <td>2.834027</td>\n",
       "      <td>0.002828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.959227</td>\n",
       "      <td>22.772503</td>\n",
       "      <td>33.340370</td>\n",
       "      <td>26.682697</td>\n",
       "      <td>53.953452</td>\n",
       "      <td>73.180149</td>\n",
       "      <td>59.572962</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.143089</td>\n",
       "      <td>89.805130</td>\n",
       "      <td>0.993975</td>\n",
       "      <td>7452.906786</td>\n",
       "      <td>0.566768</td>\n",
       "      <td>200.648778</td>\n",
       "      <td>29721.822014</td>\n",
       "      <td>5.979531</td>\n",
       "      <td>7.931707</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997553</td>\n",
       "      <td>54.330463</td>\n",
       "      <td>119.518723</td>\n",
       "      <td>79.261734</td>\n",
       "      <td>68.131779</td>\n",
       "      <td>101.136027</td>\n",
       "      <td>70.536433</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.029560</td>\n",
       "      <td>88.591990</td>\n",
       "      <td>0.959792</td>\n",
       "      <td>1102.015195</td>\n",
       "      <td>0.577856</td>\n",
       "      <td>103.310454</td>\n",
       "      <td>4319.468789</td>\n",
       "      <td>6.757758</td>\n",
       "      <td>8.729105</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998881</td>\n",
       "      <td>35.178432</td>\n",
       "      <td>52.905010</td>\n",
       "      <td>54.959171</td>\n",
       "      <td>27.326199</td>\n",
       "      <td>33.259695</td>\n",
       "      <td>36.639568</td>\n",
       "      <td>23.5</td>\n",
       "      <td>43.213203</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.109290</td>\n",
       "      <td>105.497714</td>\n",
       "      <td>0.990920</td>\n",
       "      <td>5810.045547</td>\n",
       "      <td>0.573776</td>\n",
       "      <td>196.124179</td>\n",
       "      <td>23134.684474</td>\n",
       "      <td>6.207205</td>\n",
       "      <td>8.071277</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998546</td>\n",
       "      <td>54.409065</td>\n",
       "      <td>118.513771</td>\n",
       "      <td>73.734535</td>\n",
       "      <td>66.565131</td>\n",
       "      <td>90.355411</td>\n",
       "      <td>60.412988</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.234705</td>\n",
       "      <td>152.098099</td>\n",
       "      <td>0.983940</td>\n",
       "      <td>4735.327389</td>\n",
       "      <td>0.599432</td>\n",
       "      <td>128.114749</td>\n",
       "      <td>18789.211456</td>\n",
       "      <td>4.912750</td>\n",
       "      <td>6.854427</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987966</td>\n",
       "      <td>23.898781</td>\n",
       "      <td>86.202984</td>\n",
       "      <td>35.382290</td>\n",
       "      <td>44.373544</td>\n",
       "      <td>89.599111</td>\n",
       "      <td>48.247114</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.766612</td>\n",
       "      <td>43.470814</td>\n",
       "      <td>0.987879</td>\n",
       "      <td>1792.762001</td>\n",
       "      <td>0.921410</td>\n",
       "      <td>27.683495</td>\n",
       "      <td>7127.577188</td>\n",
       "      <td>1.515934</td>\n",
       "      <td>1.856504</td>\n",
       "      <td>0.003492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.908212</td>\n",
       "      <td>15.858822</td>\n",
       "      <td>19.659817</td>\n",
       "      <td>1.515675</td>\n",
       "      <td>50.281453</td>\n",
       "      <td>60.100835</td>\n",
       "      <td>9.040244</td>\n",
       "      <td>11927.0</td>\n",
       "      <td>851.033612</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.625702</td>\n",
       "      <td>56.327930</td>\n",
       "      <td>0.991809</td>\n",
       "      <td>3437.573504</td>\n",
       "      <td>0.865713</td>\n",
       "      <td>55.309109</td>\n",
       "      <td>13693.966084</td>\n",
       "      <td>2.409132</td>\n",
       "      <td>3.005656</td>\n",
       "      <td>0.003102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964397</td>\n",
       "      <td>21.811867</td>\n",
       "      <td>34.595039</td>\n",
       "      <td>15.985023</td>\n",
       "      <td>46.840741</td>\n",
       "      <td>72.178082</td>\n",
       "      <td>43.275999</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.414214</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       energy    contrast  correlation     variance  \\\n",
       "182  0.192417   72.897108     0.993289  5431.398748   \n",
       "183  0.228674   22.062686     0.997575  4547.956061   \n",
       "184  0.153598   63.630726     0.992953  4514.795818   \n",
       "185  0.769301   34.285448     0.992006  2143.851081   \n",
       "186  0.256946   75.104632     0.995231  7873.304376   \n",
       "187  0.034585  211.007311     0.977193  4627.618620   \n",
       "188  0.772205   32.265973     0.993166  2360.266368   \n",
       "189  0.651938   44.382059     0.991639  2653.426582   \n",
       "190  0.146658   50.129835     0.996713  7626.291149   \n",
       "191  0.040459  148.225557     0.986774  5605.183896   \n",
       "192  0.790151   29.335108     0.991579  1741.422062   \n",
       "193  0.624685   45.789648     0.993797  3690.458582   \n",
       "194  0.694144   45.875700     0.992168  2928.179448   \n",
       "195  0.644294   41.037713     0.995397  4457.005257   \n",
       "196  0.143089   89.805130     0.993975  7452.906786   \n",
       "197  0.029560   88.591990     0.959792  1102.015195   \n",
       "198  0.109290  105.497714     0.990920  5810.045547   \n",
       "199  0.234705  152.098099     0.983940  4735.327389   \n",
       "200  0.766612   43.470814     0.987879  1792.762001   \n",
       "201  0.625702   56.327930     0.991809  3437.573504   \n",
       "\n",
       "     inverse difference moment  sum average  sum variance  sum entropy  \\\n",
       "182                   0.614740   149.330414  21652.697885     5.561483   \n",
       "183                   0.684219   121.122067  18169.761557     5.376793   \n",
       "184                   0.531286   145.546529  17995.552545     5.825308   \n",
       "185                   0.928766    30.900895   8541.118877     1.511281   \n",
       "186                   0.688725   151.374337  31418.112874     5.162098   \n",
       "187                   0.404178   233.767679  18299.467171     7.301754   \n",
       "188                   0.908587    32.436979   9408.799500     1.552231   \n",
       "189                   0.883038    46.206624  10569.324269     2.183957   \n",
       "190                   0.658985   198.008494  30455.034760     5.977753   \n",
       "191                   0.420295   237.118255  22272.510027     7.397180   \n",
       "192                   0.929646    26.289397   6936.353138     1.366241   \n",
       "193                   0.874884    57.013833  14716.044680     2.389257   \n",
       "194                   0.895989    43.435683  11666.842094     2.002402   \n",
       "195                   0.877984    60.466947  17786.983314     2.283116   \n",
       "196                   0.566768   200.648778  29721.822014     5.979531   \n",
       "197                   0.577856   103.310454   4319.468789     6.757758   \n",
       "198                   0.573776   196.124179  23134.684474     6.207205   \n",
       "199                   0.599432   128.114749  18789.211456     4.912750   \n",
       "200                   0.921410    27.683495   7127.577188     1.515934   \n",
       "201                   0.865713    55.309109  13693.966084     2.409132   \n",
       "\n",
       "       entropy  difference variance  ...    maximal_corr_coeff     mean_B  \\\n",
       "182   7.304616             0.001173  ...              0.997275  24.334641   \n",
       "183   6.793665             0.001711  ...              0.998274  38.379612   \n",
       "184   8.031944             0.000964  ...              0.995106  79.750870   \n",
       "185   1.812599             0.003550  ...              0.915109  16.005070   \n",
       "186   6.603945             0.001497  ...              0.997585  24.964520   \n",
       "187  10.246600             0.000536  ...              0.997454  27.689655   \n",
       "188   1.978297             0.003104  ...              0.900063  15.597744   \n",
       "189   2.708647             0.002790  ...              0.954167  22.975254   \n",
       "190   7.546238             0.001335  ...              0.998951  74.070999   \n",
       "191  10.134563             0.000572  ...              0.998695  29.388966   \n",
       "192   1.678061             0.003232  ...              0.889809  15.375862   \n",
       "193   2.962654             0.002748  ...              0.964616  30.256279   \n",
       "194   2.469971             0.002945  ...              0.947141  23.631935   \n",
       "195   2.834027             0.002828  ...              0.959227  22.772503   \n",
       "196   7.931707             0.001038  ...              0.997553  54.330463   \n",
       "197   8.729105             0.001050  ...              0.998881  35.178432   \n",
       "198   8.071277             0.001130  ...              0.998546  54.409065   \n",
       "199   6.854427             0.001165  ...              0.987966  23.898781   \n",
       "200   1.856504             0.003492  ...              0.908212  15.858822   \n",
       "201   3.005656             0.003102  ...              0.964397  21.811867   \n",
       "\n",
       "         mean_G      mean_R      std_B       std_G      std_R     area  \\\n",
       "182   94.499355   54.225159  41.756239   92.422277  56.412872      5.5   \n",
       "183   65.333393   59.050583  46.733073   71.787567  68.684190      5.5   \n",
       "184   93.388336   28.942642  74.961494   84.473642  37.316142      0.5   \n",
       "185   21.314579    3.576118  48.680908   62.979935  18.673438      0.0   \n",
       "186   87.532627   71.131737  59.350869  100.544815  86.047213      2.0   \n",
       "187  144.590858   95.801785  47.251831   80.248106  63.827009      2.0   \n",
       "188   19.756485    9.349380  46.795882   58.779602  31.145390     99.5   \n",
       "189   29.661224   10.041504  51.726987   65.063372  29.985131      0.0   \n",
       "190  109.381493   87.345341  74.873640   95.165669  78.769876     10.0   \n",
       "191  141.190071  107.218483  52.567308   85.176159  72.846905      2.0   \n",
       "192   18.196686    2.246880  49.031662   57.354588  14.433809      2.0   \n",
       "193   39.078838    6.807224  66.388570   82.963680  26.472614      0.0   \n",
       "194   30.025379    4.466053  60.617565   74.391924  21.000358      2.0   \n",
       "195   33.340370   26.682697  53.953452   73.180149  59.572962      2.0   \n",
       "196  119.518723   79.261734  68.131779  101.136027  70.536433      2.0   \n",
       "197   52.905010   54.959171  27.326199   33.259695  36.639568     23.5   \n",
       "198  118.513771   73.734535  66.565131   90.355411  60.412988      2.0   \n",
       "199   86.202984   35.382290  44.373544   89.599111  48.247114      2.0   \n",
       "200   19.659817    1.515675  50.281453   60.100835   9.040244  11927.0   \n",
       "201   34.595039   15.985023  46.840741   72.178082  43.275999      0.5   \n",
       "\n",
       "      perimeter  label  \n",
       "182    9.071068    0.0  \n",
       "183   12.242641    3.0  \n",
       "184    8.242641    3.0  \n",
       "185    0.000000    0.0  \n",
       "186    5.656854    0.0  \n",
       "187    5.656854    0.0  \n",
       "188   53.556349    0.0  \n",
       "189    0.000000    0.0  \n",
       "190   12.485281    2.0  \n",
       "191    5.656854    0.0  \n",
       "192    5.656854    0.0  \n",
       "193    0.000000    0.0  \n",
       "194    5.656854    0.0  \n",
       "195    5.656854    2.0  \n",
       "196    5.656854    0.0  \n",
       "197   43.213203    1.0  \n",
       "198    5.656854    0.0  \n",
       "199    5.656854    0.0  \n",
       "200  851.033612    0.0  \n",
       "201    3.414214    0.0  \n",
       "\n",
       "[20 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfile[182:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperating the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file = myfile.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylabel = myfile.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylabel = mylabel.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy</th>\n",
       "      <th>contrast</th>\n",
       "      <th>correlation</th>\n",
       "      <th>variance</th>\n",
       "      <th>inverse difference moment</th>\n",
       "      <th>sum average</th>\n",
       "      <th>sum variance</th>\n",
       "      <th>sum entropy</th>\n",
       "      <th>entropy</th>\n",
       "      <th>difference variance</th>\n",
       "      <th>...</th>\n",
       "      <th>info_corr</th>\n",
       "      <th>maximal_corr_coeff</th>\n",
       "      <th>mean_B</th>\n",
       "      <th>mean_G</th>\n",
       "      <th>mean_R</th>\n",
       "      <th>std_B</th>\n",
       "      <th>std_G</th>\n",
       "      <th>std_R</th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.192417</td>\n",
       "      <td>72.897108</td>\n",
       "      <td>0.993289</td>\n",
       "      <td>5431.398748</td>\n",
       "      <td>0.614740</td>\n",
       "      <td>149.330414</td>\n",
       "      <td>21652.697885</td>\n",
       "      <td>5.561483</td>\n",
       "      <td>7.304616</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.527975</td>\n",
       "      <td>0.997275</td>\n",
       "      <td>24.334641</td>\n",
       "      <td>94.499355</td>\n",
       "      <td>54.225159</td>\n",
       "      <td>41.756239</td>\n",
       "      <td>92.422277</td>\n",
       "      <td>56.412872</td>\n",
       "      <td>5.5</td>\n",
       "      <td>9.071068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.228674</td>\n",
       "      <td>22.062686</td>\n",
       "      <td>0.997575</td>\n",
       "      <td>4547.956061</td>\n",
       "      <td>0.684219</td>\n",
       "      <td>121.122067</td>\n",
       "      <td>18169.761557</td>\n",
       "      <td>5.376793</td>\n",
       "      <td>6.793665</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.591206</td>\n",
       "      <td>0.998274</td>\n",
       "      <td>38.379612</td>\n",
       "      <td>65.333393</td>\n",
       "      <td>59.050583</td>\n",
       "      <td>46.733073</td>\n",
       "      <td>71.787567</td>\n",
       "      <td>68.684190</td>\n",
       "      <td>5.5</td>\n",
       "      <td>12.242641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.153598</td>\n",
       "      <td>63.630726</td>\n",
       "      <td>0.992953</td>\n",
       "      <td>4514.795818</td>\n",
       "      <td>0.531286</td>\n",
       "      <td>145.546529</td>\n",
       "      <td>17995.552545</td>\n",
       "      <td>5.825308</td>\n",
       "      <td>8.031944</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.450169</td>\n",
       "      <td>0.995106</td>\n",
       "      <td>79.750870</td>\n",
       "      <td>93.388336</td>\n",
       "      <td>28.942642</td>\n",
       "      <td>74.961494</td>\n",
       "      <td>84.473642</td>\n",
       "      <td>37.316142</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.242641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.769301</td>\n",
       "      <td>34.285448</td>\n",
       "      <td>0.992006</td>\n",
       "      <td>2143.851081</td>\n",
       "      <td>0.928766</td>\n",
       "      <td>30.900895</td>\n",
       "      <td>8541.118877</td>\n",
       "      <td>1.511281</td>\n",
       "      <td>1.812599</td>\n",
       "      <td>0.003550</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.669718</td>\n",
       "      <td>0.915109</td>\n",
       "      <td>16.005070</td>\n",
       "      <td>21.314579</td>\n",
       "      <td>3.576118</td>\n",
       "      <td>48.680908</td>\n",
       "      <td>62.979935</td>\n",
       "      <td>18.673438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.256946</td>\n",
       "      <td>75.104632</td>\n",
       "      <td>0.995231</td>\n",
       "      <td>7873.304376</td>\n",
       "      <td>0.688725</td>\n",
       "      <td>151.374337</td>\n",
       "      <td>31418.112874</td>\n",
       "      <td>5.162098</td>\n",
       "      <td>6.603945</td>\n",
       "      <td>0.001497</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.577850</td>\n",
       "      <td>0.997585</td>\n",
       "      <td>24.964520</td>\n",
       "      <td>87.532627</td>\n",
       "      <td>71.131737</td>\n",
       "      <td>59.350869</td>\n",
       "      <td>100.544815</td>\n",
       "      <td>86.047213</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.034585</td>\n",
       "      <td>211.007311</td>\n",
       "      <td>0.977193</td>\n",
       "      <td>4627.618620</td>\n",
       "      <td>0.404178</td>\n",
       "      <td>233.767679</td>\n",
       "      <td>18299.467171</td>\n",
       "      <td>7.301754</td>\n",
       "      <td>10.246600</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.417823</td>\n",
       "      <td>0.997454</td>\n",
       "      <td>27.689655</td>\n",
       "      <td>144.590858</td>\n",
       "      <td>95.801785</td>\n",
       "      <td>47.251831</td>\n",
       "      <td>80.248106</td>\n",
       "      <td>63.827009</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.772205</td>\n",
       "      <td>32.265973</td>\n",
       "      <td>0.993166</td>\n",
       "      <td>2360.266368</td>\n",
       "      <td>0.908587</td>\n",
       "      <td>32.436979</td>\n",
       "      <td>9408.799500</td>\n",
       "      <td>1.552231</td>\n",
       "      <td>1.978297</td>\n",
       "      <td>0.003104</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.592231</td>\n",
       "      <td>0.900063</td>\n",
       "      <td>15.597744</td>\n",
       "      <td>19.756485</td>\n",
       "      <td>9.349380</td>\n",
       "      <td>46.795882</td>\n",
       "      <td>58.779602</td>\n",
       "      <td>31.145390</td>\n",
       "      <td>99.5</td>\n",
       "      <td>53.556349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.651938</td>\n",
       "      <td>44.382059</td>\n",
       "      <td>0.991639</td>\n",
       "      <td>2653.426582</td>\n",
       "      <td>0.883038</td>\n",
       "      <td>46.206624</td>\n",
       "      <td>10569.324269</td>\n",
       "      <td>2.183957</td>\n",
       "      <td>2.708647</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.617529</td>\n",
       "      <td>0.954167</td>\n",
       "      <td>22.975254</td>\n",
       "      <td>29.661224</td>\n",
       "      <td>10.041504</td>\n",
       "      <td>51.726987</td>\n",
       "      <td>65.063372</td>\n",
       "      <td>29.985131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.146658</td>\n",
       "      <td>50.129835</td>\n",
       "      <td>0.996713</td>\n",
       "      <td>7626.291149</td>\n",
       "      <td>0.658985</td>\n",
       "      <td>198.008494</td>\n",
       "      <td>30455.034760</td>\n",
       "      <td>5.977753</td>\n",
       "      <td>7.546238</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.582778</td>\n",
       "      <td>0.998951</td>\n",
       "      <td>74.070999</td>\n",
       "      <td>109.381493</td>\n",
       "      <td>87.345341</td>\n",
       "      <td>74.873640</td>\n",
       "      <td>95.165669</td>\n",
       "      <td>78.769876</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.485281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.040459</td>\n",
       "      <td>148.225557</td>\n",
       "      <td>0.986774</td>\n",
       "      <td>5605.183896</td>\n",
       "      <td>0.420295</td>\n",
       "      <td>237.118255</td>\n",
       "      <td>22272.510027</td>\n",
       "      <td>7.397180</td>\n",
       "      <td>10.134563</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.458772</td>\n",
       "      <td>0.998695</td>\n",
       "      <td>29.388966</td>\n",
       "      <td>141.190071</td>\n",
       "      <td>107.218483</td>\n",
       "      <td>52.567308</td>\n",
       "      <td>85.176159</td>\n",
       "      <td>72.846905</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.790151</td>\n",
       "      <td>29.335108</td>\n",
       "      <td>0.991579</td>\n",
       "      <td>1741.422062</td>\n",
       "      <td>0.929646</td>\n",
       "      <td>26.289397</td>\n",
       "      <td>6936.353138</td>\n",
       "      <td>1.366241</td>\n",
       "      <td>1.678061</td>\n",
       "      <td>0.003232</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.637695</td>\n",
       "      <td>0.889809</td>\n",
       "      <td>15.375862</td>\n",
       "      <td>18.196686</td>\n",
       "      <td>2.246880</td>\n",
       "      <td>49.031662</td>\n",
       "      <td>57.354588</td>\n",
       "      <td>14.433809</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.624685</td>\n",
       "      <td>45.789648</td>\n",
       "      <td>0.993797</td>\n",
       "      <td>3690.458582</td>\n",
       "      <td>0.874884</td>\n",
       "      <td>57.013833</td>\n",
       "      <td>14716.044680</td>\n",
       "      <td>2.389257</td>\n",
       "      <td>2.962654</td>\n",
       "      <td>0.002748</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.622024</td>\n",
       "      <td>0.964616</td>\n",
       "      <td>30.256279</td>\n",
       "      <td>39.078838</td>\n",
       "      <td>6.807224</td>\n",
       "      <td>66.388570</td>\n",
       "      <td>82.963680</td>\n",
       "      <td>26.472614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.694144</td>\n",
       "      <td>45.875700</td>\n",
       "      <td>0.992168</td>\n",
       "      <td>2928.179448</td>\n",
       "      <td>0.895989</td>\n",
       "      <td>43.435683</td>\n",
       "      <td>11666.842094</td>\n",
       "      <td>2.002402</td>\n",
       "      <td>2.469971</td>\n",
       "      <td>0.002945</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.632487</td>\n",
       "      <td>0.947141</td>\n",
       "      <td>23.631935</td>\n",
       "      <td>30.025379</td>\n",
       "      <td>4.466053</td>\n",
       "      <td>60.617565</td>\n",
       "      <td>74.391924</td>\n",
       "      <td>21.000358</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.644294</td>\n",
       "      <td>41.037713</td>\n",
       "      <td>0.995397</td>\n",
       "      <td>4457.005257</td>\n",
       "      <td>0.877984</td>\n",
       "      <td>60.466947</td>\n",
       "      <td>17786.983314</td>\n",
       "      <td>2.283116</td>\n",
       "      <td>2.834027</td>\n",
       "      <td>0.002828</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.617860</td>\n",
       "      <td>0.959227</td>\n",
       "      <td>22.772503</td>\n",
       "      <td>33.340370</td>\n",
       "      <td>26.682697</td>\n",
       "      <td>53.953452</td>\n",
       "      <td>73.180149</td>\n",
       "      <td>59.572962</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.143089</td>\n",
       "      <td>89.805130</td>\n",
       "      <td>0.993975</td>\n",
       "      <td>7452.906786</td>\n",
       "      <td>0.566768</td>\n",
       "      <td>200.648778</td>\n",
       "      <td>29721.822014</td>\n",
       "      <td>5.979531</td>\n",
       "      <td>7.931707</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.507896</td>\n",
       "      <td>0.997553</td>\n",
       "      <td>54.330463</td>\n",
       "      <td>119.518723</td>\n",
       "      <td>79.261734</td>\n",
       "      <td>68.131779</td>\n",
       "      <td>101.136027</td>\n",
       "      <td>70.536433</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.029560</td>\n",
       "      <td>88.591990</td>\n",
       "      <td>0.959792</td>\n",
       "      <td>1102.015195</td>\n",
       "      <td>0.577856</td>\n",
       "      <td>103.310454</td>\n",
       "      <td>4319.468789</td>\n",
       "      <td>6.757758</td>\n",
       "      <td>8.729105</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.523998</td>\n",
       "      <td>0.998881</td>\n",
       "      <td>35.178432</td>\n",
       "      <td>52.905010</td>\n",
       "      <td>54.959171</td>\n",
       "      <td>27.326199</td>\n",
       "      <td>33.259695</td>\n",
       "      <td>36.639568</td>\n",
       "      <td>23.5</td>\n",
       "      <td>43.213203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.109290</td>\n",
       "      <td>105.497714</td>\n",
       "      <td>0.990920</td>\n",
       "      <td>5810.045547</td>\n",
       "      <td>0.573776</td>\n",
       "      <td>196.124179</td>\n",
       "      <td>23134.684474</td>\n",
       "      <td>6.207205</td>\n",
       "      <td>8.071277</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.533876</td>\n",
       "      <td>0.998546</td>\n",
       "      <td>54.409065</td>\n",
       "      <td>118.513771</td>\n",
       "      <td>73.734535</td>\n",
       "      <td>66.565131</td>\n",
       "      <td>90.355411</td>\n",
       "      <td>60.412988</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.234705</td>\n",
       "      <td>152.098099</td>\n",
       "      <td>0.983940</td>\n",
       "      <td>4735.327389</td>\n",
       "      <td>0.599432</td>\n",
       "      <td>128.114749</td>\n",
       "      <td>18789.211456</td>\n",
       "      <td>4.912750</td>\n",
       "      <td>6.854427</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.429480</td>\n",
       "      <td>0.987966</td>\n",
       "      <td>23.898781</td>\n",
       "      <td>86.202984</td>\n",
       "      <td>35.382290</td>\n",
       "      <td>44.373544</td>\n",
       "      <td>89.599111</td>\n",
       "      <td>48.247114</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.766612</td>\n",
       "      <td>43.470814</td>\n",
       "      <td>0.987879</td>\n",
       "      <td>1792.762001</td>\n",
       "      <td>0.921410</td>\n",
       "      <td>27.683495</td>\n",
       "      <td>7127.577188</td>\n",
       "      <td>1.515934</td>\n",
       "      <td>1.856504</td>\n",
       "      <td>0.003492</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.640145</td>\n",
       "      <td>0.908212</td>\n",
       "      <td>15.858822</td>\n",
       "      <td>19.659817</td>\n",
       "      <td>1.515675</td>\n",
       "      <td>50.281453</td>\n",
       "      <td>60.100835</td>\n",
       "      <td>9.040244</td>\n",
       "      <td>11927.0</td>\n",
       "      <td>851.033612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.625702</td>\n",
       "      <td>56.327930</td>\n",
       "      <td>0.991809</td>\n",
       "      <td>3437.573504</td>\n",
       "      <td>0.865713</td>\n",
       "      <td>55.309109</td>\n",
       "      <td>13693.966084</td>\n",
       "      <td>2.409132</td>\n",
       "      <td>3.005656</td>\n",
       "      <td>0.003102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.614612</td>\n",
       "      <td>0.964397</td>\n",
       "      <td>21.811867</td>\n",
       "      <td>34.595039</td>\n",
       "      <td>15.985023</td>\n",
       "      <td>46.840741</td>\n",
       "      <td>72.178082</td>\n",
       "      <td>43.275999</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.414214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       energy    contrast  correlation     variance  \\\n",
       "182  0.192417   72.897108     0.993289  5431.398748   \n",
       "183  0.228674   22.062686     0.997575  4547.956061   \n",
       "184  0.153598   63.630726     0.992953  4514.795818   \n",
       "185  0.769301   34.285448     0.992006  2143.851081   \n",
       "186  0.256946   75.104632     0.995231  7873.304376   \n",
       "187  0.034585  211.007311     0.977193  4627.618620   \n",
       "188  0.772205   32.265973     0.993166  2360.266368   \n",
       "189  0.651938   44.382059     0.991639  2653.426582   \n",
       "190  0.146658   50.129835     0.996713  7626.291149   \n",
       "191  0.040459  148.225557     0.986774  5605.183896   \n",
       "192  0.790151   29.335108     0.991579  1741.422062   \n",
       "193  0.624685   45.789648     0.993797  3690.458582   \n",
       "194  0.694144   45.875700     0.992168  2928.179448   \n",
       "195  0.644294   41.037713     0.995397  4457.005257   \n",
       "196  0.143089   89.805130     0.993975  7452.906786   \n",
       "197  0.029560   88.591990     0.959792  1102.015195   \n",
       "198  0.109290  105.497714     0.990920  5810.045547   \n",
       "199  0.234705  152.098099     0.983940  4735.327389   \n",
       "200  0.766612   43.470814     0.987879  1792.762001   \n",
       "201  0.625702   56.327930     0.991809  3437.573504   \n",
       "\n",
       "     inverse difference moment  sum average  sum variance  sum entropy  \\\n",
       "182                   0.614740   149.330414  21652.697885     5.561483   \n",
       "183                   0.684219   121.122067  18169.761557     5.376793   \n",
       "184                   0.531286   145.546529  17995.552545     5.825308   \n",
       "185                   0.928766    30.900895   8541.118877     1.511281   \n",
       "186                   0.688725   151.374337  31418.112874     5.162098   \n",
       "187                   0.404178   233.767679  18299.467171     7.301754   \n",
       "188                   0.908587    32.436979   9408.799500     1.552231   \n",
       "189                   0.883038    46.206624  10569.324269     2.183957   \n",
       "190                   0.658985   198.008494  30455.034760     5.977753   \n",
       "191                   0.420295   237.118255  22272.510027     7.397180   \n",
       "192                   0.929646    26.289397   6936.353138     1.366241   \n",
       "193                   0.874884    57.013833  14716.044680     2.389257   \n",
       "194                   0.895989    43.435683  11666.842094     2.002402   \n",
       "195                   0.877984    60.466947  17786.983314     2.283116   \n",
       "196                   0.566768   200.648778  29721.822014     5.979531   \n",
       "197                   0.577856   103.310454   4319.468789     6.757758   \n",
       "198                   0.573776   196.124179  23134.684474     6.207205   \n",
       "199                   0.599432   128.114749  18789.211456     4.912750   \n",
       "200                   0.921410    27.683495   7127.577188     1.515934   \n",
       "201                   0.865713    55.309109  13693.966084     2.409132   \n",
       "\n",
       "       entropy  difference variance     ...      info_corr  \\\n",
       "182   7.304616             0.001173     ...      -0.527975   \n",
       "183   6.793665             0.001711     ...      -0.591206   \n",
       "184   8.031944             0.000964     ...      -0.450169   \n",
       "185   1.812599             0.003550     ...      -0.669718   \n",
       "186   6.603945             0.001497     ...      -0.577850   \n",
       "187  10.246600             0.000536     ...      -0.417823   \n",
       "188   1.978297             0.003104     ...      -0.592231   \n",
       "189   2.708647             0.002790     ...      -0.617529   \n",
       "190   7.546238             0.001335     ...      -0.582778   \n",
       "191  10.134563             0.000572     ...      -0.458772   \n",
       "192   1.678061             0.003232     ...      -0.637695   \n",
       "193   2.962654             0.002748     ...      -0.622024   \n",
       "194   2.469971             0.002945     ...      -0.632487   \n",
       "195   2.834027             0.002828     ...      -0.617860   \n",
       "196   7.931707             0.001038     ...      -0.507896   \n",
       "197   8.729105             0.001050     ...      -0.523998   \n",
       "198   8.071277             0.001130     ...      -0.533876   \n",
       "199   6.854427             0.001165     ...      -0.429480   \n",
       "200   1.856504             0.003492     ...      -0.640145   \n",
       "201   3.005656             0.003102     ...      -0.614612   \n",
       "\n",
       "     maximal_corr_coeff     mean_B      mean_G      mean_R      std_B  \\\n",
       "182            0.997275  24.334641   94.499355   54.225159  41.756239   \n",
       "183            0.998274  38.379612   65.333393   59.050583  46.733073   \n",
       "184            0.995106  79.750870   93.388336   28.942642  74.961494   \n",
       "185            0.915109  16.005070   21.314579    3.576118  48.680908   \n",
       "186            0.997585  24.964520   87.532627   71.131737  59.350869   \n",
       "187            0.997454  27.689655  144.590858   95.801785  47.251831   \n",
       "188            0.900063  15.597744   19.756485    9.349380  46.795882   \n",
       "189            0.954167  22.975254   29.661224   10.041504  51.726987   \n",
       "190            0.998951  74.070999  109.381493   87.345341  74.873640   \n",
       "191            0.998695  29.388966  141.190071  107.218483  52.567308   \n",
       "192            0.889809  15.375862   18.196686    2.246880  49.031662   \n",
       "193            0.964616  30.256279   39.078838    6.807224  66.388570   \n",
       "194            0.947141  23.631935   30.025379    4.466053  60.617565   \n",
       "195            0.959227  22.772503   33.340370   26.682697  53.953452   \n",
       "196            0.997553  54.330463  119.518723   79.261734  68.131779   \n",
       "197            0.998881  35.178432   52.905010   54.959171  27.326199   \n",
       "198            0.998546  54.409065  118.513771   73.734535  66.565131   \n",
       "199            0.987966  23.898781   86.202984   35.382290  44.373544   \n",
       "200            0.908212  15.858822   19.659817    1.515675  50.281453   \n",
       "201            0.964397  21.811867   34.595039   15.985023  46.840741   \n",
       "\n",
       "          std_G      std_R     area   perimeter  \n",
       "182   92.422277  56.412872      5.5    9.071068  \n",
       "183   71.787567  68.684190      5.5   12.242641  \n",
       "184   84.473642  37.316142      0.5    8.242641  \n",
       "185   62.979935  18.673438      0.0    0.000000  \n",
       "186  100.544815  86.047213      2.0    5.656854  \n",
       "187   80.248106  63.827009      2.0    5.656854  \n",
       "188   58.779602  31.145390     99.5   53.556349  \n",
       "189   65.063372  29.985131      0.0    0.000000  \n",
       "190   95.165669  78.769876     10.0   12.485281  \n",
       "191   85.176159  72.846905      2.0    5.656854  \n",
       "192   57.354588  14.433809      2.0    5.656854  \n",
       "193   82.963680  26.472614      0.0    0.000000  \n",
       "194   74.391924  21.000358      2.0    5.656854  \n",
       "195   73.180149  59.572962      2.0    5.656854  \n",
       "196  101.136027  70.536433      2.0    5.656854  \n",
       "197   33.259695  36.639568     23.5   43.213203  \n",
       "198   90.355411  60.412988      2.0    5.656854  \n",
       "199   89.599111  48.247114      2.0    5.656854  \n",
       "200   60.100835   9.040244  11927.0  851.033612  \n",
       "201   72.178082  43.275999      0.5    3.414214  \n",
       "\n",
       "[20 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file[182:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182    0\n",
       "183    3\n",
       "184    3\n",
       "185    0\n",
       "186    0\n",
       "187    0\n",
       "188    0\n",
       "189    0\n",
       "190    2\n",
       "191    0\n",
       "192    0\n",
       "193    0\n",
       "194    0\n",
       "195    2\n",
       "196    0\n",
       "197    1\n",
       "198    0\n",
       "199    0\n",
       "200    0\n",
       "201    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mylabel[182:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard = preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.618812\n",
       "std        1.153943\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        0.000000\n",
       "max        3.000000\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mylabel.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.449989\n",
       "std        0.272493\n",
       "min        0.007383\n",
       "25%        0.164645\n",
       "50%        0.555137\n",
       "75%        0.681422\n",
       "max        0.857570\n",
       "Name: energy, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['energy'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ln-2/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "my_file['energy'] = (my_file['energy'] - my_file['energy'].min())/(my_file['energy'].max() - my_file['energy'].min()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.520599\n",
       "std        0.320510\n",
       "min        0.000000\n",
       "25%        0.184974\n",
       "50%        0.644275\n",
       "75%        0.792813\n",
       "max        1.000000\n",
       "Name: energy, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['energy'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean      65.700426\n",
       "std       42.120548\n",
       "min       20.559969\n",
       "25%       36.367697\n",
       "50%       50.444148\n",
       "75%       79.971658\n",
       "max      238.228420\n",
       "Name: contrast, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['contrast'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ln-2/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "my_file['contrast'] = (my_file['contrast'] - my_file['contrast'].min())/(my_file['contrast'].max() - my_file['contrast'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.207382\n",
       "std        0.193508\n",
       "min        0.000000\n",
       "25%        0.072623\n",
       "50%        0.137292\n",
       "75%        0.272946\n",
       "max        1.000000\n",
       "Name: contrast, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['contrast'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.990490\n",
       "std        0.005369\n",
       "min        0.959792\n",
       "25%        0.988503\n",
       "50%        0.991810\n",
       "75%        0.994156\n",
       "max        0.997575\n",
       "Name: correlation, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['correlation'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file = my_file.drop('correlation', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      202.000000\n",
       "mean      3757.872814\n",
       "std       1790.173709\n",
       "min        870.935814\n",
       "25%       2465.082402\n",
       "50%       3499.463468\n",
       "75%       4752.818218\n",
       "max      10266.490134\n",
       "Name: variance, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['variance'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file['variance'] = (my_file['variance'] - my_file['variance'].min())/(my_file['variance'].max() - my_file['variance'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.307266\n",
       "std        0.190534\n",
       "min        0.000000\n",
       "25%        0.169670\n",
       "50%        0.279763\n",
       "75%        0.413162\n",
       "max        1.000000\n",
       "Name: variance, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['variance'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.748944\n",
       "std        0.169738\n",
       "min        0.316277\n",
       "25%        0.598432\n",
       "50%        0.837668\n",
       "75%        0.888959\n",
       "max        0.948041\n",
       "Name: inverse difference moment, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['inverse difference moment'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file['inverse difference moment'] = (my_file['inverse difference moment'] - my_file['inverse difference moment'].min())/(my_file['inverse difference moment'].max() - my_file['inverse difference moment'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.684856\n",
       "std        0.268673\n",
       "min        0.000000\n",
       "25%        0.446615\n",
       "50%        0.825293\n",
       "75%        0.906481\n",
       "max        1.000000\n",
       "Name: inverse difference moment, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['inverse difference moment'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean      97.614647\n",
       "std       71.928711\n",
       "min       16.617906\n",
       "25%       42.179866\n",
       "50%       62.632733\n",
       "75%      148.719413\n",
       "max      286.685535\n",
       "Name: sum average, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['sum average'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file['sum average'] = (my_file['sum average'] - my_file['sum average'].min())/(my_file['sum average'].max() - my_file['sum average'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.299913\n",
       "std        0.266336\n",
       "min        0.000000\n",
       "25%        0.094650\n",
       "50%        0.170383\n",
       "75%        0.489142\n",
       "max        1.000000\n",
       "Name: sum average, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['sum average'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      202.000000\n",
       "mean     14965.790830\n",
       "std       7138.479236\n",
       "min       3457.902315\n",
       "25%       9818.651383\n",
       "50%      13942.149590\n",
       "75%      18848.886987\n",
       "max      40955.804666\n",
       "Name: sum variance, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['sum variance'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file['sum variance'] = (my_file['sum variance'] - my_file['sum variance'].min())/(my_file['sum variance'].max() - my_file['sum variance'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.306894\n",
       "std        0.190370\n",
       "min        0.000000\n",
       "25%        0.169629\n",
       "50%        0.279596\n",
       "75%        0.410449\n",
       "max        1.000000\n",
       "Name: sum variance, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['sum variance'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       3.750295\n",
       "std        2.045991\n",
       "min        0.978486\n",
       "25%        2.049140\n",
       "50%        2.863879\n",
       "75%        5.662932\n",
       "max        7.957388\n",
       "Name: sum entropy, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['sum entropy'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file['sum entropy'] = (my_file['sum entropy'] - my_file['sum entropy'].min())/(my_file['sum entropy'].max() - my_file['sum entropy'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.397170\n",
       "std        0.293168\n",
       "min        0.000000\n",
       "25%        0.153413\n",
       "50%        0.270156\n",
       "75%        0.671230\n",
       "max        1.000000\n",
       "Name: sum entropy, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['sum entropy'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       4.902418\n",
       "std        2.832211\n",
       "min        1.210341\n",
       "25%        2.547233\n",
       "50%        3.492737\n",
       "75%        7.477470\n",
       "max       11.349265\n",
       "Name: entropy, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['entropy'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file['entropy'] = (my_file['entropy'] - my_file['entropy'].min())/(my_file['entropy'].max() - my_file['entropy'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.364149\n",
       "std        0.279340\n",
       "min        0.000000\n",
       "25%        0.131857\n",
       "50%        0.225112\n",
       "75%        0.618126\n",
       "max        1.000000\n",
       "Name: entropy, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['entropy'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.002162\n",
       "std        0.000972\n",
       "min        0.000383\n",
       "25%        0.001173\n",
       "50%        0.002487\n",
       "75%        0.002906\n",
       "max        0.004024\n",
       "Name: difference variance, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['difference variance'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file['difference variance'] = (my_file['difference variance'] - my_file['difference variance'].min())/(my_file['difference variance'].max() - my_file['difference variance'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.488644\n",
       "std        0.267015\n",
       "min        0.000000\n",
       "25%        0.216942\n",
       "50%        0.577768\n",
       "75%        0.692815\n",
       "max        1.000000\n",
       "Name: difference variance, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['difference variance'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       1.844972\n",
       "std        0.914575\n",
       "min        0.592005\n",
       "25%        1.076601\n",
       "50%        1.436997\n",
       "75%        2.581673\n",
       "max        4.194239\n",
       "Name: difference entropy, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['difference entropy'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file['difference entropy'] = (my_file['difference entropy'] - my_file['difference entropy'].min())/(my_file['difference entropy'].max() - my_file['difference entropy'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.347831\n",
       "std        0.253891\n",
       "min        0.000000\n",
       "25%        0.134527\n",
       "50%        0.234574\n",
       "75%        0.552343\n",
       "max        1.000000\n",
       "Name: difference entropy, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['difference entropy'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean      -0.566764\n",
       "std        0.074023\n",
       "min       -0.689997\n",
       "25%       -0.620178\n",
       "50%       -0.587485\n",
       "75%       -0.518922\n",
       "max       -0.324361\n",
       "Name: info_corr, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['info_corr'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file = my_file.drop('info_corr', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.964144\n",
       "std        0.039334\n",
       "min        0.823801\n",
       "25%        0.946784\n",
       "50%        0.974496\n",
       "75%        0.996552\n",
       "max        0.999570\n",
       "Name: maximal_corr_coeff, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['maximal_corr_coeff'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file = my_file.drop('maximal_corr_coeff', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean      28.971899\n",
       "std       15.828901\n",
       "min        3.971340\n",
       "25%       18.062471\n",
       "50%       24.345436\n",
       "75%       35.163239\n",
       "max       85.481976\n",
       "Name: mean_B, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['mean_B'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file['mean_B'] = (my_file['mean_B'] - my_file['mean_B'].min())/(my_file['mean_B'].max() - my_file['mean_B'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.306715\n",
       "std        0.194194\n",
       "min        0.000000\n",
       "25%        0.172875\n",
       "50%        0.249956\n",
       "75%        0.382673\n",
       "max        1.000000\n",
       "Name: mean_B, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['mean_B'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean      59.556504\n",
       "std       42.064186\n",
       "min       11.144627\n",
       "25%       26.601417\n",
       "50%       39.483566\n",
       "75%       92.039097\n",
       "max      168.650845\n",
       "Name: mean_G, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['mean_G'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file['mean_G'] = (my_file['mean_G'] - my_file['mean_G'].min())/(my_file['mean_G'].max() - my_file['mean_G'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.307365\n",
       "std        0.267064\n",
       "min        0.000000\n",
       "25%        0.098134\n",
       "50%        0.179923\n",
       "75%        0.513595\n",
       "max        1.000000\n",
       "Name: mean_G, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['mean_G'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean      34.826111\n",
       "std       35.821593\n",
       "min        0.762230\n",
       "25%        6.179100\n",
       "50%       17.057322\n",
       "75%       66.565775\n",
       "max      130.789558\n",
       "Name: mean_R, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['mean_R'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file['mean_R'] = (my_file['mean_R'] - my_file['mean_R'].min())/(my_file['mean_R'].max() - my_file['mean_R'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.261975\n",
       "std        0.275493\n",
       "min        0.000000\n",
       "25%        0.041659\n",
       "50%        0.125321\n",
       "75%        0.506075\n",
       "max        1.000000\n",
       "Name: mean_R, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['mean_R'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean      51.996351\n",
       "std       14.095391\n",
       "min       13.611756\n",
       "25%       43.921763\n",
       "50%       51.867219\n",
       "75%       61.865402\n",
       "max       92.524352\n",
       "Name: std_B, dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['std_B'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file['std_B'] = (my_file['std_B'] - my_file['std_B'].min())/(my_file['std_B'].max() - my_file['std_B'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.486419\n",
       "std        0.178620\n",
       "min        0.000000\n",
       "25%        0.384096\n",
       "50%        0.484783\n",
       "75%        0.611482\n",
       "max        1.000000\n",
       "Name: std_B, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['std_B'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean      72.999904\n",
       "std       15.286676\n",
       "min       30.477614\n",
       "25%       63.136441\n",
       "50%       73.541901\n",
       "75%       84.413857\n",
       "max      117.730371\n",
       "Name: std_G, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['std_G'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file['std_G'] = (my_file['std_G'] - my_file['std_G'].min())/(my_file['std_G'].max() - my_file['std_G'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.487346\n",
       "std        0.175200\n",
       "min        0.000000\n",
       "25%        0.374301\n",
       "50%        0.493558\n",
       "75%        0.618161\n",
       "max        1.000000\n",
       "Name: std_G, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['std_G'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean      41.956997\n",
       "std       22.791601\n",
       "min        5.189059\n",
       "25%       21.951760\n",
       "50%       39.402918\n",
       "75%       60.352599\n",
       "max       99.574606\n",
       "Name: std_R, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['std_R'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file['std_R'] = (my_file['std_R'] - my_file['std_R'].min())/(my_file['std_R'].max() - my_file['std_R'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.389551\n",
       "std        0.241473\n",
       "min        0.000000\n",
       "25%        0.177598\n",
       "50%        0.362490\n",
       "75%        0.584449\n",
       "max        1.000000\n",
       "Name: std_R, dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['std_R'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      202.000000\n",
       "mean        69.366337\n",
       "std        839.146288\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          2.000000\n",
       "75%          6.000000\n",
       "max      11927.000000\n",
       "Name: area, dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['area'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file = my_file.drop('area', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean      15.348125\n",
       "std       62.464979\n",
       "min        0.000000\n",
       "25%        3.560660\n",
       "50%        5.656854\n",
       "75%       11.071068\n",
       "max      851.033612\n",
       "Name: perimeter, dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['perimeter'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file['perimeter'] = my_file['perimeter'].map({0.000000: my_file['perimeter'].mean()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file = my_file.drop('perimeter', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy</th>\n",
       "      <th>contrast</th>\n",
       "      <th>variance</th>\n",
       "      <th>inverse difference moment</th>\n",
       "      <th>sum average</th>\n",
       "      <th>sum variance</th>\n",
       "      <th>sum entropy</th>\n",
       "      <th>entropy</th>\n",
       "      <th>difference variance</th>\n",
       "      <th>difference entropy</th>\n",
       "      <th>mean_B</th>\n",
       "      <th>mean_G</th>\n",
       "      <th>mean_R</th>\n",
       "      <th>std_B</th>\n",
       "      <th>std_G</th>\n",
       "      <th>std_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.169224</td>\n",
       "      <td>0.289995</td>\n",
       "      <td>0.503613</td>\n",
       "      <td>0.328835</td>\n",
       "      <td>0.554133</td>\n",
       "      <td>0.503203</td>\n",
       "      <td>0.699561</td>\n",
       "      <td>0.680072</td>\n",
       "      <td>0.143376</td>\n",
       "      <td>0.709940</td>\n",
       "      <td>0.313805</td>\n",
       "      <td>0.528787</td>\n",
       "      <td>0.614273</td>\n",
       "      <td>0.304604</td>\n",
       "      <td>0.615009</td>\n",
       "      <td>0.737568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.816743</td>\n",
       "      <td>0.101235</td>\n",
       "      <td>0.222058</td>\n",
       "      <td>0.910721</td>\n",
       "      <td>0.092361</td>\n",
       "      <td>0.222110</td>\n",
       "      <td>0.142707</td>\n",
       "      <td>0.124576</td>\n",
       "      <td>0.695182</td>\n",
       "      <td>0.139885</td>\n",
       "      <td>0.220593</td>\n",
       "      <td>0.101461</td>\n",
       "      <td>0.053140</td>\n",
       "      <td>0.559716</td>\n",
       "      <td>0.442374</td>\n",
       "      <td>0.309818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.616307</td>\n",
       "      <td>0.174905</td>\n",
       "      <td>0.229516</td>\n",
       "      <td>0.791696</td>\n",
       "      <td>0.149270</td>\n",
       "      <td>0.229158</td>\n",
       "      <td>0.305093</td>\n",
       "      <td>0.272178</td>\n",
       "      <td>0.536824</td>\n",
       "      <td>0.286056</td>\n",
       "      <td>0.298854</td>\n",
       "      <td>0.167377</td>\n",
       "      <td>0.074775</td>\n",
       "      <td>0.539028</td>\n",
       "      <td>0.447906</td>\n",
       "      <td>0.289288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016687</td>\n",
       "      <td>0.680178</td>\n",
       "      <td>0.343683</td>\n",
       "      <td>0.133705</td>\n",
       "      <td>0.830096</td>\n",
       "      <td>0.340649</td>\n",
       "      <td>0.935801</td>\n",
       "      <td>0.905857</td>\n",
       "      <td>0.046132</td>\n",
       "      <td>0.817664</td>\n",
       "      <td>0.265694</td>\n",
       "      <td>0.874486</td>\n",
       "      <td>0.759549</td>\n",
       "      <td>0.398753</td>\n",
       "      <td>0.512621</td>\n",
       "      <td>0.594145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.144739</td>\n",
       "      <td>0.238395</td>\n",
       "      <td>0.059277</td>\n",
       "      <td>0.370087</td>\n",
       "      <td>0.252131</td>\n",
       "      <td>0.058167</td>\n",
       "      <td>0.673827</td>\n",
       "      <td>0.645537</td>\n",
       "      <td>0.162975</td>\n",
       "      <td>0.641177</td>\n",
       "      <td>0.170598</td>\n",
       "      <td>0.232265</td>\n",
       "      <td>0.307716</td>\n",
       "      <td>0.091011</td>\n",
       "      <td>0.135052</td>\n",
       "      <td>0.348236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.753275</td>\n",
       "      <td>0.026219</td>\n",
       "      <td>0.175914</td>\n",
       "      <td>0.855644</td>\n",
       "      <td>0.100871</td>\n",
       "      <td>0.176298</td>\n",
       "      <td>0.196664</td>\n",
       "      <td>0.177152</td>\n",
       "      <td>0.647691</td>\n",
       "      <td>0.198023</td>\n",
       "      <td>0.176512</td>\n",
       "      <td>0.076325</td>\n",
       "      <td>0.152918</td>\n",
       "      <td>0.394871</td>\n",
       "      <td>0.249911</td>\n",
       "      <td>0.468215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.086338</td>\n",
       "      <td>0.109834</td>\n",
       "      <td>0.002533</td>\n",
       "      <td>0.441833</td>\n",
       "      <td>0.208530</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>0.711789</td>\n",
       "      <td>0.647242</td>\n",
       "      <td>0.255335</td>\n",
       "      <td>0.552105</td>\n",
       "      <td>0.231839</td>\n",
       "      <td>0.171394</td>\n",
       "      <td>0.286421</td>\n",
       "      <td>0.087317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.297518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.719489</td>\n",
       "      <td>0.019917</td>\n",
       "      <td>0.177375</td>\n",
       "      <td>0.837457</td>\n",
       "      <td>0.111338</td>\n",
       "      <td>0.177799</td>\n",
       "      <td>0.220557</td>\n",
       "      <td>0.198897</td>\n",
       "      <td>0.622483</td>\n",
       "      <td>0.220909</td>\n",
       "      <td>0.225201</td>\n",
       "      <td>0.090681</td>\n",
       "      <td>0.143445</td>\n",
       "      <td>0.463693</td>\n",
       "      <td>0.267135</td>\n",
       "      <td>0.421028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.979866</td>\n",
       "      <td>0.065778</td>\n",
       "      <td>0.013180</td>\n",
       "      <td>0.994070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012969</td>\n",
       "      <td>0.010677</td>\n",
       "      <td>0.008506</td>\n",
       "      <td>0.847751</td>\n",
       "      <td>0.011066</td>\n",
       "      <td>0.058835</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>0.260821</td>\n",
       "      <td>0.170652</td>\n",
       "      <td>0.017506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.796203</td>\n",
       "      <td>0.177308</td>\n",
       "      <td>0.180361</td>\n",
       "      <td>0.910296</td>\n",
       "      <td>0.088612</td>\n",
       "      <td>0.179878</td>\n",
       "      <td>0.156350</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>0.687980</td>\n",
       "      <td>0.131606</td>\n",
       "      <td>0.225653</td>\n",
       "      <td>0.099282</td>\n",
       "      <td>0.044162</td>\n",
       "      <td>0.561475</td>\n",
       "      <td>0.415473</td>\n",
       "      <td>0.177397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.180932</td>\n",
       "      <td>0.239203</td>\n",
       "      <td>0.281093</td>\n",
       "      <td>0.476267</td>\n",
       "      <td>0.414113</td>\n",
       "      <td>0.280477</td>\n",
       "      <td>0.663436</td>\n",
       "      <td>0.601878</td>\n",
       "      <td>0.247823</td>\n",
       "      <td>0.536012</td>\n",
       "      <td>0.124879</td>\n",
       "      <td>0.416336</td>\n",
       "      <td>0.442787</td>\n",
       "      <td>0.188226</td>\n",
       "      <td>0.449327</td>\n",
       "      <td>0.545056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.746699</td>\n",
       "      <td>0.221874</td>\n",
       "      <td>0.172101</td>\n",
       "      <td>0.884964</td>\n",
       "      <td>0.104835</td>\n",
       "      <td>0.171341</td>\n",
       "      <td>0.186406</td>\n",
       "      <td>0.160340</td>\n",
       "      <td>0.650283</td>\n",
       "      <td>0.165443</td>\n",
       "      <td>0.211575</td>\n",
       "      <td>0.128075</td>\n",
       "      <td>0.035218</td>\n",
       "      <td>0.444714</td>\n",
       "      <td>0.439441</td>\n",
       "      <td>0.162066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.708238</td>\n",
       "      <td>0.039289</td>\n",
       "      <td>0.192864</td>\n",
       "      <td>0.832247</td>\n",
       "      <td>0.120533</td>\n",
       "      <td>0.193210</td>\n",
       "      <td>0.226917</td>\n",
       "      <td>0.204334</td>\n",
       "      <td>0.613916</td>\n",
       "      <td>0.227441</td>\n",
       "      <td>0.196033</td>\n",
       "      <td>0.095771</td>\n",
       "      <td>0.170095</td>\n",
       "      <td>0.400597</td>\n",
       "      <td>0.273870</td>\n",
       "      <td>0.480086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.759275</td>\n",
       "      <td>0.117672</td>\n",
       "      <td>0.348243</td>\n",
       "      <td>0.859624</td>\n",
       "      <td>0.151281</td>\n",
       "      <td>0.348484</td>\n",
       "      <td>0.186493</td>\n",
       "      <td>0.168041</td>\n",
       "      <td>0.682123</td>\n",
       "      <td>0.198418</td>\n",
       "      <td>0.239835</td>\n",
       "      <td>0.152197</td>\n",
       "      <td>0.131952</td>\n",
       "      <td>0.500756</td>\n",
       "      <td>0.535543</td>\n",
       "      <td>0.451087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.734341</td>\n",
       "      <td>0.212244</td>\n",
       "      <td>0.184847</td>\n",
       "      <td>0.876952</td>\n",
       "      <td>0.112303</td>\n",
       "      <td>0.184171</td>\n",
       "      <td>0.197792</td>\n",
       "      <td>0.170491</td>\n",
       "      <td>0.645881</td>\n",
       "      <td>0.175686</td>\n",
       "      <td>0.223086</td>\n",
       "      <td>0.136636</td>\n",
       "      <td>0.037988</td>\n",
       "      <td>0.459744</td>\n",
       "      <td>0.455840</td>\n",
       "      <td>0.174449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.032162</td>\n",
       "      <td>0.644137</td>\n",
       "      <td>0.395792</td>\n",
       "      <td>0.149959</td>\n",
       "      <td>0.784006</td>\n",
       "      <td>0.393083</td>\n",
       "      <td>0.905366</td>\n",
       "      <td>0.885406</td>\n",
       "      <td>0.045673</td>\n",
       "      <td>0.838216</td>\n",
       "      <td>0.267264</td>\n",
       "      <td>0.825950</td>\n",
       "      <td>0.716113</td>\n",
       "      <td>0.410896</td>\n",
       "      <td>0.566080</td>\n",
       "      <td>0.619856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.929437</td>\n",
       "      <td>0.030788</td>\n",
       "      <td>0.039176</td>\n",
       "      <td>0.961233</td>\n",
       "      <td>0.011858</td>\n",
       "      <td>0.039227</td>\n",
       "      <td>0.054511</td>\n",
       "      <td>0.049274</td>\n",
       "      <td>0.782016</td>\n",
       "      <td>0.066333</td>\n",
       "      <td>0.081997</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.026549</td>\n",
       "      <td>0.312601</td>\n",
       "      <td>0.146925</td>\n",
       "      <td>0.165443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.309006</td>\n",
       "      <td>0.181983</td>\n",
       "      <td>0.588884</td>\n",
       "      <td>0.500712</td>\n",
       "      <td>0.470738</td>\n",
       "      <td>0.589292</td>\n",
       "      <td>0.534461</td>\n",
       "      <td>0.512072</td>\n",
       "      <td>0.282558</td>\n",
       "      <td>0.563096</td>\n",
       "      <td>0.413763</td>\n",
       "      <td>0.430469</td>\n",
       "      <td>0.534928</td>\n",
       "      <td>0.399168</td>\n",
       "      <td>0.659911</td>\n",
       "      <td>0.783451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.776195</td>\n",
       "      <td>0.025340</td>\n",
       "      <td>0.168686</td>\n",
       "      <td>0.868081</td>\n",
       "      <td>0.093564</td>\n",
       "      <td>0.169059</td>\n",
       "      <td>0.178687</td>\n",
       "      <td>0.161216</td>\n",
       "      <td>0.662719</td>\n",
       "      <td>0.182666</td>\n",
       "      <td>0.167726</td>\n",
       "      <td>0.069320</td>\n",
       "      <td>0.146390</td>\n",
       "      <td>0.389611</td>\n",
       "      <td>0.240168</td>\n",
       "      <td>0.463173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.910705</td>\n",
       "      <td>0.047852</td>\n",
       "      <td>0.143099</td>\n",
       "      <td>0.963078</td>\n",
       "      <td>0.052286</td>\n",
       "      <td>0.143284</td>\n",
       "      <td>0.064152</td>\n",
       "      <td>0.054446</td>\n",
       "      <td>0.771295</td>\n",
       "      <td>0.061737</td>\n",
       "      <td>0.169317</td>\n",
       "      <td>0.058562</td>\n",
       "      <td>0.028645</td>\n",
       "      <td>0.516078</td>\n",
       "      <td>0.360929</td>\n",
       "      <td>0.163771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005193</td>\n",
       "      <td>0.024192</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.024357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.868280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011742</td>\n",
       "      <td>0.313507</td>\n",
       "      <td>0.153461</td>\n",
       "      <td>0.076231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.638123</td>\n",
       "      <td>0.147780</td>\n",
       "      <td>0.304033</td>\n",
       "      <td>0.879514</td>\n",
       "      <td>0.184535</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.270962</td>\n",
       "      <td>0.214235</td>\n",
       "      <td>0.748563</td>\n",
       "      <td>0.149985</td>\n",
       "      <td>0.398479</td>\n",
       "      <td>0.210074</td>\n",
       "      <td>0.071560</td>\n",
       "      <td>0.682240</td>\n",
       "      <td>0.573719</td>\n",
       "      <td>0.182825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.265679</td>\n",
       "      <td>0.155492</td>\n",
       "      <td>0.768694</td>\n",
       "      <td>0.525848</td>\n",
       "      <td>0.570201</td>\n",
       "      <td>0.769660</td>\n",
       "      <td>0.598892</td>\n",
       "      <td>0.547214</td>\n",
       "      <td>0.264344</td>\n",
       "      <td>0.526277</td>\n",
       "      <td>0.652788</td>\n",
       "      <td>0.494717</td>\n",
       "      <td>0.669729</td>\n",
       "      <td>0.627026</td>\n",
       "      <td>0.731178</td>\n",
       "      <td>0.923630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.701493</td>\n",
       "      <td>0.035783</td>\n",
       "      <td>0.271819</td>\n",
       "      <td>0.870198</td>\n",
       "      <td>0.136969</td>\n",
       "      <td>0.272363</td>\n",
       "      <td>0.232108</td>\n",
       "      <td>0.194935</td>\n",
       "      <td>0.624206</td>\n",
       "      <td>0.182920</td>\n",
       "      <td>0.301243</td>\n",
       "      <td>0.143018</td>\n",
       "      <td>0.089608</td>\n",
       "      <td>0.613827</td>\n",
       "      <td>0.458148</td>\n",
       "      <td>0.387999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.037521</td>\n",
       "      <td>0.410973</td>\n",
       "      <td>0.183254</td>\n",
       "      <td>0.121111</td>\n",
       "      <td>0.565109</td>\n",
       "      <td>0.181421</td>\n",
       "      <td>0.861132</td>\n",
       "      <td>0.854264</td>\n",
       "      <td>0.037339</td>\n",
       "      <td>0.834893</td>\n",
       "      <td>0.149505</td>\n",
       "      <td>0.581961</td>\n",
       "      <td>0.565702</td>\n",
       "      <td>0.134371</td>\n",
       "      <td>0.340063</td>\n",
       "      <td>0.452158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.034828</td>\n",
       "      <td>0.858426</td>\n",
       "      <td>0.423979</td>\n",
       "      <td>0.112276</td>\n",
       "      <td>0.827759</td>\n",
       "      <td>0.420090</td>\n",
       "      <td>0.891780</td>\n",
       "      <td>0.897603</td>\n",
       "      <td>0.029799</td>\n",
       "      <td>0.899544</td>\n",
       "      <td>0.316002</td>\n",
       "      <td>0.875428</td>\n",
       "      <td>0.738687</td>\n",
       "      <td>0.418568</td>\n",
       "      <td>0.599603</td>\n",
       "      <td>0.630198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.475351</td>\n",
       "      <td>0.113515</td>\n",
       "      <td>0.343857</td>\n",
       "      <td>0.629219</td>\n",
       "      <td>0.271461</td>\n",
       "      <td>0.344112</td>\n",
       "      <td>0.381336</td>\n",
       "      <td>0.372120</td>\n",
       "      <td>0.469400</td>\n",
       "      <td>0.457843</td>\n",
       "      <td>0.414242</td>\n",
       "      <td>0.259100</td>\n",
       "      <td>0.252296</td>\n",
       "      <td>0.540759</td>\n",
       "      <td>0.500993</td>\n",
       "      <td>0.459192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.582977</td>\n",
       "      <td>0.247465</td>\n",
       "      <td>0.263660</td>\n",
       "      <td>0.823804</td>\n",
       "      <td>0.173158</td>\n",
       "      <td>0.262957</td>\n",
       "      <td>0.323813</td>\n",
       "      <td>0.270001</td>\n",
       "      <td>0.550242</td>\n",
       "      <td>0.233951</td>\n",
       "      <td>0.389343</td>\n",
       "      <td>0.207296</td>\n",
       "      <td>0.041097</td>\n",
       "      <td>0.677191</td>\n",
       "      <td>0.551749</td>\n",
       "      <td>0.188445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.052330</td>\n",
       "      <td>0.463148</td>\n",
       "      <td>0.603172</td>\n",
       "      <td>0.239494</td>\n",
       "      <td>0.865652</td>\n",
       "      <td>0.601981</td>\n",
       "      <td>0.887251</td>\n",
       "      <td>0.830420</td>\n",
       "      <td>0.083958</td>\n",
       "      <td>0.725498</td>\n",
       "      <td>0.742508</td>\n",
       "      <td>0.841126</td>\n",
       "      <td>0.848570</td>\n",
       "      <td>0.533037</td>\n",
       "      <td>0.695461</td>\n",
       "      <td>0.743058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.079862</td>\n",
       "      <td>0.585364</td>\n",
       "      <td>0.747049</td>\n",
       "      <td>0.282110</td>\n",
       "      <td>0.781438</td>\n",
       "      <td>0.745472</td>\n",
       "      <td>0.830760</td>\n",
       "      <td>0.789128</td>\n",
       "      <td>0.099432</td>\n",
       "      <td>0.764286</td>\n",
       "      <td>0.632374</td>\n",
       "      <td>0.770294</td>\n",
       "      <td>0.750642</td>\n",
       "      <td>0.844418</td>\n",
       "      <td>0.764848</td>\n",
       "      <td>0.864680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.673622</td>\n",
       "      <td>0.236813</td>\n",
       "      <td>0.206139</td>\n",
       "      <td>0.811437</td>\n",
       "      <td>0.139913</td>\n",
       "      <td>0.205368</td>\n",
       "      <td>0.233830</td>\n",
       "      <td>0.216615</td>\n",
       "      <td>0.573074</td>\n",
       "      <td>0.271532</td>\n",
       "      <td>0.141284</td>\n",
       "      <td>0.169710</td>\n",
       "      <td>0.074488</td>\n",
       "      <td>0.268916</td>\n",
       "      <td>0.480453</td>\n",
       "      <td>0.260380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.880415</td>\n",
       "      <td>0.051604</td>\n",
       "      <td>0.117267</td>\n",
       "      <td>0.942785</td>\n",
       "      <td>0.054652</td>\n",
       "      <td>0.117372</td>\n",
       "      <td>0.087996</td>\n",
       "      <td>0.076518</td>\n",
       "      <td>0.742533</td>\n",
       "      <td>0.085906</td>\n",
       "      <td>0.148910</td>\n",
       "      <td>0.057173</td>\n",
       "      <td>0.045037</td>\n",
       "      <td>0.411167</td>\n",
       "      <td>0.300986</td>\n",
       "      <td>0.174222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.801684</td>\n",
       "      <td>0.024262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.915328</td>\n",
       "      <td>0.026728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132504</td>\n",
       "      <td>0.113929</td>\n",
       "      <td>0.760796</td>\n",
       "      <td>0.122401</td>\n",
       "      <td>0.086998</td>\n",
       "      <td>0.039078</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.192364</td>\n",
       "      <td>0.138401</td>\n",
       "      <td>0.026030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.811920</td>\n",
       "      <td>0.410706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.901127</td>\n",
       "      <td>0.407058</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.970119</td>\n",
       "      <td>0.728078</td>\n",
       "      <td>0.891336</td>\n",
       "      <td>0.855435</td>\n",
       "      <td>0.772312</td>\n",
       "      <td>0.459785</td>\n",
       "      <td>0.682910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.843534</td>\n",
       "      <td>0.069507</td>\n",
       "      <td>0.259898</td>\n",
       "      <td>0.921249</td>\n",
       "      <td>0.099657</td>\n",
       "      <td>0.260220</td>\n",
       "      <td>0.122099</td>\n",
       "      <td>0.107735</td>\n",
       "      <td>0.710995</td>\n",
       "      <td>0.124364</td>\n",
       "      <td>0.240255</td>\n",
       "      <td>0.108289</td>\n",
       "      <td>0.057490</td>\n",
       "      <td>0.613340</td>\n",
       "      <td>0.486935</td>\n",
       "      <td>0.315547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.140590</td>\n",
       "      <td>0.316887</td>\n",
       "      <td>0.334944</td>\n",
       "      <td>0.444251</td>\n",
       "      <td>0.499718</td>\n",
       "      <td>0.333999</td>\n",
       "      <td>0.712943</td>\n",
       "      <td>0.642178</td>\n",
       "      <td>0.214201</td>\n",
       "      <td>0.548127</td>\n",
       "      <td>0.127916</td>\n",
       "      <td>0.502639</td>\n",
       "      <td>0.532559</td>\n",
       "      <td>0.197047</td>\n",
       "      <td>0.506081</td>\n",
       "      <td>0.593324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.032007</td>\n",
       "      <td>0.147267</td>\n",
       "      <td>0.970536</td>\n",
       "      <td>0.051183</td>\n",
       "      <td>0.147553</td>\n",
       "      <td>0.064473</td>\n",
       "      <td>0.052746</td>\n",
       "      <td>0.782980</td>\n",
       "      <td>0.050377</td>\n",
       "      <td>0.165452</td>\n",
       "      <td>0.060708</td>\n",
       "      <td>0.020644</td>\n",
       "      <td>0.521208</td>\n",
       "      <td>0.386048</td>\n",
       "      <td>0.144966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.848981</td>\n",
       "      <td>0.071954</td>\n",
       "      <td>0.172494</td>\n",
       "      <td>0.923166</td>\n",
       "      <td>0.078513</td>\n",
       "      <td>0.172605</td>\n",
       "      <td>0.111210</td>\n",
       "      <td>0.097702</td>\n",
       "      <td>0.719215</td>\n",
       "      <td>0.113572</td>\n",
       "      <td>0.198191</td>\n",
       "      <td>0.069739</td>\n",
       "      <td>0.085985</td>\n",
       "      <td>0.495080</td>\n",
       "      <td>0.312069</td>\n",
       "      <td>0.325535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.954383</td>\n",
       "      <td>0.054051</td>\n",
       "      <td>0.066594</td>\n",
       "      <td>0.986426</td>\n",
       "      <td>0.021105</td>\n",
       "      <td>0.066571</td>\n",
       "      <td>0.033350</td>\n",
       "      <td>0.026036</td>\n",
       "      <td>0.817499</td>\n",
       "      <td>0.023627</td>\n",
       "      <td>0.112506</td>\n",
       "      <td>0.026828</td>\n",
       "      <td>0.009726</td>\n",
       "      <td>0.414651</td>\n",
       "      <td>0.261029</td>\n",
       "      <td>0.081890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.587120</td>\n",
       "      <td>0.191977</td>\n",
       "      <td>0.251218</td>\n",
       "      <td>0.780205</td>\n",
       "      <td>0.180097</td>\n",
       "      <td>0.250809</td>\n",
       "      <td>0.302527</td>\n",
       "      <td>0.269404</td>\n",
       "      <td>0.525626</td>\n",
       "      <td>0.294182</td>\n",
       "      <td>0.265157</td>\n",
       "      <td>0.199069</td>\n",
       "      <td>0.114448</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.470486</td>\n",
       "      <td>0.359641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.217640</td>\n",
       "      <td>0.240444</td>\n",
       "      <td>0.485385</td>\n",
       "      <td>0.472427</td>\n",
       "      <td>0.491405</td>\n",
       "      <td>0.485222</td>\n",
       "      <td>0.656693</td>\n",
       "      <td>0.601077</td>\n",
       "      <td>0.216915</td>\n",
       "      <td>0.567732</td>\n",
       "      <td>0.249824</td>\n",
       "      <td>0.529215</td>\n",
       "      <td>0.411167</td>\n",
       "      <td>0.356654</td>\n",
       "      <td>0.709945</td>\n",
       "      <td>0.542708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.260285</td>\n",
       "      <td>0.006904</td>\n",
       "      <td>0.391357</td>\n",
       "      <td>0.582404</td>\n",
       "      <td>0.386956</td>\n",
       "      <td>0.392338</td>\n",
       "      <td>0.630229</td>\n",
       "      <td>0.550682</td>\n",
       "      <td>0.364547</td>\n",
       "      <td>0.446804</td>\n",
       "      <td>0.422132</td>\n",
       "      <td>0.344042</td>\n",
       "      <td>0.448278</td>\n",
       "      <td>0.419722</td>\n",
       "      <td>0.473452</td>\n",
       "      <td>0.672721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.171980</td>\n",
       "      <td>0.197873</td>\n",
       "      <td>0.387828</td>\n",
       "      <td>0.340331</td>\n",
       "      <td>0.477394</td>\n",
       "      <td>0.387692</td>\n",
       "      <td>0.694496</td>\n",
       "      <td>0.672813</td>\n",
       "      <td>0.159429</td>\n",
       "      <td>0.697615</td>\n",
       "      <td>0.929689</td>\n",
       "      <td>0.522162</td>\n",
       "      <td>0.216727</td>\n",
       "      <td>0.777439</td>\n",
       "      <td>0.618846</td>\n",
       "      <td>0.340381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.896178</td>\n",
       "      <td>0.063057</td>\n",
       "      <td>0.135481</td>\n",
       "      <td>0.969489</td>\n",
       "      <td>0.052887</td>\n",
       "      <td>0.135560</td>\n",
       "      <td>0.076344</td>\n",
       "      <td>0.059401</td>\n",
       "      <td>0.869805</td>\n",
       "      <td>0.047101</td>\n",
       "      <td>0.147634</td>\n",
       "      <td>0.064569</td>\n",
       "      <td>0.021641</td>\n",
       "      <td>0.444405</td>\n",
       "      <td>0.372508</td>\n",
       "      <td>0.142865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.293539</td>\n",
       "      <td>0.250586</td>\n",
       "      <td>0.745285</td>\n",
       "      <td>0.589536</td>\n",
       "      <td>0.498973</td>\n",
       "      <td>0.745647</td>\n",
       "      <td>0.599466</td>\n",
       "      <td>0.531970</td>\n",
       "      <td>0.305995</td>\n",
       "      <td>0.482356</td>\n",
       "      <td>0.257551</td>\n",
       "      <td>0.484984</td>\n",
       "      <td>0.541190</td>\n",
       "      <td>0.579617</td>\n",
       "      <td>0.803037</td>\n",
       "      <td>0.856679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.031995</td>\n",
       "      <td>0.874942</td>\n",
       "      <td>0.399836</td>\n",
       "      <td>0.139135</td>\n",
       "      <td>0.804057</td>\n",
       "      <td>0.395797</td>\n",
       "      <td>0.906055</td>\n",
       "      <td>0.891244</td>\n",
       "      <td>0.041939</td>\n",
       "      <td>0.852812</td>\n",
       "      <td>0.290984</td>\n",
       "      <td>0.847244</td>\n",
       "      <td>0.730920</td>\n",
       "      <td>0.426295</td>\n",
       "      <td>0.570417</td>\n",
       "      <td>0.621260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.899593</td>\n",
       "      <td>0.053779</td>\n",
       "      <td>0.158514</td>\n",
       "      <td>0.937548</td>\n",
       "      <td>0.058574</td>\n",
       "      <td>0.158699</td>\n",
       "      <td>0.082211</td>\n",
       "      <td>0.075743</td>\n",
       "      <td>0.747268</td>\n",
       "      <td>0.098770</td>\n",
       "      <td>0.142637</td>\n",
       "      <td>0.054676</td>\n",
       "      <td>0.066041</td>\n",
       "      <td>0.420517</td>\n",
       "      <td>0.324368</td>\n",
       "      <td>0.275003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.758134</td>\n",
       "      <td>0.109442</td>\n",
       "      <td>0.189716</td>\n",
       "      <td>0.897108</td>\n",
       "      <td>0.109560</td>\n",
       "      <td>0.189649</td>\n",
       "      <td>0.172731</td>\n",
       "      <td>0.147778</td>\n",
       "      <td>0.661098</td>\n",
       "      <td>0.153561</td>\n",
       "      <td>0.233146</td>\n",
       "      <td>0.117561</td>\n",
       "      <td>0.071364</td>\n",
       "      <td>0.483006</td>\n",
       "      <td>0.396386</td>\n",
       "      <td>0.262710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.163818</td>\n",
       "      <td>0.135848</td>\n",
       "      <td>0.718995</td>\n",
       "      <td>0.542462</td>\n",
       "      <td>0.671649</td>\n",
       "      <td>0.719964</td>\n",
       "      <td>0.716340</td>\n",
       "      <td>0.624908</td>\n",
       "      <td>0.261304</td>\n",
       "      <td>0.490682</td>\n",
       "      <td>0.860006</td>\n",
       "      <td>0.623702</td>\n",
       "      <td>0.665884</td>\n",
       "      <td>0.776326</td>\n",
       "      <td>0.741387</td>\n",
       "      <td>0.779577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.038905</td>\n",
       "      <td>0.586514</td>\n",
       "      <td>0.503882</td>\n",
       "      <td>0.164647</td>\n",
       "      <td>0.816463</td>\n",
       "      <td>0.501751</td>\n",
       "      <td>0.919728</td>\n",
       "      <td>0.880194</td>\n",
       "      <td>0.051927</td>\n",
       "      <td>0.808667</td>\n",
       "      <td>0.311832</td>\n",
       "      <td>0.825653</td>\n",
       "      <td>0.818722</td>\n",
       "      <td>0.493654</td>\n",
       "      <td>0.626898</td>\n",
       "      <td>0.716824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.920701</td>\n",
       "      <td>0.040314</td>\n",
       "      <td>0.092649</td>\n",
       "      <td>0.970882</td>\n",
       "      <td>0.035811</td>\n",
       "      <td>0.092764</td>\n",
       "      <td>0.055561</td>\n",
       "      <td>0.046131</td>\n",
       "      <td>0.782385</td>\n",
       "      <td>0.050987</td>\n",
       "      <td>0.139915</td>\n",
       "      <td>0.044773</td>\n",
       "      <td>0.011418</td>\n",
       "      <td>0.448850</td>\n",
       "      <td>0.308036</td>\n",
       "      <td>0.097947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.726078</td>\n",
       "      <td>0.115909</td>\n",
       "      <td>0.300091</td>\n",
       "      <td>0.884202</td>\n",
       "      <td>0.149577</td>\n",
       "      <td>0.300234</td>\n",
       "      <td>0.202148</td>\n",
       "      <td>0.172830</td>\n",
       "      <td>0.649604</td>\n",
       "      <td>0.174849</td>\n",
       "      <td>0.322473</td>\n",
       "      <td>0.177353</td>\n",
       "      <td>0.046490</td>\n",
       "      <td>0.668801</td>\n",
       "      <td>0.601540</td>\n",
       "      <td>0.225496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.807777</td>\n",
       "      <td>0.116304</td>\n",
       "      <td>0.218959</td>\n",
       "      <td>0.917608</td>\n",
       "      <td>0.099300</td>\n",
       "      <td>0.218917</td>\n",
       "      <td>0.146716</td>\n",
       "      <td>0.124237</td>\n",
       "      <td>0.703470</td>\n",
       "      <td>0.126164</td>\n",
       "      <td>0.241203</td>\n",
       "      <td>0.119873</td>\n",
       "      <td>0.028485</td>\n",
       "      <td>0.595669</td>\n",
       "      <td>0.503300</td>\n",
       "      <td>0.167518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.749143</td>\n",
       "      <td>0.094078</td>\n",
       "      <td>0.381677</td>\n",
       "      <td>0.889109</td>\n",
       "      <td>0.162363</td>\n",
       "      <td>0.382130</td>\n",
       "      <td>0.186939</td>\n",
       "      <td>0.160144</td>\n",
       "      <td>0.671443</td>\n",
       "      <td>0.160701</td>\n",
       "      <td>0.230659</td>\n",
       "      <td>0.140920</td>\n",
       "      <td>0.199346</td>\n",
       "      <td>0.511220</td>\n",
       "      <td>0.489412</td>\n",
       "      <td>0.576189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.159620</td>\n",
       "      <td>0.318122</td>\n",
       "      <td>0.700541</td>\n",
       "      <td>0.396494</td>\n",
       "      <td>0.681425</td>\n",
       "      <td>0.700410</td>\n",
       "      <td>0.716595</td>\n",
       "      <td>0.662927</td>\n",
       "      <td>0.179710</td>\n",
       "      <td>0.615511</td>\n",
       "      <td>0.617823</td>\n",
       "      <td>0.688062</td>\n",
       "      <td>0.603715</td>\n",
       "      <td>0.690891</td>\n",
       "      <td>0.809813</td>\n",
       "      <td>0.692345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.026085</td>\n",
       "      <td>0.312549</td>\n",
       "      <td>0.024595</td>\n",
       "      <td>0.414045</td>\n",
       "      <td>0.321003</td>\n",
       "      <td>0.022976</td>\n",
       "      <td>0.828106</td>\n",
       "      <td>0.741574</td>\n",
       "      <td>0.183148</td>\n",
       "      <td>0.573303</td>\n",
       "      <td>0.382859</td>\n",
       "      <td>0.265135</td>\n",
       "      <td>0.416812</td>\n",
       "      <td>0.173793</td>\n",
       "      <td>0.031885</td>\n",
       "      <td>0.333213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.119864</td>\n",
       "      <td>0.390216</td>\n",
       "      <td>0.525686</td>\n",
       "      <td>0.407587</td>\n",
       "      <td>0.664672</td>\n",
       "      <td>0.524744</td>\n",
       "      <td>0.749218</td>\n",
       "      <td>0.676693</td>\n",
       "      <td>0.205149</td>\n",
       "      <td>0.566305</td>\n",
       "      <td>0.618787</td>\n",
       "      <td>0.681682</td>\n",
       "      <td>0.561207</td>\n",
       "      <td>0.671038</td>\n",
       "      <td>0.686257</td>\n",
       "      <td>0.585089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.267379</td>\n",
       "      <td>0.604305</td>\n",
       "      <td>0.411300</td>\n",
       "      <td>0.448197</td>\n",
       "      <td>0.412848</td>\n",
       "      <td>0.408858</td>\n",
       "      <td>0.563737</td>\n",
       "      <td>0.556675</td>\n",
       "      <td>0.214612</td>\n",
       "      <td>0.661302</td>\n",
       "      <td>0.244477</td>\n",
       "      <td>0.476542</td>\n",
       "      <td>0.266252</td>\n",
       "      <td>0.389821</td>\n",
       "      <td>0.677589</td>\n",
       "      <td>0.456193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.893015</td>\n",
       "      <td>0.105256</td>\n",
       "      <td>0.098113</td>\n",
       "      <td>0.957846</td>\n",
       "      <td>0.040973</td>\n",
       "      <td>0.097863</td>\n",
       "      <td>0.077010</td>\n",
       "      <td>0.063731</td>\n",
       "      <td>0.853903</td>\n",
       "      <td>0.068592</td>\n",
       "      <td>0.145840</td>\n",
       "      <td>0.054063</td>\n",
       "      <td>0.005795</td>\n",
       "      <td>0.464688</td>\n",
       "      <td>0.339510</td>\n",
       "      <td>0.040803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.727275</td>\n",
       "      <td>0.164323</td>\n",
       "      <td>0.273176</td>\n",
       "      <td>0.869686</td>\n",
       "      <td>0.143265</td>\n",
       "      <td>0.272977</td>\n",
       "      <td>0.204996</td>\n",
       "      <td>0.177072</td>\n",
       "      <td>0.746733</td>\n",
       "      <td>0.177171</td>\n",
       "      <td>0.218874</td>\n",
       "      <td>0.148886</td>\n",
       "      <td>0.117074</td>\n",
       "      <td>0.421086</td>\n",
       "      <td>0.477927</td>\n",
       "      <td>0.403525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows  16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       energy  contrast  variance  inverse difference moment  sum average  \\\n",
       "0    0.169224  0.289995  0.503613                   0.328835     0.554133   \n",
       "1    0.816743  0.101235  0.222058                   0.910721     0.092361   \n",
       "2    0.616307  0.174905  0.229516                   0.791696     0.149270   \n",
       "3    0.016687  0.680178  0.343683                   0.133705     0.830096   \n",
       "4    0.144739  0.238395  0.059277                   0.370087     0.252131   \n",
       "5    0.753275  0.026219  0.175914                   0.855644     0.100871   \n",
       "6    0.086338  0.109834  0.002533                   0.441833     0.208530   \n",
       "7    0.719489  0.019917  0.177375                   0.837457     0.111338   \n",
       "8    0.979866  0.065778  0.013180                   0.994070     0.000000   \n",
       "9    0.796203  0.177308  0.180361                   0.910296     0.088612   \n",
       "10   0.180932  0.239203  0.281093                   0.476267     0.414113   \n",
       "11   0.746699  0.221874  0.172101                   0.884964     0.104835   \n",
       "12   0.708238  0.039289  0.192864                   0.832247     0.120533   \n",
       "13   0.759275  0.117672  0.348243                   0.859624     0.151281   \n",
       "14   0.734341  0.212244  0.184847                   0.876952     0.112303   \n",
       "15   0.032162  0.644137  0.395792                   0.149959     0.784006   \n",
       "16   0.929437  0.030788  0.039176                   0.961233     0.011858   \n",
       "17   0.309006  0.181983  0.588884                   0.500712     0.470738   \n",
       "18   0.776195  0.025340  0.168686                   0.868081     0.093564   \n",
       "19   0.910705  0.047852  0.143099                   0.963078     0.052286   \n",
       "20   1.000000  0.005193  0.024192                   1.000000     0.000296   \n",
       "21   0.638123  0.147780  0.304033                   0.879514     0.184535   \n",
       "22   0.265679  0.155492  0.768694                   0.525848     0.570201   \n",
       "23   0.701493  0.035783  0.271819                   0.870198     0.136969   \n",
       "24   0.037521  0.410973  0.183254                   0.121111     0.565109   \n",
       "25   0.034828  0.858426  0.423979                   0.112276     0.827759   \n",
       "26   0.475351  0.113515  0.343857                   0.629219     0.271461   \n",
       "27   0.582977  0.247465  0.263660                   0.823804     0.173158   \n",
       "28   0.052330  0.463148  0.603172                   0.239494     0.865652   \n",
       "29   0.079862  0.585364  0.747049                   0.282110     0.781438   \n",
       "..        ...       ...       ...                        ...          ...   \n",
       "172  0.673622  0.236813  0.206139                   0.811437     0.139913   \n",
       "173  0.880415  0.051604  0.117267                   0.942785     0.054652   \n",
       "174  0.801684  0.024262  0.000000                   0.915328     0.026728   \n",
       "175  0.000000  0.811920  0.410706                   0.000000     0.901127   \n",
       "176  0.843534  0.069507  0.259898                   0.921249     0.099657   \n",
       "177  0.140590  0.316887  0.334944                   0.444251     0.499718   \n",
       "178  0.915000  0.032007  0.147267                   0.970536     0.051183   \n",
       "179  0.848981  0.071954  0.172494                   0.923166     0.078513   \n",
       "180  0.954383  0.054051  0.066594                   0.986426     0.021105   \n",
       "181  0.587120  0.191977  0.251218                   0.780205     0.180097   \n",
       "182  0.217640  0.240444  0.485385                   0.472427     0.491405   \n",
       "183  0.260285  0.006904  0.391357                   0.582404     0.386956   \n",
       "184  0.171980  0.197873  0.387828                   0.340331     0.477394   \n",
       "185  0.896178  0.063057  0.135481                   0.969489     0.052887   \n",
       "186  0.293539  0.250586  0.745285                   0.589536     0.498973   \n",
       "187  0.031995  0.874942  0.399836                   0.139135     0.804057   \n",
       "188  0.899593  0.053779  0.158514                   0.937548     0.058574   \n",
       "189  0.758134  0.109442  0.189716                   0.897108     0.109560   \n",
       "190  0.163818  0.135848  0.718995                   0.542462     0.671649   \n",
       "191  0.038905  0.586514  0.503882                   0.164647     0.816463   \n",
       "192  0.920701  0.040314  0.092649                   0.970882     0.035811   \n",
       "193  0.726078  0.115909  0.300091                   0.884202     0.149577   \n",
       "194  0.807777  0.116304  0.218959                   0.917608     0.099300   \n",
       "195  0.749143  0.094078  0.381677                   0.889109     0.162363   \n",
       "196  0.159620  0.318122  0.700541                   0.396494     0.681425   \n",
       "197  0.026085  0.312549  0.024595                   0.414045     0.321003   \n",
       "198  0.119864  0.390216  0.525686                   0.407587     0.664672   \n",
       "199  0.267379  0.604305  0.411300                   0.448197     0.412848   \n",
       "200  0.893015  0.105256  0.098113                   0.957846     0.040973   \n",
       "201  0.727275  0.164323  0.273176                   0.869686     0.143265   \n",
       "\n",
       "     sum variance  sum entropy   entropy  difference variance  \\\n",
       "0        0.503203     0.699561  0.680072             0.143376   \n",
       "1        0.222110     0.142707  0.124576             0.695182   \n",
       "2        0.229158     0.305093  0.272178             0.536824   \n",
       "3        0.340649     0.935801  0.905857             0.046132   \n",
       "4        0.058167     0.673827  0.645537             0.162975   \n",
       "5        0.176298     0.196664  0.177152             0.647691   \n",
       "6        0.002042     0.711789  0.647242             0.255335   \n",
       "7        0.177799     0.220557  0.198897             0.622483   \n",
       "8        0.012969     0.010677  0.008506             0.847751   \n",
       "9        0.179878     0.156350  0.132000             0.687980   \n",
       "10       0.280477     0.663436  0.601878             0.247823   \n",
       "11       0.171341     0.186406  0.160340             0.650283   \n",
       "12       0.193210     0.226917  0.204334             0.613916   \n",
       "13       0.348484     0.186493  0.168041             0.682123   \n",
       "14       0.184171     0.197792  0.170491             0.645881   \n",
       "15       0.393083     0.905366  0.885406             0.045673   \n",
       "16       0.039227     0.054511  0.049274             0.782016   \n",
       "17       0.589292     0.534461  0.512072             0.282558   \n",
       "18       0.169059     0.178687  0.161216             0.662719   \n",
       "19       0.143284     0.064152  0.054446             0.771295   \n",
       "20       0.024357     0.000000  0.000000             0.868280   \n",
       "21       0.304000     0.270962  0.214235             0.748563   \n",
       "22       0.769660     0.598892  0.547214             0.264344   \n",
       "23       0.272363     0.232108  0.194935             0.624206   \n",
       "24       0.181421     0.861132  0.854264             0.037339   \n",
       "25       0.420090     0.891780  0.897603             0.029799   \n",
       "26       0.344112     0.381336  0.372120             0.469400   \n",
       "27       0.262957     0.323813  0.270001             0.550242   \n",
       "28       0.601981     0.887251  0.830420             0.083958   \n",
       "29       0.745472     0.830760  0.789128             0.099432   \n",
       "..            ...          ...       ...                  ...   \n",
       "172      0.205368     0.233830  0.216615             0.573074   \n",
       "173      0.117372     0.087996  0.076518             0.742533   \n",
       "174      0.000000     0.132504  0.113929             0.760796   \n",
       "175      0.407058     1.000000  1.000000             0.000000   \n",
       "176      0.260220     0.122099  0.107735             0.710995   \n",
       "177      0.333999     0.712943  0.642178             0.214201   \n",
       "178      0.147553     0.064473  0.052746             0.782980   \n",
       "179      0.172605     0.111210  0.097702             0.719215   \n",
       "180      0.066571     0.033350  0.026036             0.817499   \n",
       "181      0.250809     0.302527  0.269404             0.525626   \n",
       "182      0.485222     0.656693  0.601077             0.216915   \n",
       "183      0.392338     0.630229  0.550682             0.364547   \n",
       "184      0.387692     0.694496  0.672813             0.159429   \n",
       "185      0.135560     0.076344  0.059401             0.869805   \n",
       "186      0.745647     0.599466  0.531970             0.305995   \n",
       "187      0.395797     0.906055  0.891244             0.041939   \n",
       "188      0.158699     0.082211  0.075743             0.747268   \n",
       "189      0.189649     0.172731  0.147778             0.661098   \n",
       "190      0.719964     0.716340  0.624908             0.261304   \n",
       "191      0.501751     0.919728  0.880194             0.051927   \n",
       "192      0.092764     0.055561  0.046131             0.782385   \n",
       "193      0.300234     0.202148  0.172830             0.649604   \n",
       "194      0.218917     0.146716  0.124237             0.703470   \n",
       "195      0.382130     0.186939  0.160144             0.671443   \n",
       "196      0.700410     0.716595  0.662927             0.179710   \n",
       "197      0.022976     0.828106  0.741574             0.183148   \n",
       "198      0.524744     0.749218  0.676693             0.205149   \n",
       "199      0.408858     0.563737  0.556675             0.214612   \n",
       "200      0.097863     0.077010  0.063731             0.853903   \n",
       "201      0.272977     0.204996  0.177072             0.746733   \n",
       "\n",
       "     difference entropy    mean_B    mean_G    mean_R     std_B     std_G  \\\n",
       "0              0.709940  0.313805  0.528787  0.614273  0.304604  0.615009   \n",
       "1              0.139885  0.220593  0.101461  0.053140  0.559716  0.442374   \n",
       "2              0.286056  0.298854  0.167377  0.074775  0.539028  0.447906   \n",
       "3              0.817664  0.265694  0.874486  0.759549  0.398753  0.512621   \n",
       "4              0.641177  0.170598  0.232265  0.307716  0.091011  0.135052   \n",
       "5              0.198023  0.176512  0.076325  0.152918  0.394871  0.249911   \n",
       "6              0.552105  0.231839  0.171394  0.286421  0.087317  0.000000   \n",
       "7              0.220909  0.225201  0.090681  0.143445  0.463693  0.267135   \n",
       "8              0.011066  0.058835  0.005192  0.000907  0.260821  0.170652   \n",
       "9              0.131606  0.225653  0.099282  0.044162  0.561475  0.415473   \n",
       "10             0.536012  0.124879  0.416336  0.442787  0.188226  0.449327   \n",
       "11             0.165443  0.211575  0.128075  0.035218  0.444714  0.439441   \n",
       "12             0.227441  0.196033  0.095771  0.170095  0.400597  0.273870   \n",
       "13             0.198418  0.239835  0.152197  0.131952  0.500756  0.535543   \n",
       "14             0.175686  0.223086  0.136636  0.037988  0.459744  0.455840   \n",
       "15             0.838216  0.267264  0.825950  0.716113  0.410896  0.566080   \n",
       "16             0.066333  0.081997  0.009346  0.026549  0.312601  0.146925   \n",
       "17             0.563096  0.413763  0.430469  0.534928  0.399168  0.659911   \n",
       "18             0.182666  0.167726  0.069320  0.146390  0.389611  0.240168   \n",
       "19             0.061737  0.169317  0.058562  0.028645  0.516078  0.360929   \n",
       "20             0.000000  0.069477  0.000000  0.011742  0.313507  0.153461   \n",
       "21             0.149985  0.398479  0.210074  0.071560  0.682240  0.573719   \n",
       "22             0.526277  0.652788  0.494717  0.669729  0.627026  0.731178   \n",
       "23             0.182920  0.301243  0.143018  0.089608  0.613827  0.458148   \n",
       "24             0.834893  0.149505  0.581961  0.565702  0.134371  0.340063   \n",
       "25             0.899544  0.316002  0.875428  0.738687  0.418568  0.599603   \n",
       "26             0.457843  0.414242  0.259100  0.252296  0.540759  0.500993   \n",
       "27             0.233951  0.389343  0.207296  0.041097  0.677191  0.551749   \n",
       "28             0.725498  0.742508  0.841126  0.848570  0.533037  0.695461   \n",
       "29             0.764286  0.632374  0.770294  0.750642  0.844418  0.764848   \n",
       "..                  ...       ...       ...       ...       ...       ...   \n",
       "172            0.271532  0.141284  0.169710  0.074488  0.268916  0.480453   \n",
       "173            0.085906  0.148910  0.057173  0.045037  0.411167  0.300986   \n",
       "174            0.122401  0.086998  0.039078  0.006200  0.192364  0.138401   \n",
       "175            0.970119  0.728078  0.891336  0.855435  0.772312  0.459785   \n",
       "176            0.124364  0.240255  0.108289  0.057490  0.613340  0.486935   \n",
       "177            0.548127  0.127916  0.502639  0.532559  0.197047  0.506081   \n",
       "178            0.050377  0.165452  0.060708  0.020644  0.521208  0.386048   \n",
       "179            0.113572  0.198191  0.069739  0.085985  0.495080  0.312069   \n",
       "180            0.023627  0.112506  0.026828  0.009726  0.414651  0.261029   \n",
       "181            0.294182  0.265157  0.199069  0.114448  0.417356  0.470486   \n",
       "182            0.567732  0.249824  0.529215  0.411167  0.356654  0.709945   \n",
       "183            0.446804  0.422132  0.344042  0.448278  0.419722  0.473452   \n",
       "184            0.697615  0.929689  0.522162  0.216727  0.777439  0.618846   \n",
       "185            0.047101  0.147634  0.064569  0.021641  0.444405  0.372508   \n",
       "186            0.482356  0.257551  0.484984  0.541190  0.579617  0.803037   \n",
       "187            0.852812  0.290984  0.847244  0.730920  0.426295  0.570417   \n",
       "188            0.098770  0.142637  0.054676  0.066041  0.420517  0.324368   \n",
       "189            0.153561  0.233146  0.117561  0.071364  0.483006  0.396386   \n",
       "190            0.490682  0.860006  0.623702  0.665884  0.776326  0.741387   \n",
       "191            0.808667  0.311832  0.825653  0.818722  0.493654  0.626898   \n",
       "192            0.050987  0.139915  0.044773  0.011418  0.448850  0.308036   \n",
       "193            0.174849  0.322473  0.177353  0.046490  0.668801  0.601540   \n",
       "194            0.126164  0.241203  0.119873  0.028485  0.595669  0.503300   \n",
       "195            0.160701  0.230659  0.140920  0.199346  0.511220  0.489412   \n",
       "196            0.615511  0.617823  0.688062  0.603715  0.690891  0.809813   \n",
       "197            0.573303  0.382859  0.265135  0.416812  0.173793  0.031885   \n",
       "198            0.566305  0.618787  0.681682  0.561207  0.671038  0.686257   \n",
       "199            0.661302  0.244477  0.476542  0.266252  0.389821  0.677589   \n",
       "200            0.068592  0.145840  0.054063  0.005795  0.464688  0.339510   \n",
       "201            0.177171  0.218874  0.148886  0.117074  0.421086  0.477927   \n",
       "\n",
       "        std_R  \n",
       "0    0.737568  \n",
       "1    0.309818  \n",
       "2    0.289288  \n",
       "3    0.594145  \n",
       "4    0.348236  \n",
       "5    0.468215  \n",
       "6    0.297518  \n",
       "7    0.421028  \n",
       "8    0.017506  \n",
       "9    0.177397  \n",
       "10   0.545056  \n",
       "11   0.162066  \n",
       "12   0.480086  \n",
       "13   0.451087  \n",
       "14   0.174449  \n",
       "15   0.619856  \n",
       "16   0.165443  \n",
       "17   0.783451  \n",
       "18   0.463173  \n",
       "19   0.163771  \n",
       "20   0.076231  \n",
       "21   0.182825  \n",
       "22   0.923630  \n",
       "23   0.387999  \n",
       "24   0.452158  \n",
       "25   0.630198  \n",
       "26   0.459192  \n",
       "27   0.188445  \n",
       "28   0.743058  \n",
       "29   0.864680  \n",
       "..        ...  \n",
       "172  0.260380  \n",
       "173  0.174222  \n",
       "174  0.026030  \n",
       "175  0.682910  \n",
       "176  0.315547  \n",
       "177  0.593324  \n",
       "178  0.144966  \n",
       "179  0.325535  \n",
       "180  0.081890  \n",
       "181  0.359641  \n",
       "182  0.542708  \n",
       "183  0.672721  \n",
       "184  0.340381  \n",
       "185  0.142865  \n",
       "186  0.856679  \n",
       "187  0.621260  \n",
       "188  0.275003  \n",
       "189  0.262710  \n",
       "190  0.779577  \n",
       "191  0.716824  \n",
       "192  0.097947  \n",
       "193  0.225496  \n",
       "194  0.167518  \n",
       "195  0.576189  \n",
       "196  0.692345  \n",
       "197  0.333213  \n",
       "198  0.585089  \n",
       "199  0.456193  \n",
       "200  0.040803  \n",
       "201  0.403525  \n",
       "\n",
       "[202 rows x 16 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Dataset into training and testing dataset\n",
    "\n",
    "#### 162 Tea leaves images are used as training dataset and remaining 40 tea leaf images are used for testing  (80% of dataset is used for training purpose and 20% of dataset is used for testing purpose) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = my_file[:162]\n",
    "train_label = mylabel[:162] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = my_file[162:]\n",
    "test_label = mylabel[162:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy</th>\n",
       "      <th>contrast</th>\n",
       "      <th>variance</th>\n",
       "      <th>inverse difference moment</th>\n",
       "      <th>sum average</th>\n",
       "      <th>sum variance</th>\n",
       "      <th>sum entropy</th>\n",
       "      <th>entropy</th>\n",
       "      <th>difference variance</th>\n",
       "      <th>difference entropy</th>\n",
       "      <th>mean_B</th>\n",
       "      <th>mean_G</th>\n",
       "      <th>mean_R</th>\n",
       "      <th>std_B</th>\n",
       "      <th>std_G</th>\n",
       "      <th>std_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.169224</td>\n",
       "      <td>0.289995</td>\n",
       "      <td>0.503613</td>\n",
       "      <td>0.328835</td>\n",
       "      <td>0.554133</td>\n",
       "      <td>0.503203</td>\n",
       "      <td>0.699561</td>\n",
       "      <td>0.680072</td>\n",
       "      <td>0.143376</td>\n",
       "      <td>0.709940</td>\n",
       "      <td>0.313805</td>\n",
       "      <td>0.528787</td>\n",
       "      <td>0.614273</td>\n",
       "      <td>0.304604</td>\n",
       "      <td>0.615009</td>\n",
       "      <td>0.737568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.816743</td>\n",
       "      <td>0.101235</td>\n",
       "      <td>0.222058</td>\n",
       "      <td>0.910721</td>\n",
       "      <td>0.092361</td>\n",
       "      <td>0.222110</td>\n",
       "      <td>0.142707</td>\n",
       "      <td>0.124576</td>\n",
       "      <td>0.695182</td>\n",
       "      <td>0.139885</td>\n",
       "      <td>0.220593</td>\n",
       "      <td>0.101461</td>\n",
       "      <td>0.053140</td>\n",
       "      <td>0.559716</td>\n",
       "      <td>0.442374</td>\n",
       "      <td>0.309818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.616307</td>\n",
       "      <td>0.174905</td>\n",
       "      <td>0.229516</td>\n",
       "      <td>0.791696</td>\n",
       "      <td>0.149270</td>\n",
       "      <td>0.229158</td>\n",
       "      <td>0.305093</td>\n",
       "      <td>0.272178</td>\n",
       "      <td>0.536824</td>\n",
       "      <td>0.286056</td>\n",
       "      <td>0.298854</td>\n",
       "      <td>0.167377</td>\n",
       "      <td>0.074775</td>\n",
       "      <td>0.539028</td>\n",
       "      <td>0.447906</td>\n",
       "      <td>0.289288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016687</td>\n",
       "      <td>0.680178</td>\n",
       "      <td>0.343683</td>\n",
       "      <td>0.133705</td>\n",
       "      <td>0.830096</td>\n",
       "      <td>0.340649</td>\n",
       "      <td>0.935801</td>\n",
       "      <td>0.905857</td>\n",
       "      <td>0.046132</td>\n",
       "      <td>0.817664</td>\n",
       "      <td>0.265694</td>\n",
       "      <td>0.874486</td>\n",
       "      <td>0.759549</td>\n",
       "      <td>0.398753</td>\n",
       "      <td>0.512621</td>\n",
       "      <td>0.594145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.144739</td>\n",
       "      <td>0.238395</td>\n",
       "      <td>0.059277</td>\n",
       "      <td>0.370087</td>\n",
       "      <td>0.252131</td>\n",
       "      <td>0.058167</td>\n",
       "      <td>0.673827</td>\n",
       "      <td>0.645537</td>\n",
       "      <td>0.162975</td>\n",
       "      <td>0.641177</td>\n",
       "      <td>0.170598</td>\n",
       "      <td>0.232265</td>\n",
       "      <td>0.307716</td>\n",
       "      <td>0.091011</td>\n",
       "      <td>0.135052</td>\n",
       "      <td>0.348236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.753275</td>\n",
       "      <td>0.026219</td>\n",
       "      <td>0.175914</td>\n",
       "      <td>0.855644</td>\n",
       "      <td>0.100871</td>\n",
       "      <td>0.176298</td>\n",
       "      <td>0.196664</td>\n",
       "      <td>0.177152</td>\n",
       "      <td>0.647691</td>\n",
       "      <td>0.198023</td>\n",
       "      <td>0.176512</td>\n",
       "      <td>0.076325</td>\n",
       "      <td>0.152918</td>\n",
       "      <td>0.394871</td>\n",
       "      <td>0.249911</td>\n",
       "      <td>0.468215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.086338</td>\n",
       "      <td>0.109834</td>\n",
       "      <td>0.002533</td>\n",
       "      <td>0.441833</td>\n",
       "      <td>0.208530</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>0.711789</td>\n",
       "      <td>0.647242</td>\n",
       "      <td>0.255335</td>\n",
       "      <td>0.552105</td>\n",
       "      <td>0.231839</td>\n",
       "      <td>0.171394</td>\n",
       "      <td>0.286421</td>\n",
       "      <td>0.087317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.297518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.719489</td>\n",
       "      <td>0.019917</td>\n",
       "      <td>0.177375</td>\n",
       "      <td>0.837457</td>\n",
       "      <td>0.111338</td>\n",
       "      <td>0.177799</td>\n",
       "      <td>0.220557</td>\n",
       "      <td>0.198897</td>\n",
       "      <td>0.622483</td>\n",
       "      <td>0.220909</td>\n",
       "      <td>0.225201</td>\n",
       "      <td>0.090681</td>\n",
       "      <td>0.143445</td>\n",
       "      <td>0.463693</td>\n",
       "      <td>0.267135</td>\n",
       "      <td>0.421028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.979866</td>\n",
       "      <td>0.065778</td>\n",
       "      <td>0.013180</td>\n",
       "      <td>0.994070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012969</td>\n",
       "      <td>0.010677</td>\n",
       "      <td>0.008506</td>\n",
       "      <td>0.847751</td>\n",
       "      <td>0.011066</td>\n",
       "      <td>0.058835</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>0.260821</td>\n",
       "      <td>0.170652</td>\n",
       "      <td>0.017506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.796203</td>\n",
       "      <td>0.177308</td>\n",
       "      <td>0.180361</td>\n",
       "      <td>0.910296</td>\n",
       "      <td>0.088612</td>\n",
       "      <td>0.179878</td>\n",
       "      <td>0.156350</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>0.687980</td>\n",
       "      <td>0.131606</td>\n",
       "      <td>0.225653</td>\n",
       "      <td>0.099282</td>\n",
       "      <td>0.044162</td>\n",
       "      <td>0.561475</td>\n",
       "      <td>0.415473</td>\n",
       "      <td>0.177397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.180932</td>\n",
       "      <td>0.239203</td>\n",
       "      <td>0.281093</td>\n",
       "      <td>0.476267</td>\n",
       "      <td>0.414113</td>\n",
       "      <td>0.280477</td>\n",
       "      <td>0.663436</td>\n",
       "      <td>0.601878</td>\n",
       "      <td>0.247823</td>\n",
       "      <td>0.536012</td>\n",
       "      <td>0.124879</td>\n",
       "      <td>0.416336</td>\n",
       "      <td>0.442787</td>\n",
       "      <td>0.188226</td>\n",
       "      <td>0.449327</td>\n",
       "      <td>0.545056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.746699</td>\n",
       "      <td>0.221874</td>\n",
       "      <td>0.172101</td>\n",
       "      <td>0.884964</td>\n",
       "      <td>0.104835</td>\n",
       "      <td>0.171341</td>\n",
       "      <td>0.186406</td>\n",
       "      <td>0.160340</td>\n",
       "      <td>0.650283</td>\n",
       "      <td>0.165443</td>\n",
       "      <td>0.211575</td>\n",
       "      <td>0.128075</td>\n",
       "      <td>0.035218</td>\n",
       "      <td>0.444714</td>\n",
       "      <td>0.439441</td>\n",
       "      <td>0.162066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.708238</td>\n",
       "      <td>0.039289</td>\n",
       "      <td>0.192864</td>\n",
       "      <td>0.832247</td>\n",
       "      <td>0.120533</td>\n",
       "      <td>0.193210</td>\n",
       "      <td>0.226917</td>\n",
       "      <td>0.204334</td>\n",
       "      <td>0.613916</td>\n",
       "      <td>0.227441</td>\n",
       "      <td>0.196033</td>\n",
       "      <td>0.095771</td>\n",
       "      <td>0.170095</td>\n",
       "      <td>0.400597</td>\n",
       "      <td>0.273870</td>\n",
       "      <td>0.480086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.759275</td>\n",
       "      <td>0.117672</td>\n",
       "      <td>0.348243</td>\n",
       "      <td>0.859624</td>\n",
       "      <td>0.151281</td>\n",
       "      <td>0.348484</td>\n",
       "      <td>0.186493</td>\n",
       "      <td>0.168041</td>\n",
       "      <td>0.682123</td>\n",
       "      <td>0.198418</td>\n",
       "      <td>0.239835</td>\n",
       "      <td>0.152197</td>\n",
       "      <td>0.131952</td>\n",
       "      <td>0.500756</td>\n",
       "      <td>0.535543</td>\n",
       "      <td>0.451087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.734341</td>\n",
       "      <td>0.212244</td>\n",
       "      <td>0.184847</td>\n",
       "      <td>0.876952</td>\n",
       "      <td>0.112303</td>\n",
       "      <td>0.184171</td>\n",
       "      <td>0.197792</td>\n",
       "      <td>0.170491</td>\n",
       "      <td>0.645881</td>\n",
       "      <td>0.175686</td>\n",
       "      <td>0.223086</td>\n",
       "      <td>0.136636</td>\n",
       "      <td>0.037988</td>\n",
       "      <td>0.459744</td>\n",
       "      <td>0.455840</td>\n",
       "      <td>0.174449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.032162</td>\n",
       "      <td>0.644137</td>\n",
       "      <td>0.395792</td>\n",
       "      <td>0.149959</td>\n",
       "      <td>0.784006</td>\n",
       "      <td>0.393083</td>\n",
       "      <td>0.905366</td>\n",
       "      <td>0.885406</td>\n",
       "      <td>0.045673</td>\n",
       "      <td>0.838216</td>\n",
       "      <td>0.267264</td>\n",
       "      <td>0.825950</td>\n",
       "      <td>0.716113</td>\n",
       "      <td>0.410896</td>\n",
       "      <td>0.566080</td>\n",
       "      <td>0.619856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.929437</td>\n",
       "      <td>0.030788</td>\n",
       "      <td>0.039176</td>\n",
       "      <td>0.961233</td>\n",
       "      <td>0.011858</td>\n",
       "      <td>0.039227</td>\n",
       "      <td>0.054511</td>\n",
       "      <td>0.049274</td>\n",
       "      <td>0.782016</td>\n",
       "      <td>0.066333</td>\n",
       "      <td>0.081997</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.026549</td>\n",
       "      <td>0.312601</td>\n",
       "      <td>0.146925</td>\n",
       "      <td>0.165443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.309006</td>\n",
       "      <td>0.181983</td>\n",
       "      <td>0.588884</td>\n",
       "      <td>0.500712</td>\n",
       "      <td>0.470738</td>\n",
       "      <td>0.589292</td>\n",
       "      <td>0.534461</td>\n",
       "      <td>0.512072</td>\n",
       "      <td>0.282558</td>\n",
       "      <td>0.563096</td>\n",
       "      <td>0.413763</td>\n",
       "      <td>0.430469</td>\n",
       "      <td>0.534928</td>\n",
       "      <td>0.399168</td>\n",
       "      <td>0.659911</td>\n",
       "      <td>0.783451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.776195</td>\n",
       "      <td>0.025340</td>\n",
       "      <td>0.168686</td>\n",
       "      <td>0.868081</td>\n",
       "      <td>0.093564</td>\n",
       "      <td>0.169059</td>\n",
       "      <td>0.178687</td>\n",
       "      <td>0.161216</td>\n",
       "      <td>0.662719</td>\n",
       "      <td>0.182666</td>\n",
       "      <td>0.167726</td>\n",
       "      <td>0.069320</td>\n",
       "      <td>0.146390</td>\n",
       "      <td>0.389611</td>\n",
       "      <td>0.240168</td>\n",
       "      <td>0.463173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.910705</td>\n",
       "      <td>0.047852</td>\n",
       "      <td>0.143099</td>\n",
       "      <td>0.963078</td>\n",
       "      <td>0.052286</td>\n",
       "      <td>0.143284</td>\n",
       "      <td>0.064152</td>\n",
       "      <td>0.054446</td>\n",
       "      <td>0.771295</td>\n",
       "      <td>0.061737</td>\n",
       "      <td>0.169317</td>\n",
       "      <td>0.058562</td>\n",
       "      <td>0.028645</td>\n",
       "      <td>0.516078</td>\n",
       "      <td>0.360929</td>\n",
       "      <td>0.163771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005193</td>\n",
       "      <td>0.024192</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.024357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.868280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011742</td>\n",
       "      <td>0.313507</td>\n",
       "      <td>0.153461</td>\n",
       "      <td>0.076231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.638123</td>\n",
       "      <td>0.147780</td>\n",
       "      <td>0.304033</td>\n",
       "      <td>0.879514</td>\n",
       "      <td>0.184535</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.270962</td>\n",
       "      <td>0.214235</td>\n",
       "      <td>0.748563</td>\n",
       "      <td>0.149985</td>\n",
       "      <td>0.398479</td>\n",
       "      <td>0.210074</td>\n",
       "      <td>0.071560</td>\n",
       "      <td>0.682240</td>\n",
       "      <td>0.573719</td>\n",
       "      <td>0.182825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.265679</td>\n",
       "      <td>0.155492</td>\n",
       "      <td>0.768694</td>\n",
       "      <td>0.525848</td>\n",
       "      <td>0.570201</td>\n",
       "      <td>0.769660</td>\n",
       "      <td>0.598892</td>\n",
       "      <td>0.547214</td>\n",
       "      <td>0.264344</td>\n",
       "      <td>0.526277</td>\n",
       "      <td>0.652788</td>\n",
       "      <td>0.494717</td>\n",
       "      <td>0.669729</td>\n",
       "      <td>0.627026</td>\n",
       "      <td>0.731178</td>\n",
       "      <td>0.923630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.701493</td>\n",
       "      <td>0.035783</td>\n",
       "      <td>0.271819</td>\n",
       "      <td>0.870198</td>\n",
       "      <td>0.136969</td>\n",
       "      <td>0.272363</td>\n",
       "      <td>0.232108</td>\n",
       "      <td>0.194935</td>\n",
       "      <td>0.624206</td>\n",
       "      <td>0.182920</td>\n",
       "      <td>0.301243</td>\n",
       "      <td>0.143018</td>\n",
       "      <td>0.089608</td>\n",
       "      <td>0.613827</td>\n",
       "      <td>0.458148</td>\n",
       "      <td>0.387999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.037521</td>\n",
       "      <td>0.410973</td>\n",
       "      <td>0.183254</td>\n",
       "      <td>0.121111</td>\n",
       "      <td>0.565109</td>\n",
       "      <td>0.181421</td>\n",
       "      <td>0.861132</td>\n",
       "      <td>0.854264</td>\n",
       "      <td>0.037339</td>\n",
       "      <td>0.834893</td>\n",
       "      <td>0.149505</td>\n",
       "      <td>0.581961</td>\n",
       "      <td>0.565702</td>\n",
       "      <td>0.134371</td>\n",
       "      <td>0.340063</td>\n",
       "      <td>0.452158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.034828</td>\n",
       "      <td>0.858426</td>\n",
       "      <td>0.423979</td>\n",
       "      <td>0.112276</td>\n",
       "      <td>0.827759</td>\n",
       "      <td>0.420090</td>\n",
       "      <td>0.891780</td>\n",
       "      <td>0.897603</td>\n",
       "      <td>0.029799</td>\n",
       "      <td>0.899544</td>\n",
       "      <td>0.316002</td>\n",
       "      <td>0.875428</td>\n",
       "      <td>0.738687</td>\n",
       "      <td>0.418568</td>\n",
       "      <td>0.599603</td>\n",
       "      <td>0.630198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.475351</td>\n",
       "      <td>0.113515</td>\n",
       "      <td>0.343857</td>\n",
       "      <td>0.629219</td>\n",
       "      <td>0.271461</td>\n",
       "      <td>0.344112</td>\n",
       "      <td>0.381336</td>\n",
       "      <td>0.372120</td>\n",
       "      <td>0.469400</td>\n",
       "      <td>0.457843</td>\n",
       "      <td>0.414242</td>\n",
       "      <td>0.259100</td>\n",
       "      <td>0.252296</td>\n",
       "      <td>0.540759</td>\n",
       "      <td>0.500993</td>\n",
       "      <td>0.459192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.582977</td>\n",
       "      <td>0.247465</td>\n",
       "      <td>0.263660</td>\n",
       "      <td>0.823804</td>\n",
       "      <td>0.173158</td>\n",
       "      <td>0.262957</td>\n",
       "      <td>0.323813</td>\n",
       "      <td>0.270001</td>\n",
       "      <td>0.550242</td>\n",
       "      <td>0.233951</td>\n",
       "      <td>0.389343</td>\n",
       "      <td>0.207296</td>\n",
       "      <td>0.041097</td>\n",
       "      <td>0.677191</td>\n",
       "      <td>0.551749</td>\n",
       "      <td>0.188445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.052330</td>\n",
       "      <td>0.463148</td>\n",
       "      <td>0.603172</td>\n",
       "      <td>0.239494</td>\n",
       "      <td>0.865652</td>\n",
       "      <td>0.601981</td>\n",
       "      <td>0.887251</td>\n",
       "      <td>0.830420</td>\n",
       "      <td>0.083958</td>\n",
       "      <td>0.725498</td>\n",
       "      <td>0.742508</td>\n",
       "      <td>0.841126</td>\n",
       "      <td>0.848570</td>\n",
       "      <td>0.533037</td>\n",
       "      <td>0.695461</td>\n",
       "      <td>0.743058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.079862</td>\n",
       "      <td>0.585364</td>\n",
       "      <td>0.747049</td>\n",
       "      <td>0.282110</td>\n",
       "      <td>0.781438</td>\n",
       "      <td>0.745472</td>\n",
       "      <td>0.830760</td>\n",
       "      <td>0.789128</td>\n",
       "      <td>0.099432</td>\n",
       "      <td>0.764286</td>\n",
       "      <td>0.632374</td>\n",
       "      <td>0.770294</td>\n",
       "      <td>0.750642</td>\n",
       "      <td>0.844418</td>\n",
       "      <td>0.764848</td>\n",
       "      <td>0.864680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.645853</td>\n",
       "      <td>0.135929</td>\n",
       "      <td>0.443657</td>\n",
       "      <td>0.823416</td>\n",
       "      <td>0.217616</td>\n",
       "      <td>0.444006</td>\n",
       "      <td>0.275301</td>\n",
       "      <td>0.241708</td>\n",
       "      <td>0.568529</td>\n",
       "      <td>0.250496</td>\n",
       "      <td>0.473873</td>\n",
       "      <td>0.236883</td>\n",
       "      <td>0.104340</td>\n",
       "      <td>0.838114</td>\n",
       "      <td>0.672522</td>\n",
       "      <td>0.406499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.212732</td>\n",
       "      <td>0.397300</td>\n",
       "      <td>0.447082</td>\n",
       "      <td>0.417542</td>\n",
       "      <td>0.474010</td>\n",
       "      <td>0.445922</td>\n",
       "      <td>0.659979</td>\n",
       "      <td>0.627627</td>\n",
       "      <td>0.185861</td>\n",
       "      <td>0.646859</td>\n",
       "      <td>0.247395</td>\n",
       "      <td>0.519701</td>\n",
       "      <td>0.374571</td>\n",
       "      <td>0.354900</td>\n",
       "      <td>0.684364</td>\n",
       "      <td>0.504045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.278409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.340610</td>\n",
       "      <td>0.592376</td>\n",
       "      <td>0.352626</td>\n",
       "      <td>0.341517</td>\n",
       "      <td>0.604308</td>\n",
       "      <td>0.529951</td>\n",
       "      <td>0.399729</td>\n",
       "      <td>0.440212</td>\n",
       "      <td>0.667015</td>\n",
       "      <td>0.338520</td>\n",
       "      <td>0.284144</td>\n",
       "      <td>0.703021</td>\n",
       "      <td>0.479525</td>\n",
       "      <td>0.442842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.880541</td>\n",
       "      <td>0.084340</td>\n",
       "      <td>0.076190</td>\n",
       "      <td>0.955531</td>\n",
       "      <td>0.039759</td>\n",
       "      <td>0.076012</td>\n",
       "      <td>0.085511</td>\n",
       "      <td>0.071197</td>\n",
       "      <td>0.944586</td>\n",
       "      <td>0.069753</td>\n",
       "      <td>0.136550</td>\n",
       "      <td>0.054957</td>\n",
       "      <td>0.001686</td>\n",
       "      <td>0.398962</td>\n",
       "      <td>0.311373</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.031826</td>\n",
       "      <td>0.594671</td>\n",
       "      <td>0.681899</td>\n",
       "      <td>0.296255</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.680121</td>\n",
       "      <td>0.903889</td>\n",
       "      <td>0.834994</td>\n",
       "      <td>0.108456</td>\n",
       "      <td>0.708133</td>\n",
       "      <td>0.617055</td>\n",
       "      <td>0.985698</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.877554</td>\n",
       "      <td>0.723824</td>\n",
       "      <td>0.827395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.074071</td>\n",
       "      <td>0.460207</td>\n",
       "      <td>0.444862</td>\n",
       "      <td>0.312196</td>\n",
       "      <td>0.636052</td>\n",
       "      <td>0.443332</td>\n",
       "      <td>0.846141</td>\n",
       "      <td>0.782075</td>\n",
       "      <td>0.115774</td>\n",
       "      <td>0.676443</td>\n",
       "      <td>0.010460</td>\n",
       "      <td>0.674330</td>\n",
       "      <td>0.625163</td>\n",
       "      <td>0.059598</td>\n",
       "      <td>0.646336</td>\n",
       "      <td>0.653199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.074672</td>\n",
       "      <td>0.719582</td>\n",
       "      <td>0.597443</td>\n",
       "      <td>0.241884</td>\n",
       "      <td>0.754096</td>\n",
       "      <td>0.594751</td>\n",
       "      <td>0.860951</td>\n",
       "      <td>0.818228</td>\n",
       "      <td>0.081610</td>\n",
       "      <td>0.773312</td>\n",
       "      <td>0.311437</td>\n",
       "      <td>0.756115</td>\n",
       "      <td>0.766888</td>\n",
       "      <td>0.520741</td>\n",
       "      <td>0.700660</td>\n",
       "      <td>0.771711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.861733</td>\n",
       "      <td>0.066044</td>\n",
       "      <td>0.064422</td>\n",
       "      <td>0.938579</td>\n",
       "      <td>0.039600</td>\n",
       "      <td>0.064324</td>\n",
       "      <td>0.102768</td>\n",
       "      <td>0.088436</td>\n",
       "      <td>0.758093</td>\n",
       "      <td>0.095588</td>\n",
       "      <td>0.123677</td>\n",
       "      <td>0.055475</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>0.341972</td>\n",
       "      <td>0.291142</td>\n",
       "      <td>0.021512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.242339</td>\n",
       "      <td>0.239148</td>\n",
       "      <td>0.497708</td>\n",
       "      <td>0.498061</td>\n",
       "      <td>0.479255</td>\n",
       "      <td>0.497580</td>\n",
       "      <td>0.623507</td>\n",
       "      <td>0.570164</td>\n",
       "      <td>0.235208</td>\n",
       "      <td>0.546601</td>\n",
       "      <td>0.239183</td>\n",
       "      <td>0.517943</td>\n",
       "      <td>0.398800</td>\n",
       "      <td>0.357749</td>\n",
       "      <td>0.719585</td>\n",
       "      <td>0.548627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.737837</td>\n",
       "      <td>0.123088</td>\n",
       "      <td>0.249290</td>\n",
       "      <td>0.857726</td>\n",
       "      <td>0.113028</td>\n",
       "      <td>0.249277</td>\n",
       "      <td>0.209732</td>\n",
       "      <td>0.187314</td>\n",
       "      <td>0.626262</td>\n",
       "      <td>0.213894</td>\n",
       "      <td>0.238091</td>\n",
       "      <td>0.112843</td>\n",
       "      <td>0.093472</td>\n",
       "      <td>0.549612</td>\n",
       "      <td>0.411648</td>\n",
       "      <td>0.397622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.736400</td>\n",
       "      <td>0.088800</td>\n",
       "      <td>0.366964</td>\n",
       "      <td>0.878258</td>\n",
       "      <td>0.161588</td>\n",
       "      <td>0.367415</td>\n",
       "      <td>0.201976</td>\n",
       "      <td>0.174083</td>\n",
       "      <td>0.652291</td>\n",
       "      <td>0.174873</td>\n",
       "      <td>0.285335</td>\n",
       "      <td>0.145946</td>\n",
       "      <td>0.171685</td>\n",
       "      <td>0.585209</td>\n",
       "      <td>0.493819</td>\n",
       "      <td>0.516183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.851731</td>\n",
       "      <td>0.048748</td>\n",
       "      <td>0.259864</td>\n",
       "      <td>0.925294</td>\n",
       "      <td>0.096625</td>\n",
       "      <td>0.260306</td>\n",
       "      <td>0.116619</td>\n",
       "      <td>0.102781</td>\n",
       "      <td>0.716928</td>\n",
       "      <td>0.118980</td>\n",
       "      <td>0.231058</td>\n",
       "      <td>0.104268</td>\n",
       "      <td>0.058751</td>\n",
       "      <td>0.603979</td>\n",
       "      <td>0.484588</td>\n",
       "      <td>0.318007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.284387</td>\n",
       "      <td>0.146664</td>\n",
       "      <td>0.672039</td>\n",
       "      <td>0.570640</td>\n",
       "      <td>0.514095</td>\n",
       "      <td>0.672840</td>\n",
       "      <td>0.576264</td>\n",
       "      <td>0.514959</td>\n",
       "      <td>0.313239</td>\n",
       "      <td>0.471214</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.481350</td>\n",
       "      <td>0.424212</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.735300</td>\n",
       "      <td>0.614458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.727530</td>\n",
       "      <td>0.049789</td>\n",
       "      <td>0.063248</td>\n",
       "      <td>0.848463</td>\n",
       "      <td>0.070763</td>\n",
       "      <td>0.063242</td>\n",
       "      <td>0.193881</td>\n",
       "      <td>0.176635</td>\n",
       "      <td>0.654409</td>\n",
       "      <td>0.209215</td>\n",
       "      <td>0.173089</td>\n",
       "      <td>0.086279</td>\n",
       "      <td>0.025816</td>\n",
       "      <td>0.325622</td>\n",
       "      <td>0.252005</td>\n",
       "      <td>0.088513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.794043</td>\n",
       "      <td>0.027502</td>\n",
       "      <td>0.149330</td>\n",
       "      <td>0.880099</td>\n",
       "      <td>0.082796</td>\n",
       "      <td>0.149647</td>\n",
       "      <td>0.162030</td>\n",
       "      <td>0.145990</td>\n",
       "      <td>0.682160</td>\n",
       "      <td>0.168556</td>\n",
       "      <td>0.183661</td>\n",
       "      <td>0.062259</td>\n",
       "      <td>0.122114</td>\n",
       "      <td>0.439205</td>\n",
       "      <td>0.227237</td>\n",
       "      <td>0.403000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.471033</td>\n",
       "      <td>0.240571</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.592830</td>\n",
       "      <td>0.277197</td>\n",
       "      <td>0.363198</td>\n",
       "      <td>0.389181</td>\n",
       "      <td>0.398795</td>\n",
       "      <td>0.398540</td>\n",
       "      <td>0.530844</td>\n",
       "      <td>0.363709</td>\n",
       "      <td>0.259050</td>\n",
       "      <td>0.284365</td>\n",
       "      <td>0.446762</td>\n",
       "      <td>0.503644</td>\n",
       "      <td>0.544987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.705738</td>\n",
       "      <td>0.058311</td>\n",
       "      <td>0.381418</td>\n",
       "      <td>0.856901</td>\n",
       "      <td>0.176308</td>\n",
       "      <td>0.382078</td>\n",
       "      <td>0.230541</td>\n",
       "      <td>0.200624</td>\n",
       "      <td>0.618844</td>\n",
       "      <td>0.202152</td>\n",
       "      <td>0.306789</td>\n",
       "      <td>0.160876</td>\n",
       "      <td>0.182036</td>\n",
       "      <td>0.597425</td>\n",
       "      <td>0.507315</td>\n",
       "      <td>0.525931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.280717</td>\n",
       "      <td>0.160962</td>\n",
       "      <td>0.768933</td>\n",
       "      <td>0.561061</td>\n",
       "      <td>0.557869</td>\n",
       "      <td>0.769868</td>\n",
       "      <td>0.583372</td>\n",
       "      <td>0.523030</td>\n",
       "      <td>0.292712</td>\n",
       "      <td>0.481569</td>\n",
       "      <td>0.640075</td>\n",
       "      <td>0.484277</td>\n",
       "      <td>0.654803</td>\n",
       "      <td>0.626683</td>\n",
       "      <td>0.731693</td>\n",
       "      <td>0.922313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.020219</td>\n",
       "      <td>0.554469</td>\n",
       "      <td>0.368241</td>\n",
       "      <td>0.141403</td>\n",
       "      <td>0.833108</td>\n",
       "      <td>0.365991</td>\n",
       "      <td>0.933129</td>\n",
       "      <td>0.902192</td>\n",
       "      <td>0.047187</td>\n",
       "      <td>0.812903</td>\n",
       "      <td>0.283739</td>\n",
       "      <td>0.874879</td>\n",
       "      <td>0.766307</td>\n",
       "      <td>0.431001</td>\n",
       "      <td>0.531658</td>\n",
       "      <td>0.613396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.743322</td>\n",
       "      <td>0.083516</td>\n",
       "      <td>0.375759</td>\n",
       "      <td>0.887884</td>\n",
       "      <td>0.165842</td>\n",
       "      <td>0.376260</td>\n",
       "      <td>0.191724</td>\n",
       "      <td>0.163524</td>\n",
       "      <td>0.659353</td>\n",
       "      <td>0.161803</td>\n",
       "      <td>0.389260</td>\n",
       "      <td>0.185456</td>\n",
       "      <td>0.067530</td>\n",
       "      <td>0.806767</td>\n",
       "      <td>0.646458</td>\n",
       "      <td>0.239361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.849902</td>\n",
       "      <td>0.019333</td>\n",
       "      <td>0.145730</td>\n",
       "      <td>0.949844</td>\n",
       "      <td>0.070827</td>\n",
       "      <td>0.146087</td>\n",
       "      <td>0.107178</td>\n",
       "      <td>0.087951</td>\n",
       "      <td>0.862835</td>\n",
       "      <td>0.079129</td>\n",
       "      <td>0.174678</td>\n",
       "      <td>0.089540</td>\n",
       "      <td>0.017940</td>\n",
       "      <td>0.451763</td>\n",
       "      <td>0.412236</td>\n",
       "      <td>0.115770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.397566</td>\n",
       "      <td>0.320199</td>\n",
       "      <td>0.466986</td>\n",
       "      <td>0.569552</td>\n",
       "      <td>0.348194</td>\n",
       "      <td>0.466319</td>\n",
       "      <td>0.466221</td>\n",
       "      <td>0.454695</td>\n",
       "      <td>0.355109</td>\n",
       "      <td>0.541982</td>\n",
       "      <td>0.175946</td>\n",
       "      <td>0.320325</td>\n",
       "      <td>0.429330</td>\n",
       "      <td>0.192105</td>\n",
       "      <td>0.578639</td>\n",
       "      <td>0.739005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.124393</td>\n",
       "      <td>0.248500</td>\n",
       "      <td>0.487117</td>\n",
       "      <td>0.370300</td>\n",
       "      <td>0.549832</td>\n",
       "      <td>0.486911</td>\n",
       "      <td>0.801573</td>\n",
       "      <td>0.735678</td>\n",
       "      <td>0.145483</td>\n",
       "      <td>0.644228</td>\n",
       "      <td>0.282172</td>\n",
       "      <td>0.545305</td>\n",
       "      <td>0.567497</td>\n",
       "      <td>0.433477</td>\n",
       "      <td>0.601541</td>\n",
       "      <td>0.699214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.487581</td>\n",
       "      <td>0.123430</td>\n",
       "      <td>0.352985</td>\n",
       "      <td>0.643946</td>\n",
       "      <td>0.266580</td>\n",
       "      <td>0.353203</td>\n",
       "      <td>0.371759</td>\n",
       "      <td>0.360644</td>\n",
       "      <td>0.455881</td>\n",
       "      <td>0.442211</td>\n",
       "      <td>0.355406</td>\n",
       "      <td>0.248507</td>\n",
       "      <td>0.274784</td>\n",
       "      <td>0.440869</td>\n",
       "      <td>0.493297</td>\n",
       "      <td>0.538858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.859038</td>\n",
       "      <td>0.087688</td>\n",
       "      <td>0.124883</td>\n",
       "      <td>0.934718</td>\n",
       "      <td>0.061451</td>\n",
       "      <td>0.124796</td>\n",
       "      <td>0.103159</td>\n",
       "      <td>0.089044</td>\n",
       "      <td>0.749533</td>\n",
       "      <td>0.100213</td>\n",
       "      <td>0.108491</td>\n",
       "      <td>0.074117</td>\n",
       "      <td>0.037926</td>\n",
       "      <td>0.282874</td>\n",
       "      <td>0.351699</td>\n",
       "      <td>0.183958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.842537</td>\n",
       "      <td>0.110994</td>\n",
       "      <td>0.204451</td>\n",
       "      <td>0.927244</td>\n",
       "      <td>0.086240</td>\n",
       "      <td>0.204407</td>\n",
       "      <td>0.116193</td>\n",
       "      <td>0.100923</td>\n",
       "      <td>0.717716</td>\n",
       "      <td>0.112887</td>\n",
       "      <td>0.231374</td>\n",
       "      <td>0.096031</td>\n",
       "      <td>0.042288</td>\n",
       "      <td>0.606232</td>\n",
       "      <td>0.446972</td>\n",
       "      <td>0.172812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.050335</td>\n",
       "      <td>0.567271</td>\n",
       "      <td>0.411831</td>\n",
       "      <td>0.281598</td>\n",
       "      <td>0.670655</td>\n",
       "      <td>0.409605</td>\n",
       "      <td>0.884174</td>\n",
       "      <td>0.813312</td>\n",
       "      <td>0.105402</td>\n",
       "      <td>0.674642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.714094</td>\n",
       "      <td>0.653454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.620931</td>\n",
       "      <td>0.626360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.486603</td>\n",
       "      <td>0.134009</td>\n",
       "      <td>0.340928</td>\n",
       "      <td>0.640326</td>\n",
       "      <td>0.263973</td>\n",
       "      <td>0.341058</td>\n",
       "      <td>0.371184</td>\n",
       "      <td>0.361974</td>\n",
       "      <td>0.466402</td>\n",
       "      <td>0.446690</td>\n",
       "      <td>0.406217</td>\n",
       "      <td>0.251548</td>\n",
       "      <td>0.246625</td>\n",
       "      <td>0.540365</td>\n",
       "      <td>0.497705</td>\n",
       "      <td>0.457404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.173193</td>\n",
       "      <td>0.210094</td>\n",
       "      <td>0.505773</td>\n",
       "      <td>0.336097</td>\n",
       "      <td>0.543099</td>\n",
       "      <td>0.505831</td>\n",
       "      <td>0.700749</td>\n",
       "      <td>0.679332</td>\n",
       "      <td>0.150142</td>\n",
       "      <td>0.702214</td>\n",
       "      <td>0.308823</td>\n",
       "      <td>0.517248</td>\n",
       "      <td>0.604296</td>\n",
       "      <td>0.302371</td>\n",
       "      <td>0.616105</td>\n",
       "      <td>0.740104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.494194</td>\n",
       "      <td>0.147221</td>\n",
       "      <td>0.406913</td>\n",
       "      <td>0.714284</td>\n",
       "      <td>0.248651</td>\n",
       "      <td>0.407114</td>\n",
       "      <td>0.400247</td>\n",
       "      <td>0.360798</td>\n",
       "      <td>0.444975</td>\n",
       "      <td>0.384820</td>\n",
       "      <td>0.429429</td>\n",
       "      <td>0.265146</td>\n",
       "      <td>0.155253</td>\n",
       "      <td>0.662022</td>\n",
       "      <td>0.587674</td>\n",
       "      <td>0.487641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows  16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       energy  contrast  variance  inverse difference moment  sum average  \\\n",
       "0    0.169224  0.289995  0.503613                   0.328835     0.554133   \n",
       "1    0.816743  0.101235  0.222058                   0.910721     0.092361   \n",
       "2    0.616307  0.174905  0.229516                   0.791696     0.149270   \n",
       "3    0.016687  0.680178  0.343683                   0.133705     0.830096   \n",
       "4    0.144739  0.238395  0.059277                   0.370087     0.252131   \n",
       "5    0.753275  0.026219  0.175914                   0.855644     0.100871   \n",
       "6    0.086338  0.109834  0.002533                   0.441833     0.208530   \n",
       "7    0.719489  0.019917  0.177375                   0.837457     0.111338   \n",
       "8    0.979866  0.065778  0.013180                   0.994070     0.000000   \n",
       "9    0.796203  0.177308  0.180361                   0.910296     0.088612   \n",
       "10   0.180932  0.239203  0.281093                   0.476267     0.414113   \n",
       "11   0.746699  0.221874  0.172101                   0.884964     0.104835   \n",
       "12   0.708238  0.039289  0.192864                   0.832247     0.120533   \n",
       "13   0.759275  0.117672  0.348243                   0.859624     0.151281   \n",
       "14   0.734341  0.212244  0.184847                   0.876952     0.112303   \n",
       "15   0.032162  0.644137  0.395792                   0.149959     0.784006   \n",
       "16   0.929437  0.030788  0.039176                   0.961233     0.011858   \n",
       "17   0.309006  0.181983  0.588884                   0.500712     0.470738   \n",
       "18   0.776195  0.025340  0.168686                   0.868081     0.093564   \n",
       "19   0.910705  0.047852  0.143099                   0.963078     0.052286   \n",
       "20   1.000000  0.005193  0.024192                   1.000000     0.000296   \n",
       "21   0.638123  0.147780  0.304033                   0.879514     0.184535   \n",
       "22   0.265679  0.155492  0.768694                   0.525848     0.570201   \n",
       "23   0.701493  0.035783  0.271819                   0.870198     0.136969   \n",
       "24   0.037521  0.410973  0.183254                   0.121111     0.565109   \n",
       "25   0.034828  0.858426  0.423979                   0.112276     0.827759   \n",
       "26   0.475351  0.113515  0.343857                   0.629219     0.271461   \n",
       "27   0.582977  0.247465  0.263660                   0.823804     0.173158   \n",
       "28   0.052330  0.463148  0.603172                   0.239494     0.865652   \n",
       "29   0.079862  0.585364  0.747049                   0.282110     0.781438   \n",
       "..        ...       ...       ...                        ...          ...   \n",
       "132  0.645853  0.135929  0.443657                   0.823416     0.217616   \n",
       "133  0.212732  0.397300  0.447082                   0.417542     0.474010   \n",
       "134  0.278409  0.000000  0.340610                   0.592376     0.352626   \n",
       "135  0.880541  0.084340  0.076190                   0.955531     0.039759   \n",
       "136  0.031826  0.594671  0.681899                   0.296255     1.000000   \n",
       "137  0.074071  0.460207  0.444862                   0.312196     0.636052   \n",
       "138  0.074672  0.719582  0.597443                   0.241884     0.754096   \n",
       "139  0.861733  0.066044  0.064422                   0.938579     0.039600   \n",
       "140  0.242339  0.239148  0.497708                   0.498061     0.479255   \n",
       "141  0.737837  0.123088  0.249290                   0.857726     0.113028   \n",
       "142  0.736400  0.088800  0.366964                   0.878258     0.161588   \n",
       "143  0.851731  0.048748  0.259864                   0.925294     0.096625   \n",
       "144  0.284387  0.146664  0.672039                   0.570640     0.514095   \n",
       "145  0.727530  0.049789  0.063248                   0.848463     0.070763   \n",
       "146  0.794043  0.027502  0.149330                   0.880099     0.082796   \n",
       "147  0.471033  0.240571  0.363636                   0.592830     0.277197   \n",
       "148  0.705738  0.058311  0.381418                   0.856901     0.176308   \n",
       "149  0.280717  0.160962  0.768933                   0.561061     0.557869   \n",
       "150  0.020219  0.554469  0.368241                   0.141403     0.833108   \n",
       "151  0.743322  0.083516  0.375759                   0.887884     0.165842   \n",
       "152  0.849902  0.019333  0.145730                   0.949844     0.070827   \n",
       "153  0.397566  0.320199  0.466986                   0.569552     0.348194   \n",
       "154  0.124393  0.248500  0.487117                   0.370300     0.549832   \n",
       "155  0.487581  0.123430  0.352985                   0.643946     0.266580   \n",
       "156  0.859038  0.087688  0.124883                   0.934718     0.061451   \n",
       "157  0.842537  0.110994  0.204451                   0.927244     0.086240   \n",
       "158  0.050335  0.567271  0.411831                   0.281598     0.670655   \n",
       "159  0.486603  0.134009  0.340928                   0.640326     0.263973   \n",
       "160  0.173193  0.210094  0.505773                   0.336097     0.543099   \n",
       "161  0.494194  0.147221  0.406913                   0.714284     0.248651   \n",
       "\n",
       "     sum variance  sum entropy   entropy  difference variance  \\\n",
       "0        0.503203     0.699561  0.680072             0.143376   \n",
       "1        0.222110     0.142707  0.124576             0.695182   \n",
       "2        0.229158     0.305093  0.272178             0.536824   \n",
       "3        0.340649     0.935801  0.905857             0.046132   \n",
       "4        0.058167     0.673827  0.645537             0.162975   \n",
       "5        0.176298     0.196664  0.177152             0.647691   \n",
       "6        0.002042     0.711789  0.647242             0.255335   \n",
       "7        0.177799     0.220557  0.198897             0.622483   \n",
       "8        0.012969     0.010677  0.008506             0.847751   \n",
       "9        0.179878     0.156350  0.132000             0.687980   \n",
       "10       0.280477     0.663436  0.601878             0.247823   \n",
       "11       0.171341     0.186406  0.160340             0.650283   \n",
       "12       0.193210     0.226917  0.204334             0.613916   \n",
       "13       0.348484     0.186493  0.168041             0.682123   \n",
       "14       0.184171     0.197792  0.170491             0.645881   \n",
       "15       0.393083     0.905366  0.885406             0.045673   \n",
       "16       0.039227     0.054511  0.049274             0.782016   \n",
       "17       0.589292     0.534461  0.512072             0.282558   \n",
       "18       0.169059     0.178687  0.161216             0.662719   \n",
       "19       0.143284     0.064152  0.054446             0.771295   \n",
       "20       0.024357     0.000000  0.000000             0.868280   \n",
       "21       0.304000     0.270962  0.214235             0.748563   \n",
       "22       0.769660     0.598892  0.547214             0.264344   \n",
       "23       0.272363     0.232108  0.194935             0.624206   \n",
       "24       0.181421     0.861132  0.854264             0.037339   \n",
       "25       0.420090     0.891780  0.897603             0.029799   \n",
       "26       0.344112     0.381336  0.372120             0.469400   \n",
       "27       0.262957     0.323813  0.270001             0.550242   \n",
       "28       0.601981     0.887251  0.830420             0.083958   \n",
       "29       0.745472     0.830760  0.789128             0.099432   \n",
       "..            ...          ...       ...                  ...   \n",
       "132      0.444006     0.275301  0.241708             0.568529   \n",
       "133      0.445922     0.659979  0.627627             0.185861   \n",
       "134      0.341517     0.604308  0.529951             0.399729   \n",
       "135      0.076012     0.085511  0.071197             0.944586   \n",
       "136      0.680121     0.903889  0.834994             0.108456   \n",
       "137      0.443332     0.846141  0.782075             0.115774   \n",
       "138      0.594751     0.860951  0.818228             0.081610   \n",
       "139      0.064324     0.102768  0.088436             0.758093   \n",
       "140      0.497580     0.623507  0.570164             0.235208   \n",
       "141      0.249277     0.209732  0.187314             0.626262   \n",
       "142      0.367415     0.201976  0.174083             0.652291   \n",
       "143      0.260306     0.116619  0.102781             0.716928   \n",
       "144      0.672840     0.576264  0.514959             0.313239   \n",
       "145      0.063242     0.193881  0.176635             0.654409   \n",
       "146      0.149647     0.162030  0.145990             0.682160   \n",
       "147      0.363198     0.389181  0.398795             0.398540   \n",
       "148      0.382078     0.230541  0.200624             0.618844   \n",
       "149      0.769868     0.583372  0.523030             0.292712   \n",
       "150      0.365991     0.933129  0.902192             0.047187   \n",
       "151      0.376260     0.191724  0.163524             0.659353   \n",
       "152      0.146087     0.107178  0.087951             0.862835   \n",
       "153      0.466319     0.466221  0.454695             0.355109   \n",
       "154      0.486911     0.801573  0.735678             0.145483   \n",
       "155      0.353203     0.371759  0.360644             0.455881   \n",
       "156      0.124796     0.103159  0.089044             0.749533   \n",
       "157      0.204407     0.116193  0.100923             0.717716   \n",
       "158      0.409605     0.884174  0.813312             0.105402   \n",
       "159      0.341058     0.371184  0.361974             0.466402   \n",
       "160      0.505831     0.700749  0.679332             0.150142   \n",
       "161      0.407114     0.400247  0.360798             0.444975   \n",
       "\n",
       "     difference entropy    mean_B    mean_G    mean_R     std_B     std_G  \\\n",
       "0              0.709940  0.313805  0.528787  0.614273  0.304604  0.615009   \n",
       "1              0.139885  0.220593  0.101461  0.053140  0.559716  0.442374   \n",
       "2              0.286056  0.298854  0.167377  0.074775  0.539028  0.447906   \n",
       "3              0.817664  0.265694  0.874486  0.759549  0.398753  0.512621   \n",
       "4              0.641177  0.170598  0.232265  0.307716  0.091011  0.135052   \n",
       "5              0.198023  0.176512  0.076325  0.152918  0.394871  0.249911   \n",
       "6              0.552105  0.231839  0.171394  0.286421  0.087317  0.000000   \n",
       "7              0.220909  0.225201  0.090681  0.143445  0.463693  0.267135   \n",
       "8              0.011066  0.058835  0.005192  0.000907  0.260821  0.170652   \n",
       "9              0.131606  0.225653  0.099282  0.044162  0.561475  0.415473   \n",
       "10             0.536012  0.124879  0.416336  0.442787  0.188226  0.449327   \n",
       "11             0.165443  0.211575  0.128075  0.035218  0.444714  0.439441   \n",
       "12             0.227441  0.196033  0.095771  0.170095  0.400597  0.273870   \n",
       "13             0.198418  0.239835  0.152197  0.131952  0.500756  0.535543   \n",
       "14             0.175686  0.223086  0.136636  0.037988  0.459744  0.455840   \n",
       "15             0.838216  0.267264  0.825950  0.716113  0.410896  0.566080   \n",
       "16             0.066333  0.081997  0.009346  0.026549  0.312601  0.146925   \n",
       "17             0.563096  0.413763  0.430469  0.534928  0.399168  0.659911   \n",
       "18             0.182666  0.167726  0.069320  0.146390  0.389611  0.240168   \n",
       "19             0.061737  0.169317  0.058562  0.028645  0.516078  0.360929   \n",
       "20             0.000000  0.069477  0.000000  0.011742  0.313507  0.153461   \n",
       "21             0.149985  0.398479  0.210074  0.071560  0.682240  0.573719   \n",
       "22             0.526277  0.652788  0.494717  0.669729  0.627026  0.731178   \n",
       "23             0.182920  0.301243  0.143018  0.089608  0.613827  0.458148   \n",
       "24             0.834893  0.149505  0.581961  0.565702  0.134371  0.340063   \n",
       "25             0.899544  0.316002  0.875428  0.738687  0.418568  0.599603   \n",
       "26             0.457843  0.414242  0.259100  0.252296  0.540759  0.500993   \n",
       "27             0.233951  0.389343  0.207296  0.041097  0.677191  0.551749   \n",
       "28             0.725498  0.742508  0.841126  0.848570  0.533037  0.695461   \n",
       "29             0.764286  0.632374  0.770294  0.750642  0.844418  0.764848   \n",
       "..                  ...       ...       ...       ...       ...       ...   \n",
       "132            0.250496  0.473873  0.236883  0.104340  0.838114  0.672522   \n",
       "133            0.646859  0.247395  0.519701  0.374571  0.354900  0.684364   \n",
       "134            0.440212  0.667015  0.338520  0.284144  0.703021  0.479525   \n",
       "135            0.069753  0.136550  0.054957  0.001686  0.398962  0.311373   \n",
       "136            0.708133  0.617055  0.985698  1.000000  0.877554  0.723824   \n",
       "137            0.676443  0.010460  0.674330  0.625163  0.059598  0.646336   \n",
       "138            0.773312  0.311437  0.756115  0.766888  0.520741  0.700660   \n",
       "139            0.095588  0.123677  0.055475  0.002988  0.341972  0.291142   \n",
       "140            0.546601  0.239183  0.517943  0.398800  0.357749  0.719585   \n",
       "141            0.213894  0.238091  0.112843  0.093472  0.549612  0.411648   \n",
       "142            0.174873  0.285335  0.145946  0.171685  0.585209  0.493819   \n",
       "143            0.118980  0.231058  0.104268  0.058751  0.603979  0.484588   \n",
       "144            0.471214  1.000000  0.481350  0.424212  1.000000  0.735300   \n",
       "145            0.209215  0.173089  0.086279  0.025816  0.325622  0.252005   \n",
       "146            0.168556  0.183661  0.062259  0.122114  0.439205  0.227237   \n",
       "147            0.530844  0.363709  0.259050  0.284365  0.446762  0.503644   \n",
       "148            0.202152  0.306789  0.160876  0.182036  0.597425  0.507315   \n",
       "149            0.481569  0.640075  0.484277  0.654803  0.626683  0.731693   \n",
       "150            0.812903  0.283739  0.874879  0.766307  0.431001  0.531658   \n",
       "151            0.161803  0.389260  0.185456  0.067530  0.806767  0.646458   \n",
       "152            0.079129  0.174678  0.089540  0.017940  0.451763  0.412236   \n",
       "153            0.541982  0.175946  0.320325  0.429330  0.192105  0.578639   \n",
       "154            0.644228  0.282172  0.545305  0.567497  0.433477  0.601541   \n",
       "155            0.442211  0.355406  0.248507  0.274784  0.440869  0.493297   \n",
       "156            0.100213  0.108491  0.074117  0.037926  0.282874  0.351699   \n",
       "157            0.112887  0.231374  0.096031  0.042288  0.606232  0.446972   \n",
       "158            0.674642  0.000000  0.714094  0.653454  0.000000  0.620931   \n",
       "159            0.446690  0.406217  0.251548  0.246625  0.540365  0.497705   \n",
       "160            0.702214  0.308823  0.517248  0.604296  0.302371  0.616105   \n",
       "161            0.384820  0.429429  0.265146  0.155253  0.662022  0.587674   \n",
       "\n",
       "        std_R  \n",
       "0    0.737568  \n",
       "1    0.309818  \n",
       "2    0.289288  \n",
       "3    0.594145  \n",
       "4    0.348236  \n",
       "5    0.468215  \n",
       "6    0.297518  \n",
       "7    0.421028  \n",
       "8    0.017506  \n",
       "9    0.177397  \n",
       "10   0.545056  \n",
       "11   0.162066  \n",
       "12   0.480086  \n",
       "13   0.451087  \n",
       "14   0.174449  \n",
       "15   0.619856  \n",
       "16   0.165443  \n",
       "17   0.783451  \n",
       "18   0.463173  \n",
       "19   0.163771  \n",
       "20   0.076231  \n",
       "21   0.182825  \n",
       "22   0.923630  \n",
       "23   0.387999  \n",
       "24   0.452158  \n",
       "25   0.630198  \n",
       "26   0.459192  \n",
       "27   0.188445  \n",
       "28   0.743058  \n",
       "29   0.864680  \n",
       "..        ...  \n",
       "132  0.406499  \n",
       "133  0.504045  \n",
       "134  0.442842  \n",
       "135  0.007778  \n",
       "136  0.827395  \n",
       "137  0.653199  \n",
       "138  0.771711  \n",
       "139  0.021512  \n",
       "140  0.548627  \n",
       "141  0.397622  \n",
       "142  0.516183  \n",
       "143  0.318007  \n",
       "144  0.614458  \n",
       "145  0.088513  \n",
       "146  0.403000  \n",
       "147  0.544987  \n",
       "148  0.525931  \n",
       "149  0.922313  \n",
       "150  0.613396  \n",
       "151  0.239361  \n",
       "152  0.115770  \n",
       "153  0.739005  \n",
       "154  0.699214  \n",
       "155  0.538858  \n",
       "156  0.183958  \n",
       "157  0.172812  \n",
       "158  0.626360  \n",
       "159  0.457404  \n",
       "160  0.740104  \n",
       "161  0.487641  \n",
       "\n",
       "[162 rows x 16 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      3\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      3\n",
       "5      3\n",
       "6      1\n",
       "7      3\n",
       "8      0\n",
       "9      0\n",
       "10     0\n",
       "11     0\n",
       "12     3\n",
       "13     0\n",
       "14     0\n",
       "15     0\n",
       "16     2\n",
       "17     1\n",
       "18     3\n",
       "19     0\n",
       "20     0\n",
       "21     0\n",
       "22     3\n",
       "23     0\n",
       "24     0\n",
       "25     0\n",
       "26     3\n",
       "27     0\n",
       "28     0\n",
       "29     0\n",
       "      ..\n",
       "132    0\n",
       "133    0\n",
       "134    3\n",
       "135    0\n",
       "136    0\n",
       "137    0\n",
       "138    0\n",
       "139    0\n",
       "140    0\n",
       "141    0\n",
       "142    2\n",
       "143    0\n",
       "144    3\n",
       "145    0\n",
       "146    3\n",
       "147    3\n",
       "148    2\n",
       "149    3\n",
       "150    0\n",
       "151    0\n",
       "152    0\n",
       "153    3\n",
       "154    0\n",
       "155    3\n",
       "156    0\n",
       "157    0\n",
       "158    0\n",
       "159    3\n",
       "160    3\n",
       "161    0\n",
       "Name: label, Length: 162, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy</th>\n",
       "      <th>contrast</th>\n",
       "      <th>variance</th>\n",
       "      <th>inverse difference moment</th>\n",
       "      <th>sum average</th>\n",
       "      <th>sum variance</th>\n",
       "      <th>sum entropy</th>\n",
       "      <th>entropy</th>\n",
       "      <th>difference variance</th>\n",
       "      <th>difference entropy</th>\n",
       "      <th>mean_B</th>\n",
       "      <th>mean_G</th>\n",
       "      <th>mean_R</th>\n",
       "      <th>std_B</th>\n",
       "      <th>std_G</th>\n",
       "      <th>std_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.912701</td>\n",
       "      <td>0.103995</td>\n",
       "      <td>0.057363</td>\n",
       "      <td>0.973406</td>\n",
       "      <td>0.026295</td>\n",
       "      <td>0.057030</td>\n",
       "      <td>0.060228</td>\n",
       "      <td>0.048115</td>\n",
       "      <td>0.987541</td>\n",
       "      <td>0.040413</td>\n",
       "      <td>0.111921</td>\n",
       "      <td>0.038536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.365689</td>\n",
       "      <td>0.274969</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.802899</td>\n",
       "      <td>0.131688</td>\n",
       "      <td>0.176016</td>\n",
       "      <td>0.897297</td>\n",
       "      <td>0.083034</td>\n",
       "      <td>0.175788</td>\n",
       "      <td>0.151498</td>\n",
       "      <td>0.134484</td>\n",
       "      <td>0.679371</td>\n",
       "      <td>0.157074</td>\n",
       "      <td>0.146306</td>\n",
       "      <td>0.093407</td>\n",
       "      <td>0.057747</td>\n",
       "      <td>0.366779</td>\n",
       "      <td>0.386870</td>\n",
       "      <td>0.294857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.654991</td>\n",
       "      <td>0.023718</td>\n",
       "      <td>0.268112</td>\n",
       "      <td>0.869235</td>\n",
       "      <td>0.167608</td>\n",
       "      <td>0.268718</td>\n",
       "      <td>0.252792</td>\n",
       "      <td>0.209413</td>\n",
       "      <td>0.614776</td>\n",
       "      <td>0.177381</td>\n",
       "      <td>0.323161</td>\n",
       "      <td>0.202048</td>\n",
       "      <td>0.050047</td>\n",
       "      <td>0.568116</td>\n",
       "      <td>0.568696</td>\n",
       "      <td>0.211591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.844038</td>\n",
       "      <td>0.050417</td>\n",
       "      <td>0.205173</td>\n",
       "      <td>0.962903</td>\n",
       "      <td>0.089557</td>\n",
       "      <td>0.205483</td>\n",
       "      <td>0.101417</td>\n",
       "      <td>0.076707</td>\n",
       "      <td>0.754815</td>\n",
       "      <td>0.055386</td>\n",
       "      <td>0.230158</td>\n",
       "      <td>0.110132</td>\n",
       "      <td>0.020558</td>\n",
       "      <td>0.574570</td>\n",
       "      <td>0.489568</td>\n",
       "      <td>0.154522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.037351</td>\n",
       "      <td>0.704891</td>\n",
       "      <td>0.516688</td>\n",
       "      <td>0.168996</td>\n",
       "      <td>0.830211</td>\n",
       "      <td>0.513899</td>\n",
       "      <td>0.925518</td>\n",
       "      <td>0.883008</td>\n",
       "      <td>0.053791</td>\n",
       "      <td>0.806301</td>\n",
       "      <td>0.340693</td>\n",
       "      <td>0.834916</td>\n",
       "      <td>0.837268</td>\n",
       "      <td>0.529395</td>\n",
       "      <td>0.631379</td>\n",
       "      <td>0.728693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.009876</td>\n",
       "      <td>0.422267</td>\n",
       "      <td>0.353680</td>\n",
       "      <td>0.220852</td>\n",
       "      <td>0.934069</td>\n",
       "      <td>0.352165</td>\n",
       "      <td>0.945251</td>\n",
       "      <td>0.855314</td>\n",
       "      <td>0.097865</td>\n",
       "      <td>0.627474</td>\n",
       "      <td>0.447481</td>\n",
       "      <td>0.972793</td>\n",
       "      <td>0.842667</td>\n",
       "      <td>0.621903</td>\n",
       "      <td>0.510829</td>\n",
       "      <td>0.576742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.507251</td>\n",
       "      <td>0.153106</td>\n",
       "      <td>0.355712</td>\n",
       "      <td>0.656894</td>\n",
       "      <td>0.262457</td>\n",
       "      <td>0.355764</td>\n",
       "      <td>0.351175</td>\n",
       "      <td>0.342577</td>\n",
       "      <td>0.472403</td>\n",
       "      <td>0.427251</td>\n",
       "      <td>0.341421</td>\n",
       "      <td>0.244177</td>\n",
       "      <td>0.274670</td>\n",
       "      <td>0.435213</td>\n",
       "      <td>0.495676</td>\n",
       "      <td>0.540223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.715721</td>\n",
       "      <td>0.074629</td>\n",
       "      <td>0.287857</td>\n",
       "      <td>0.865516</td>\n",
       "      <td>0.145956</td>\n",
       "      <td>0.288212</td>\n",
       "      <td>0.218153</td>\n",
       "      <td>0.188595</td>\n",
       "      <td>0.626046</td>\n",
       "      <td>0.193984</td>\n",
       "      <td>0.350272</td>\n",
       "      <td>0.162270</td>\n",
       "      <td>0.063109</td>\n",
       "      <td>0.710056</td>\n",
       "      <td>0.531423</td>\n",
       "      <td>0.248220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.328106</td>\n",
       "      <td>0.049275</td>\n",
       "      <td>0.409954</td>\n",
       "      <td>0.619402</td>\n",
       "      <td>0.367306</td>\n",
       "      <td>0.410731</td>\n",
       "      <td>0.548129</td>\n",
       "      <td>0.485241</td>\n",
       "      <td>0.409449</td>\n",
       "      <td>0.428987</td>\n",
       "      <td>0.398853</td>\n",
       "      <td>0.325164</td>\n",
       "      <td>0.430801</td>\n",
       "      <td>0.428924</td>\n",
       "      <td>0.489261</td>\n",
       "      <td>0.685704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.971210</td>\n",
       "      <td>0.022061</td>\n",
       "      <td>0.130377</td>\n",
       "      <td>0.994994</td>\n",
       "      <td>0.033170</td>\n",
       "      <td>0.130683</td>\n",
       "      <td>0.021014</td>\n",
       "      <td>0.015535</td>\n",
       "      <td>0.821306</td>\n",
       "      <td>0.011573</td>\n",
       "      <td>0.125511</td>\n",
       "      <td>0.038168</td>\n",
       "      <td>0.021424</td>\n",
       "      <td>0.476160</td>\n",
       "      <td>0.352179</td>\n",
       "      <td>0.169903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.673622</td>\n",
       "      <td>0.236813</td>\n",
       "      <td>0.206139</td>\n",
       "      <td>0.811437</td>\n",
       "      <td>0.139913</td>\n",
       "      <td>0.205368</td>\n",
       "      <td>0.233830</td>\n",
       "      <td>0.216615</td>\n",
       "      <td>0.573074</td>\n",
       "      <td>0.271532</td>\n",
       "      <td>0.141284</td>\n",
       "      <td>0.169710</td>\n",
       "      <td>0.074488</td>\n",
       "      <td>0.268916</td>\n",
       "      <td>0.480453</td>\n",
       "      <td>0.260380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.880415</td>\n",
       "      <td>0.051604</td>\n",
       "      <td>0.117267</td>\n",
       "      <td>0.942785</td>\n",
       "      <td>0.054652</td>\n",
       "      <td>0.117372</td>\n",
       "      <td>0.087996</td>\n",
       "      <td>0.076518</td>\n",
       "      <td>0.742533</td>\n",
       "      <td>0.085906</td>\n",
       "      <td>0.148910</td>\n",
       "      <td>0.057173</td>\n",
       "      <td>0.045037</td>\n",
       "      <td>0.411167</td>\n",
       "      <td>0.300986</td>\n",
       "      <td>0.174222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.801684</td>\n",
       "      <td>0.024262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.915328</td>\n",
       "      <td>0.026728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132504</td>\n",
       "      <td>0.113929</td>\n",
       "      <td>0.760796</td>\n",
       "      <td>0.122401</td>\n",
       "      <td>0.086998</td>\n",
       "      <td>0.039078</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.192364</td>\n",
       "      <td>0.138401</td>\n",
       "      <td>0.026030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.811920</td>\n",
       "      <td>0.410706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.901127</td>\n",
       "      <td>0.407058</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.970119</td>\n",
       "      <td>0.728078</td>\n",
       "      <td>0.891336</td>\n",
       "      <td>0.855435</td>\n",
       "      <td>0.772312</td>\n",
       "      <td>0.459785</td>\n",
       "      <td>0.682910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.843534</td>\n",
       "      <td>0.069507</td>\n",
       "      <td>0.259898</td>\n",
       "      <td>0.921249</td>\n",
       "      <td>0.099657</td>\n",
       "      <td>0.260220</td>\n",
       "      <td>0.122099</td>\n",
       "      <td>0.107735</td>\n",
       "      <td>0.710995</td>\n",
       "      <td>0.124364</td>\n",
       "      <td>0.240255</td>\n",
       "      <td>0.108289</td>\n",
       "      <td>0.057490</td>\n",
       "      <td>0.613340</td>\n",
       "      <td>0.486935</td>\n",
       "      <td>0.315547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.140590</td>\n",
       "      <td>0.316887</td>\n",
       "      <td>0.334944</td>\n",
       "      <td>0.444251</td>\n",
       "      <td>0.499718</td>\n",
       "      <td>0.333999</td>\n",
       "      <td>0.712943</td>\n",
       "      <td>0.642178</td>\n",
       "      <td>0.214201</td>\n",
       "      <td>0.548127</td>\n",
       "      <td>0.127916</td>\n",
       "      <td>0.502639</td>\n",
       "      <td>0.532559</td>\n",
       "      <td>0.197047</td>\n",
       "      <td>0.506081</td>\n",
       "      <td>0.593324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.032007</td>\n",
       "      <td>0.147267</td>\n",
       "      <td>0.970536</td>\n",
       "      <td>0.051183</td>\n",
       "      <td>0.147553</td>\n",
       "      <td>0.064473</td>\n",
       "      <td>0.052746</td>\n",
       "      <td>0.782980</td>\n",
       "      <td>0.050377</td>\n",
       "      <td>0.165452</td>\n",
       "      <td>0.060708</td>\n",
       "      <td>0.020644</td>\n",
       "      <td>0.521208</td>\n",
       "      <td>0.386048</td>\n",
       "      <td>0.144966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.848981</td>\n",
       "      <td>0.071954</td>\n",
       "      <td>0.172494</td>\n",
       "      <td>0.923166</td>\n",
       "      <td>0.078513</td>\n",
       "      <td>0.172605</td>\n",
       "      <td>0.111210</td>\n",
       "      <td>0.097702</td>\n",
       "      <td>0.719215</td>\n",
       "      <td>0.113572</td>\n",
       "      <td>0.198191</td>\n",
       "      <td>0.069739</td>\n",
       "      <td>0.085985</td>\n",
       "      <td>0.495080</td>\n",
       "      <td>0.312069</td>\n",
       "      <td>0.325535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.954383</td>\n",
       "      <td>0.054051</td>\n",
       "      <td>0.066594</td>\n",
       "      <td>0.986426</td>\n",
       "      <td>0.021105</td>\n",
       "      <td>0.066571</td>\n",
       "      <td>0.033350</td>\n",
       "      <td>0.026036</td>\n",
       "      <td>0.817499</td>\n",
       "      <td>0.023627</td>\n",
       "      <td>0.112506</td>\n",
       "      <td>0.026828</td>\n",
       "      <td>0.009726</td>\n",
       "      <td>0.414651</td>\n",
       "      <td>0.261029</td>\n",
       "      <td>0.081890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.587120</td>\n",
       "      <td>0.191977</td>\n",
       "      <td>0.251218</td>\n",
       "      <td>0.780205</td>\n",
       "      <td>0.180097</td>\n",
       "      <td>0.250809</td>\n",
       "      <td>0.302527</td>\n",
       "      <td>0.269404</td>\n",
       "      <td>0.525626</td>\n",
       "      <td>0.294182</td>\n",
       "      <td>0.265157</td>\n",
       "      <td>0.199069</td>\n",
       "      <td>0.114448</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.470486</td>\n",
       "      <td>0.359641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.217640</td>\n",
       "      <td>0.240444</td>\n",
       "      <td>0.485385</td>\n",
       "      <td>0.472427</td>\n",
       "      <td>0.491405</td>\n",
       "      <td>0.485222</td>\n",
       "      <td>0.656693</td>\n",
       "      <td>0.601077</td>\n",
       "      <td>0.216915</td>\n",
       "      <td>0.567732</td>\n",
       "      <td>0.249824</td>\n",
       "      <td>0.529215</td>\n",
       "      <td>0.411167</td>\n",
       "      <td>0.356654</td>\n",
       "      <td>0.709945</td>\n",
       "      <td>0.542708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.260285</td>\n",
       "      <td>0.006904</td>\n",
       "      <td>0.391357</td>\n",
       "      <td>0.582404</td>\n",
       "      <td>0.386956</td>\n",
       "      <td>0.392338</td>\n",
       "      <td>0.630229</td>\n",
       "      <td>0.550682</td>\n",
       "      <td>0.364547</td>\n",
       "      <td>0.446804</td>\n",
       "      <td>0.422132</td>\n",
       "      <td>0.344042</td>\n",
       "      <td>0.448278</td>\n",
       "      <td>0.419722</td>\n",
       "      <td>0.473452</td>\n",
       "      <td>0.672721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.171980</td>\n",
       "      <td>0.197873</td>\n",
       "      <td>0.387828</td>\n",
       "      <td>0.340331</td>\n",
       "      <td>0.477394</td>\n",
       "      <td>0.387692</td>\n",
       "      <td>0.694496</td>\n",
       "      <td>0.672813</td>\n",
       "      <td>0.159429</td>\n",
       "      <td>0.697615</td>\n",
       "      <td>0.929689</td>\n",
       "      <td>0.522162</td>\n",
       "      <td>0.216727</td>\n",
       "      <td>0.777439</td>\n",
       "      <td>0.618846</td>\n",
       "      <td>0.340381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.896178</td>\n",
       "      <td>0.063057</td>\n",
       "      <td>0.135481</td>\n",
       "      <td>0.969489</td>\n",
       "      <td>0.052887</td>\n",
       "      <td>0.135560</td>\n",
       "      <td>0.076344</td>\n",
       "      <td>0.059401</td>\n",
       "      <td>0.869805</td>\n",
       "      <td>0.047101</td>\n",
       "      <td>0.147634</td>\n",
       "      <td>0.064569</td>\n",
       "      <td>0.021641</td>\n",
       "      <td>0.444405</td>\n",
       "      <td>0.372508</td>\n",
       "      <td>0.142865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.293539</td>\n",
       "      <td>0.250586</td>\n",
       "      <td>0.745285</td>\n",
       "      <td>0.589536</td>\n",
       "      <td>0.498973</td>\n",
       "      <td>0.745647</td>\n",
       "      <td>0.599466</td>\n",
       "      <td>0.531970</td>\n",
       "      <td>0.305995</td>\n",
       "      <td>0.482356</td>\n",
       "      <td>0.257551</td>\n",
       "      <td>0.484984</td>\n",
       "      <td>0.541190</td>\n",
       "      <td>0.579617</td>\n",
       "      <td>0.803037</td>\n",
       "      <td>0.856679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.031995</td>\n",
       "      <td>0.874942</td>\n",
       "      <td>0.399836</td>\n",
       "      <td>0.139135</td>\n",
       "      <td>0.804057</td>\n",
       "      <td>0.395797</td>\n",
       "      <td>0.906055</td>\n",
       "      <td>0.891244</td>\n",
       "      <td>0.041939</td>\n",
       "      <td>0.852812</td>\n",
       "      <td>0.290984</td>\n",
       "      <td>0.847244</td>\n",
       "      <td>0.730920</td>\n",
       "      <td>0.426295</td>\n",
       "      <td>0.570417</td>\n",
       "      <td>0.621260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.899593</td>\n",
       "      <td>0.053779</td>\n",
       "      <td>0.158514</td>\n",
       "      <td>0.937548</td>\n",
       "      <td>0.058574</td>\n",
       "      <td>0.158699</td>\n",
       "      <td>0.082211</td>\n",
       "      <td>0.075743</td>\n",
       "      <td>0.747268</td>\n",
       "      <td>0.098770</td>\n",
       "      <td>0.142637</td>\n",
       "      <td>0.054676</td>\n",
       "      <td>0.066041</td>\n",
       "      <td>0.420517</td>\n",
       "      <td>0.324368</td>\n",
       "      <td>0.275003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.758134</td>\n",
       "      <td>0.109442</td>\n",
       "      <td>0.189716</td>\n",
       "      <td>0.897108</td>\n",
       "      <td>0.109560</td>\n",
       "      <td>0.189649</td>\n",
       "      <td>0.172731</td>\n",
       "      <td>0.147778</td>\n",
       "      <td>0.661098</td>\n",
       "      <td>0.153561</td>\n",
       "      <td>0.233146</td>\n",
       "      <td>0.117561</td>\n",
       "      <td>0.071364</td>\n",
       "      <td>0.483006</td>\n",
       "      <td>0.396386</td>\n",
       "      <td>0.262710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.163818</td>\n",
       "      <td>0.135848</td>\n",
       "      <td>0.718995</td>\n",
       "      <td>0.542462</td>\n",
       "      <td>0.671649</td>\n",
       "      <td>0.719964</td>\n",
       "      <td>0.716340</td>\n",
       "      <td>0.624908</td>\n",
       "      <td>0.261304</td>\n",
       "      <td>0.490682</td>\n",
       "      <td>0.860006</td>\n",
       "      <td>0.623702</td>\n",
       "      <td>0.665884</td>\n",
       "      <td>0.776326</td>\n",
       "      <td>0.741387</td>\n",
       "      <td>0.779577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.038905</td>\n",
       "      <td>0.586514</td>\n",
       "      <td>0.503882</td>\n",
       "      <td>0.164647</td>\n",
       "      <td>0.816463</td>\n",
       "      <td>0.501751</td>\n",
       "      <td>0.919728</td>\n",
       "      <td>0.880194</td>\n",
       "      <td>0.051927</td>\n",
       "      <td>0.808667</td>\n",
       "      <td>0.311832</td>\n",
       "      <td>0.825653</td>\n",
       "      <td>0.818722</td>\n",
       "      <td>0.493654</td>\n",
       "      <td>0.626898</td>\n",
       "      <td>0.716824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.920701</td>\n",
       "      <td>0.040314</td>\n",
       "      <td>0.092649</td>\n",
       "      <td>0.970882</td>\n",
       "      <td>0.035811</td>\n",
       "      <td>0.092764</td>\n",
       "      <td>0.055561</td>\n",
       "      <td>0.046131</td>\n",
       "      <td>0.782385</td>\n",
       "      <td>0.050987</td>\n",
       "      <td>0.139915</td>\n",
       "      <td>0.044773</td>\n",
       "      <td>0.011418</td>\n",
       "      <td>0.448850</td>\n",
       "      <td>0.308036</td>\n",
       "      <td>0.097947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.726078</td>\n",
       "      <td>0.115909</td>\n",
       "      <td>0.300091</td>\n",
       "      <td>0.884202</td>\n",
       "      <td>0.149577</td>\n",
       "      <td>0.300234</td>\n",
       "      <td>0.202148</td>\n",
       "      <td>0.172830</td>\n",
       "      <td>0.649604</td>\n",
       "      <td>0.174849</td>\n",
       "      <td>0.322473</td>\n",
       "      <td>0.177353</td>\n",
       "      <td>0.046490</td>\n",
       "      <td>0.668801</td>\n",
       "      <td>0.601540</td>\n",
       "      <td>0.225496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.807777</td>\n",
       "      <td>0.116304</td>\n",
       "      <td>0.218959</td>\n",
       "      <td>0.917608</td>\n",
       "      <td>0.099300</td>\n",
       "      <td>0.218917</td>\n",
       "      <td>0.146716</td>\n",
       "      <td>0.124237</td>\n",
       "      <td>0.703470</td>\n",
       "      <td>0.126164</td>\n",
       "      <td>0.241203</td>\n",
       "      <td>0.119873</td>\n",
       "      <td>0.028485</td>\n",
       "      <td>0.595669</td>\n",
       "      <td>0.503300</td>\n",
       "      <td>0.167518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.749143</td>\n",
       "      <td>0.094078</td>\n",
       "      <td>0.381677</td>\n",
       "      <td>0.889109</td>\n",
       "      <td>0.162363</td>\n",
       "      <td>0.382130</td>\n",
       "      <td>0.186939</td>\n",
       "      <td>0.160144</td>\n",
       "      <td>0.671443</td>\n",
       "      <td>0.160701</td>\n",
       "      <td>0.230659</td>\n",
       "      <td>0.140920</td>\n",
       "      <td>0.199346</td>\n",
       "      <td>0.511220</td>\n",
       "      <td>0.489412</td>\n",
       "      <td>0.576189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.159620</td>\n",
       "      <td>0.318122</td>\n",
       "      <td>0.700541</td>\n",
       "      <td>0.396494</td>\n",
       "      <td>0.681425</td>\n",
       "      <td>0.700410</td>\n",
       "      <td>0.716595</td>\n",
       "      <td>0.662927</td>\n",
       "      <td>0.179710</td>\n",
       "      <td>0.615511</td>\n",
       "      <td>0.617823</td>\n",
       "      <td>0.688062</td>\n",
       "      <td>0.603715</td>\n",
       "      <td>0.690891</td>\n",
       "      <td>0.809813</td>\n",
       "      <td>0.692345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.026085</td>\n",
       "      <td>0.312549</td>\n",
       "      <td>0.024595</td>\n",
       "      <td>0.414045</td>\n",
       "      <td>0.321003</td>\n",
       "      <td>0.022976</td>\n",
       "      <td>0.828106</td>\n",
       "      <td>0.741574</td>\n",
       "      <td>0.183148</td>\n",
       "      <td>0.573303</td>\n",
       "      <td>0.382859</td>\n",
       "      <td>0.265135</td>\n",
       "      <td>0.416812</td>\n",
       "      <td>0.173793</td>\n",
       "      <td>0.031885</td>\n",
       "      <td>0.333213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.119864</td>\n",
       "      <td>0.390216</td>\n",
       "      <td>0.525686</td>\n",
       "      <td>0.407587</td>\n",
       "      <td>0.664672</td>\n",
       "      <td>0.524744</td>\n",
       "      <td>0.749218</td>\n",
       "      <td>0.676693</td>\n",
       "      <td>0.205149</td>\n",
       "      <td>0.566305</td>\n",
       "      <td>0.618787</td>\n",
       "      <td>0.681682</td>\n",
       "      <td>0.561207</td>\n",
       "      <td>0.671038</td>\n",
       "      <td>0.686257</td>\n",
       "      <td>0.585089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.267379</td>\n",
       "      <td>0.604305</td>\n",
       "      <td>0.411300</td>\n",
       "      <td>0.448197</td>\n",
       "      <td>0.412848</td>\n",
       "      <td>0.408858</td>\n",
       "      <td>0.563737</td>\n",
       "      <td>0.556675</td>\n",
       "      <td>0.214612</td>\n",
       "      <td>0.661302</td>\n",
       "      <td>0.244477</td>\n",
       "      <td>0.476542</td>\n",
       "      <td>0.266252</td>\n",
       "      <td>0.389821</td>\n",
       "      <td>0.677589</td>\n",
       "      <td>0.456193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.893015</td>\n",
       "      <td>0.105256</td>\n",
       "      <td>0.098113</td>\n",
       "      <td>0.957846</td>\n",
       "      <td>0.040973</td>\n",
       "      <td>0.097863</td>\n",
       "      <td>0.077010</td>\n",
       "      <td>0.063731</td>\n",
       "      <td>0.853903</td>\n",
       "      <td>0.068592</td>\n",
       "      <td>0.145840</td>\n",
       "      <td>0.054063</td>\n",
       "      <td>0.005795</td>\n",
       "      <td>0.464688</td>\n",
       "      <td>0.339510</td>\n",
       "      <td>0.040803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.727275</td>\n",
       "      <td>0.164323</td>\n",
       "      <td>0.273176</td>\n",
       "      <td>0.869686</td>\n",
       "      <td>0.143265</td>\n",
       "      <td>0.272977</td>\n",
       "      <td>0.204996</td>\n",
       "      <td>0.177072</td>\n",
       "      <td>0.746733</td>\n",
       "      <td>0.177171</td>\n",
       "      <td>0.218874</td>\n",
       "      <td>0.148886</td>\n",
       "      <td>0.117074</td>\n",
       "      <td>0.421086</td>\n",
       "      <td>0.477927</td>\n",
       "      <td>0.403525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       energy  contrast  variance  inverse difference moment  sum average  \\\n",
       "162  0.912701  0.103995  0.057363                   0.973406     0.026295   \n",
       "163  0.802899  0.131688  0.176016                   0.897297     0.083034   \n",
       "164  0.654991  0.023718  0.268112                   0.869235     0.167608   \n",
       "165  0.844038  0.050417  0.205173                   0.962903     0.089557   \n",
       "166  0.037351  0.704891  0.516688                   0.168996     0.830211   \n",
       "167  0.009876  0.422267  0.353680                   0.220852     0.934069   \n",
       "168  0.507251  0.153106  0.355712                   0.656894     0.262457   \n",
       "169  0.715721  0.074629  0.287857                   0.865516     0.145956   \n",
       "170  0.328106  0.049275  0.409954                   0.619402     0.367306   \n",
       "171  0.971210  0.022061  0.130377                   0.994994     0.033170   \n",
       "172  0.673622  0.236813  0.206139                   0.811437     0.139913   \n",
       "173  0.880415  0.051604  0.117267                   0.942785     0.054652   \n",
       "174  0.801684  0.024262  0.000000                   0.915328     0.026728   \n",
       "175  0.000000  0.811920  0.410706                   0.000000     0.901127   \n",
       "176  0.843534  0.069507  0.259898                   0.921249     0.099657   \n",
       "177  0.140590  0.316887  0.334944                   0.444251     0.499718   \n",
       "178  0.915000  0.032007  0.147267                   0.970536     0.051183   \n",
       "179  0.848981  0.071954  0.172494                   0.923166     0.078513   \n",
       "180  0.954383  0.054051  0.066594                   0.986426     0.021105   \n",
       "181  0.587120  0.191977  0.251218                   0.780205     0.180097   \n",
       "182  0.217640  0.240444  0.485385                   0.472427     0.491405   \n",
       "183  0.260285  0.006904  0.391357                   0.582404     0.386956   \n",
       "184  0.171980  0.197873  0.387828                   0.340331     0.477394   \n",
       "185  0.896178  0.063057  0.135481                   0.969489     0.052887   \n",
       "186  0.293539  0.250586  0.745285                   0.589536     0.498973   \n",
       "187  0.031995  0.874942  0.399836                   0.139135     0.804057   \n",
       "188  0.899593  0.053779  0.158514                   0.937548     0.058574   \n",
       "189  0.758134  0.109442  0.189716                   0.897108     0.109560   \n",
       "190  0.163818  0.135848  0.718995                   0.542462     0.671649   \n",
       "191  0.038905  0.586514  0.503882                   0.164647     0.816463   \n",
       "192  0.920701  0.040314  0.092649                   0.970882     0.035811   \n",
       "193  0.726078  0.115909  0.300091                   0.884202     0.149577   \n",
       "194  0.807777  0.116304  0.218959                   0.917608     0.099300   \n",
       "195  0.749143  0.094078  0.381677                   0.889109     0.162363   \n",
       "196  0.159620  0.318122  0.700541                   0.396494     0.681425   \n",
       "197  0.026085  0.312549  0.024595                   0.414045     0.321003   \n",
       "198  0.119864  0.390216  0.525686                   0.407587     0.664672   \n",
       "199  0.267379  0.604305  0.411300                   0.448197     0.412848   \n",
       "200  0.893015  0.105256  0.098113                   0.957846     0.040973   \n",
       "201  0.727275  0.164323  0.273176                   0.869686     0.143265   \n",
       "\n",
       "     sum variance  sum entropy   entropy  difference variance  \\\n",
       "162      0.057030     0.060228  0.048115             0.987541   \n",
       "163      0.175788     0.151498  0.134484             0.679371   \n",
       "164      0.268718     0.252792  0.209413             0.614776   \n",
       "165      0.205483     0.101417  0.076707             0.754815   \n",
       "166      0.513899     0.925518  0.883008             0.053791   \n",
       "167      0.352165     0.945251  0.855314             0.097865   \n",
       "168      0.355764     0.351175  0.342577             0.472403   \n",
       "169      0.288212     0.218153  0.188595             0.626046   \n",
       "170      0.410731     0.548129  0.485241             0.409449   \n",
       "171      0.130683     0.021014  0.015535             0.821306   \n",
       "172      0.205368     0.233830  0.216615             0.573074   \n",
       "173      0.117372     0.087996  0.076518             0.742533   \n",
       "174      0.000000     0.132504  0.113929             0.760796   \n",
       "175      0.407058     1.000000  1.000000             0.000000   \n",
       "176      0.260220     0.122099  0.107735             0.710995   \n",
       "177      0.333999     0.712943  0.642178             0.214201   \n",
       "178      0.147553     0.064473  0.052746             0.782980   \n",
       "179      0.172605     0.111210  0.097702             0.719215   \n",
       "180      0.066571     0.033350  0.026036             0.817499   \n",
       "181      0.250809     0.302527  0.269404             0.525626   \n",
       "182      0.485222     0.656693  0.601077             0.216915   \n",
       "183      0.392338     0.630229  0.550682             0.364547   \n",
       "184      0.387692     0.694496  0.672813             0.159429   \n",
       "185      0.135560     0.076344  0.059401             0.869805   \n",
       "186      0.745647     0.599466  0.531970             0.305995   \n",
       "187      0.395797     0.906055  0.891244             0.041939   \n",
       "188      0.158699     0.082211  0.075743             0.747268   \n",
       "189      0.189649     0.172731  0.147778             0.661098   \n",
       "190      0.719964     0.716340  0.624908             0.261304   \n",
       "191      0.501751     0.919728  0.880194             0.051927   \n",
       "192      0.092764     0.055561  0.046131             0.782385   \n",
       "193      0.300234     0.202148  0.172830             0.649604   \n",
       "194      0.218917     0.146716  0.124237             0.703470   \n",
       "195      0.382130     0.186939  0.160144             0.671443   \n",
       "196      0.700410     0.716595  0.662927             0.179710   \n",
       "197      0.022976     0.828106  0.741574             0.183148   \n",
       "198      0.524744     0.749218  0.676693             0.205149   \n",
       "199      0.408858     0.563737  0.556675             0.214612   \n",
       "200      0.097863     0.077010  0.063731             0.853903   \n",
       "201      0.272977     0.204996  0.177072             0.746733   \n",
       "\n",
       "     difference entropy    mean_B    mean_G    mean_R     std_B     std_G  \\\n",
       "162            0.040413  0.111921  0.038536  0.000000  0.365689  0.274969   \n",
       "163            0.157074  0.146306  0.093407  0.057747  0.366779  0.386870   \n",
       "164            0.177381  0.323161  0.202048  0.050047  0.568116  0.568696   \n",
       "165            0.055386  0.230158  0.110132  0.020558  0.574570  0.489568   \n",
       "166            0.806301  0.340693  0.834916  0.837268  0.529395  0.631379   \n",
       "167            0.627474  0.447481  0.972793  0.842667  0.621903  0.510829   \n",
       "168            0.427251  0.341421  0.244177  0.274670  0.435213  0.495676   \n",
       "169            0.193984  0.350272  0.162270  0.063109  0.710056  0.531423   \n",
       "170            0.428987  0.398853  0.325164  0.430801  0.428924  0.489261   \n",
       "171            0.011573  0.125511  0.038168  0.021424  0.476160  0.352179   \n",
       "172            0.271532  0.141284  0.169710  0.074488  0.268916  0.480453   \n",
       "173            0.085906  0.148910  0.057173  0.045037  0.411167  0.300986   \n",
       "174            0.122401  0.086998  0.039078  0.006200  0.192364  0.138401   \n",
       "175            0.970119  0.728078  0.891336  0.855435  0.772312  0.459785   \n",
       "176            0.124364  0.240255  0.108289  0.057490  0.613340  0.486935   \n",
       "177            0.548127  0.127916  0.502639  0.532559  0.197047  0.506081   \n",
       "178            0.050377  0.165452  0.060708  0.020644  0.521208  0.386048   \n",
       "179            0.113572  0.198191  0.069739  0.085985  0.495080  0.312069   \n",
       "180            0.023627  0.112506  0.026828  0.009726  0.414651  0.261029   \n",
       "181            0.294182  0.265157  0.199069  0.114448  0.417356  0.470486   \n",
       "182            0.567732  0.249824  0.529215  0.411167  0.356654  0.709945   \n",
       "183            0.446804  0.422132  0.344042  0.448278  0.419722  0.473452   \n",
       "184            0.697615  0.929689  0.522162  0.216727  0.777439  0.618846   \n",
       "185            0.047101  0.147634  0.064569  0.021641  0.444405  0.372508   \n",
       "186            0.482356  0.257551  0.484984  0.541190  0.579617  0.803037   \n",
       "187            0.852812  0.290984  0.847244  0.730920  0.426295  0.570417   \n",
       "188            0.098770  0.142637  0.054676  0.066041  0.420517  0.324368   \n",
       "189            0.153561  0.233146  0.117561  0.071364  0.483006  0.396386   \n",
       "190            0.490682  0.860006  0.623702  0.665884  0.776326  0.741387   \n",
       "191            0.808667  0.311832  0.825653  0.818722  0.493654  0.626898   \n",
       "192            0.050987  0.139915  0.044773  0.011418  0.448850  0.308036   \n",
       "193            0.174849  0.322473  0.177353  0.046490  0.668801  0.601540   \n",
       "194            0.126164  0.241203  0.119873  0.028485  0.595669  0.503300   \n",
       "195            0.160701  0.230659  0.140920  0.199346  0.511220  0.489412   \n",
       "196            0.615511  0.617823  0.688062  0.603715  0.690891  0.809813   \n",
       "197            0.573303  0.382859  0.265135  0.416812  0.173793  0.031885   \n",
       "198            0.566305  0.618787  0.681682  0.561207  0.671038  0.686257   \n",
       "199            0.661302  0.244477  0.476542  0.266252  0.389821  0.677589   \n",
       "200            0.068592  0.145840  0.054063  0.005795  0.464688  0.339510   \n",
       "201            0.177171  0.218874  0.148886  0.117074  0.421086  0.477927   \n",
       "\n",
       "        std_R  \n",
       "162  0.000000  \n",
       "163  0.294857  \n",
       "164  0.211591  \n",
       "165  0.154522  \n",
       "166  0.728693  \n",
       "167  0.576742  \n",
       "168  0.540223  \n",
       "169  0.248220  \n",
       "170  0.685704  \n",
       "171  0.169903  \n",
       "172  0.260380  \n",
       "173  0.174222  \n",
       "174  0.026030  \n",
       "175  0.682910  \n",
       "176  0.315547  \n",
       "177  0.593324  \n",
       "178  0.144966  \n",
       "179  0.325535  \n",
       "180  0.081890  \n",
       "181  0.359641  \n",
       "182  0.542708  \n",
       "183  0.672721  \n",
       "184  0.340381  \n",
       "185  0.142865  \n",
       "186  0.856679  \n",
       "187  0.621260  \n",
       "188  0.275003  \n",
       "189  0.262710  \n",
       "190  0.779577  \n",
       "191  0.716824  \n",
       "192  0.097947  \n",
       "193  0.225496  \n",
       "194  0.167518  \n",
       "195  0.576189  \n",
       "196  0.692345  \n",
       "197  0.333213  \n",
       "198  0.585089  \n",
       "199  0.456193  \n",
       "200  0.040803  \n",
       "201  0.403525  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162    0\n",
       "163    0\n",
       "164    0\n",
       "165    0\n",
       "166    0\n",
       "167    0\n",
       "168    3\n",
       "169    0\n",
       "170    3\n",
       "171    0\n",
       "172    0\n",
       "173    0\n",
       "174    0\n",
       "175    0\n",
       "176    0\n",
       "177    0\n",
       "178    0\n",
       "179    0\n",
       "180    0\n",
       "181    0\n",
       "182    0\n",
       "183    3\n",
       "184    3\n",
       "185    0\n",
       "186    0\n",
       "187    0\n",
       "188    0\n",
       "189    0\n",
       "190    2\n",
       "191    0\n",
       "192    0\n",
       "193    0\n",
       "194    0\n",
       "195    2\n",
       "196    0\n",
       "197    1\n",
       "198    0\n",
       "199    0\n",
       "200    0\n",
       "201    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Step is the model Selection\n",
    "\n",
    "#### Training \n",
    "\n",
    "#### Evaluation\n",
    "\n",
    "#### Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "####  Support Vector machine works well for multiclass classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing of the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of the trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 82.50\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Hyper-Parameter Tuning\n",
    "\n",
    "#### Regularization parameter C - high C value implies strict classification.\n",
    "\n",
    "#### Gamma parameter - high gamma parameter value implies only nearby points (support vector) are considered for classification.\n",
    "\n",
    "#### Kernel - Radial Basis Kernel(rbf) , linear kernel are popular choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel = 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 90.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel = 'linear',C=10,gamma = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1, kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 95.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel = 'linear',C=10,gamma = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=2, kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 95.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel = 'linear',C=10,gamma = 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.02, kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 95.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel = 'linear',C=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 97.50\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel = 'rbf',C=10,gamma=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 97.50\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel = 'rbf',C=100,gamma=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 97.50\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel = 'rbf',C=100,gamma=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=2, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 95.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel = 'rbf',C=100,gamma=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 95.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel = 'rbf',C=1,gamma=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 82.50\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel = 'rbf', C=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.0001, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.825"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(test_sample,test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 82.50\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier\n",
    "\n",
    "#### case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 90.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tree.DecisionTreeClassifier(criterion = 'entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 85.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### case 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tree.DecisionTreeClassifier(min_samples_split = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 87.50\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### case 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tree.DecisionTreeClassifier(criterion = 'entropy', min_samples_split = 79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=79,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 90.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-NN Classifier\n",
    "\n",
    "#### case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors = 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 97.50\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 97.50\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### case 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors = 5,algorithm = 'kd_tree') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 97.50\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### case 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors = 5,algorithm = 'ball_tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 97.50\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### case 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors = 6,algorithm = 'brute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=6, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 95.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier\n",
    "\n",
    "#### case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 90.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=5, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 92.50\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### case 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators = 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=70, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 97.50\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### case 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(criterion = 'entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 92.50\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### case 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators = 30, criterion = 'entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 95.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### case 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators = 100,criterion = 'entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 97.50\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier\n",
    "\n",
    "#### case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = tree.DecisionTreeClassifier(criterion = 'gini', max_depth = 1)\n",
    "adabst = AdaBoostClassifier(base_estimator = dtree, n_estimators = 5000, learning_rate = 0.05, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=0.05, n_estimators=5000, random_state=42)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adabst.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = adabst.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 92.50\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = tree.DecisionTreeClassifier(criterion = 'gini')\n",
    "adabst = AdaBoostClassifier(base_estimator = dtree, n_estimators = 5000, learning_rate = 0.05, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=0.05, n_estimators=5000, random_state=42)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adabst.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = adabst.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 85.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### case 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = tree.DecisionTreeClassifier(min_samples_split = 10)\n",
    "adabst = AdaBoostClassifier(base_estimator = dtree, n_estimators = 1000, learning_rate = 0.05, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=10,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=0.05, n_estimators=1000, random_state=42)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adabst.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = adabst.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 92.50\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### case 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = tree.DecisionTreeClassifier(min_samples_split = 10)\n",
    "adabst = AdaBoostClassifier(base_estimator = dtree, n_estimators = 5000, learning_rate = 0.01, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=10,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=0.01, n_estimators=5000, random_state=42)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adabst.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = adabst.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 95.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### case 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = tree.DecisionTreeClassifier(min_samples_split = 10)\n",
    "adabst = AdaBoostClassifier(base_estimator = dtree, n_estimators = 5000, learning_rate = 0.005, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=10,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=0.005, n_estimators=5000, random_state=42)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adabst.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = adabst.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 95.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation for model selection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [] \n",
    "value = [] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-fold Cross-validation for SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel = 'linear',C=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mylabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model,my_file,mylabel,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9047619 , 0.97619048, 0.95121951, 0.97435897, 1.        ])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f257ed48be0>]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(5),scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9613061735012955"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append('SVM')\n",
    "value.append(scores.mean()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-fold Cross-validation for Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model,my_file,mylabel,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83333333, 0.95238095, 0.90243902, 0.87179487, 0.86842105])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f257ecd7be0>]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(5),scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8856738469061961"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append('Decision Tree')\n",
    "value.append(scores.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SVM', 'Decision Tree']"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[96.13061735012955, 88.5673846906196]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-fold Cross-validation for Naive-Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model,my_file,mylabel,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57142857, 0.47619048, 0.56097561, 0.38461538, 0.47368421])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f257ec55240>]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(5),scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4933788505033691"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append('Naive-Bayes')\n",
    "value.append(scores.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['SVM', 'Decision Tree', 'Naive-Bayes'],\n",
       " [96.13061735012955, 88.5673846906196, 49.33788505033691])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models,value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-fold Cross-validation for k-nearest neighbour classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors = 5,algorithm = 'auto') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model,my_file,mylabel,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85714286, 0.88095238, 0.87804878, 0.87179487, 0.97368421])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f257ebbf208>]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(5),scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.892324620180846"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append('K-NN')\n",
    "value.append(scores.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['SVM', 'Decision Tree', 'Naive-Bayes', 'K-NN'],\n",
       " [96.13061735012955, 88.5673846906196, 49.33788505033691, 89.2324620180846])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models,value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### K-fold Cross-validation for Random Forset Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators = 100,criterion = 'entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model,my_file,mylabel,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9047619 , 0.95238095, 0.92682927, 0.8974359 , 0.97368421])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f257eb9d860>]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8VPXVx/HPSdj3LaxhX4SwQ8CFKqhoEZRVEG2tWhU3am0f22px6UOl2Nba1ta1llbbRyWgIAqKFIFWcclAWBLWsE4SlrCFNQlJzvPHTOw4DmRIMnNnOe/Xi5eTub/JPXPNfOfO7945V1QVY4wx8SHB6QKMMcaEj4W+McbEEQt9Y4yJIxb6xhgTRyz0jTEmjljoG2NMHLHQN8aYOGKhb4wxccRC3xhj4kgNpwvw16JFC+3UqZPTZRhjTFRZs2bNIVVNqmhcxIV+p06dcLlcTpdhjDFRRUT2BDPOpneMMSaOWOgbY0wcsdA3xpg4YqFvjDFxxELfGGPiiIW+McbEEQt9Y4yJIxb6xhgTAd5Zm8M8lzvk67HQN8YYh5WVKc8u28bCdbkhX5eFvjHGOOzznYfJOXqGKantQ74uC31jjHHYXJebRnVq8O3erUO+Lgt9Y4xxUMHps3yQuZ/xA9tRp2ZiyNdnoW+MMQ5atD6X4pKysEztgIW+McY4Ks2VQ0qbRvRp1zgs6wsq9EVklIhsFZFsEXkkwPKOIrJcRDaIyEoRSfbef6WIrPP5Vygi46v7SRhjTDTalHecjbkFTElNDts6Kwx9EUkEngeuA1KAm0UkxW/YM8DrqtoPmAnMBlDVFao6QFUHAFcBp4GPqrF+Y4yJWmkuN7USExg/sF3Y1hnMnv5QIFtVd6pqMfAWMM5vTAqw3Ht7RYDlADcCH6jq6coWa4wxsaKopJSF63K5tncrmtSrFbb1BhP67QDfr4nleO/ztR6Y5L09AWgoIs39xkwF3qxMkcYYE2s+yjrAsdNnuWlIeA7glgsm9CXAfer388PAcBHJAIYDuUDJV79ApA3QF1gacAUi00TEJSKu/Pz8oAo3xpholuZy065JXYZ1bRHW9QYT+jmA71tRMpDnO0BV81R1oqoOBGZ47yvwGTIFWKCqZwOtQFVfUdVUVU1NSqrwur7GGBPVco6e5pPsQ9w4OJmEhED71aETTOinA91FpLOI1MIzTbPId4CItBCR8t/1KDDH73fcjE3tGGMMAG+v8fTYuXFw+M7aKVdh6KtqCTAdz9TMZiBNVbNEZKaIjPUOGwFsFZFtQCtgVvnjRaQTnk8Kq6q1cmOMiUJlZcq8NW6GdW1B+2b1wr7+GsEMUtUlwBK/+57wuT0fmH+Ox+7mmwd+jTEmLn3mba7201E9HVm/fSPXGGPCaG66m8Z1a3JtSitH1m+hb4wxYVJw+iwfZu1n/IC2YWmuFoiFvjHGhMm73uZqk8PUXC0QC31jjAmTNJeb3m3D11wtEAt9Y4wJg6y8AjJzj4ethfK5WOgbY0wYzHPlUKtGAuMGtHW0Dgt9Y4wJscKzpSzIyOXbvVuHtblaIBb6xhgTYh9tOkDBmbPc5PDUDljoG2NMyM3zNle7rKt/8+Hws9A3xpgQKm+uNjk1/M3VArHQN8aYEJq/JgdwprlaIBb6xhgTImVlyjxXDt/q1oLkpuFvrhaIhb4xxoTI6h2HyT12xvFz831Z6BtjTIjMdXmaq13jUHO1QCz0jTEmBI6dLmZp1n4mDGznWHO1QCz0jTEmBN5dl+dtrhYZB3DLWegbY0wIpLnc9GnXiN5tnWuuFkhQoS8io0Rkq4hki8gjAZZ3FJHlIrJBRFaKSLLPsg4i8pGIbBaRTd7LJxpjTMzKzC0gK8/55mqBVBj6IpIIPA9cB6QAN4tIit+wZ4DXVbUfMBOY7bPsdeC3qtoLGAocrI7CjTEmUqW53J7mav0j70qxwezpDwWyVXWnqhYDbwHj/MakAMu9t1eUL/e+OdRQ1WUAqnpSVU9XS+XGGBOBCs+WsjAjl1G9W9O4Xk2ny/mGYEK/HeD2+TmHb17ofD0wyXt7AtBQRJoDPYBjIvKOiGSIyG+9nxyMMSYmLc3az/HCEm4aEnlTOxBc6AdqFqF+Pz8MDBeRDGA4kAuUADWAy73LhwBdgNu/sQKRaSLiEhFXfn5+8NUbY0yEmefKIblpXS7t4nxztUCCCf0cwPctKxnI8x2gqnmqOlFVBwIzvPcVeB+b4Z0aKgEWAoP8V6Cqr6hqqqqmJiUlVfKpGGOMs9xHvM3VBrePiOZqgQQT+ulAdxHpLCK1gKnAIt8BItJCRMp/16PAHJ/HNhWR8iS/CthU9bKNMSbyzF+TgwjcGGHn5vuqMPS9e+jTgaXAZiBNVbNEZKaIjPUOGwFsFZFtQCtglvexpXimdpaLyEY8U0V/qfZnYYwxDistU+av8TRXa9ekrtPlnFONYAap6hJgid99T/jcng/MP8djlwH9qlCjMcZEvNU7DpF77AyPju7pdCnnZd/INcaYajA33U2TepHVXC0QC31jjKmiY6eL+SjrAOMHtKN2jcg+K91C3xhjqmhhRi7FpWUR2XbBn4W+McZUUZorh77tGpPStpHTpVTIQt8YY6ogM7eATfuOMyWCT9P0ZaFvjDFVMDfdTe0aCYwdEHnN1QKx0DfGmEoqPFvKu+tyGdWnNY3rRl5ztUAs9I0xppK+aq4WBQdwy1noG2NMJaW53LRvVpdLIrS5WiAW+sYYUwnuI6f5NPtwRDdXC8RC3xhjKmFeeXO1wdFx1k45C31jjLlApWXKfJeby7sn0TaCm6sFYqFvjDEX6NPsQ+QVFEbVAdxyFvpxbO/h05wpLnW6DGOizlyXm6b1ajIypaXTpVwwC/04tf3ACa5+diUTXviUvGNnnC7HmKhx9FQxy7IOMH5g5DdXC8RCPw6pKjMWZFK3ZiK5R88w4YVPycorcLosY6LCwnXR01wtEAv9ODR/TQ5f7j7CjDG9mHffpSSKMOWlz1i59aDTpRkT0VSVuelu+iU3plebyG+uFkhQoS8io0Rkq4hki8gjAZZ3FJHlIrJBRFaKSLLPslIRWef9t8j/sSa8jp4q5ldLNjO4Y1MmD25Pz9aNWPDAMDo2r8+dr7l488u9TpdoTMTKzD3Olv0nmByle/kQROiLSCLwPHAdkALcLCIpfsOeAV5X1X7ATGC2z7IzqjrA+28sxlG//nALxwtLmDWhz1dfKGnVqA5p917K5d1b8Og7G/nNh1soK1OHKzUm8sx17fU0V+vf1ulSKi2YPf2hQLaq7lTVYuAtYJzfmBRguff2igDLTQRw7T7CW+lu7vpWZ3q2/vpH0wa1a/Dq91K55eIOvLByBw/NXUdRiZ3ZY0w5T3O1PK6LouZqgQQT+u0At8/POd77fK0HJnlvTwAaikh5M4o6IuISkc9FZHyVqjWVdra0jBkLMmnXpC4/HNk94JgaiQnMGt+Hn43qyaL1edz66pccO10c5kqNiUwfZu7nRGEJU4ZE79QOBBf6gZpK+H/2fxgYLiIZwHAgFyjxLuugqqnALcAfRKTrN1YgMs37xuDKz88PvnoTtDmf7GLrgRP8Ymxv6tWqcc5xIsJ9I7ry3M0DWec+xsQXV7P38OkwVmpMZPqquVrn6GmuFkgwoZ8D+L61JQN5vgNUNU9VJ6rqQGCG976C8mXe/+4EVgID/Vegqq+oaqqqpiYlJVXmeZjzyD12hj/8azsje7XimpRWQT1mbP+2/POuizl8spgJL3zKOvexEFdpTOTae/g0q3ccZkqUNVcLJJjQTwe6i0hnEakFTAW+dhaOiLQQkfLf9Sgwx3t/UxGpXT4GGAZsqq7iTXB+sSjL89+x/sffz29o52a8c/9l1KudyNRXPmNp1v5QlGdMxJu/xu1prhYll0Q8nwpDX1VLgOnAUmAzkKaqWSIyU0TKz8YZAWwVkW1AK2CW9/5egEtE1uM5wPu0qlroh9FHWftZtukAD43sTnLTehf8+K5JDVhw/zB6tm7Evf9cw5xPdoWgSmMiV2mZMm9NDld0T6JN4+hqrhaIqEbWqXmpqanqcrmcLiMmnCoq4ZpnV9GwTk3ef/Bb1Eys/HfxzhSX8tDcDJZmHeCOYZ14bEwKiVH+MdeYYKzals9tc77khe8MYnTfNk6Xc04issZ7/PS87Bu5Mey55dvJKyhk1oQ+VQp8gLq1EnnhO4P5/rDO/O3T3dz/f2usWZuJC2npnuZqV/eKvuZqgVjox6gt+4/z1092cVNqe1I7NauW35mYIDxxQwpP3pDCR5sOcPNfPufQyaJq+d3GRKIjp4r5aNN+JgxMjsrmaoFY6MegsjLlsQWZNKxTg0eu61ntv/+OYZ156buD2bL/OBNfWM2O/JPVvg5jIsHCjFzOlipThkT/AdxyFvoxaN4aN649R/n56F40rV8rJOv4du/WvDXtUk4XlzDpxdV8uetISNZjjFNUlTSXm/7Jjb/xDfZoZqEfYw6fLGL2B1sY2rlZyK/dOaB9E965bxjN6tfiu69+wXvr8yp+kDFRYmNuQdQ3VwvEQj/GzP5gCycLS3hqfB9EQn92TYfm9XjnvssY0KEJP3gzgxdX7iDSzggzpjLmprs9zdUGRG9ztUAs9GPIFzsPM39NDndf0YUerRqGbb1N6tXiH3cOZWz/tvz6wy3MWJhJSWlZ2NZvTHU7U1zKonV5jO7bhkZ1ore5WiDnbsJiokpxSRmPLcwkuWldHrwqcEO1UKpdI5E/3DSA5KZ1eWHlDnKPnuH57wyiQW37EzPR58OsfZwoKonaq2Odj+3px4hXP9nJ9oMnmTmuN3VrOXNqWUKC8NNRPfnVhL58kn2IKS99xoHjhY7UYkxVpKXn0LF5PS7pUj2nO0cSC/0Y4D5ymueWb2dU79Zc1TO4hmqhdMvFHXj1tlT2HD7F+Oc/Zcv+406XZEzQ9hw+xWc7DzN5cHJYjouFm4V+lFNVnlyURYJ4vjgVKa68qCVp915KmSqTX/yMT7YfcrokY4Iyf00OCQKTQnz2m1Ms9KPc0qwDfLzlID++pgdtm0RWM6jebRuz4P5htG1Sl9v/9iXzXO6KH2SMg0rLlPlrcriiR2w0VwvEQj+KnSwq4X/fy6JXm0bcflknp8sJqG2Tusy771Iu6dKcn8zfwLPLttkpnSZi/Wd7PvsKCrkpBg/glrPQj2J/WLaN/cc9DdVqVLGhWig1qlOTv90xhBsHJ/Pc8u38z7z1FJfYKZ0m8qS53DSrX4urezl/bCxU7Hy6KLUp7zh/W72bqUM6MKhDU6fLqVDNxAR+e2M/OjSrx7PLtrG/oJAXvzs4qi8wbWLL4ZNFLNt0gO9d2olaNSJ3J6qqYveZxbCyMmXGwo00qVuTn426yOlygiYiPHh1d56d0p/03UeY/NJqco7a9XdNZFi4Ls/TXC2Gp3bAQj8qvZXuJmPvMWaM6UWTeqFpqBZKEwcl89odQ9lXUMiEF1aTmVvgdEkmzqkqaelu+rdvwkWtw/dtdicEFfoiMkpEtopItog8EmB5RxFZLiIbRGSliCT7LW8kIrki8ufqKjxeHTpZxNMfbOaSLs2YMLCd0+VU2mXdWvDOfZdRKzGBKS9/xsdbDjhdkoljG3IK2HrgBFNi4Bq4Fakw9EUkEXgeuA5IAW4WEf8Twp8BXlfVfsBMYLbf8l8Cq6pervnV4s2cOVvKU+P7Rv0XR7q3asiCBy6ja1ID7nrNxT8+3+N0SSZOzXW5qVMzgRv6x1ZztUCC2dMfCmSr6k5VLQbeAsb5jUkBlntvr/BdLiKD8Vws/aOqlxvfVu84xDsZudxzRVe6tWzgdDnVomXDOrw17RKuvKgljy/M5FdLNlNWZqd0mvA5U1zKe+vyGN0n9pqrBRJM6LcDfL9Vk+O9z9d6YJL39gSgoYg0F5EE4HfAT6paaLwrKinlsYWZdGhWj+lXdXO6nGpVv3YNXr51MLde0pFX/r2TH7yZQeFZu/6uCY8PMr3N1YbE9gHccsGEfqA5BP9dsYeB4SKSAQwHcoES4H5giaqe96uYIjJNRFwi4srPzw+ipPjzl3/vZGf+KWaO602dmrFxrU5fNRITmDmuNz8f3ZPFG/fxnVe/4MipYqfLMnEgzeWmU/N6XNw59pqrBRJM6OcAvm+BycDXLpGkqnmqOlFVBwIzvPcVAJcC00VkN555/++JyNP+K1DVV1Q1VVVTk5KSKvdMYtiew6f408fZjOnbhhEXtXS6nJAREaZd0ZXnbxnExtwCJr24mt2HTjldlolhew6f4vOdR5ic2j7qj5EFK5jQTwe6i0hnEakFTAUW+Q4QkRbeqRyAR4E5AKr6HVXtoKqd8HwaeF1Vv3H2jzk3VeWJd7OomZjA49dHTkO1UBrTrw1v3HUxx04XM/HF1azZc9TpkkyMmufyNlcbFPtn7ZSrMPRVtQSYDiwFNgNpqpolIjNFZKx32Ahgq4hsw3PQdlaI6o07SzbuZ9W2fH58TQ9aN67jdDlhk9qpGe/cP4yGdWpwy18+54ON+5wuycSY8uZqw3skxdVrSyKt+VVqaqq6XC6ny4gIJwrPMvLZVbRoUJt3HxgW0f11QuXwySLuft1FhvsYM0b34s5vdY6bj+EmtFZsPcgdf0vnpe8OYlSfNk6XU2UiskZVUysaF38pEkWeXbaNgyeKmDWhb1wGPkDzBrV54+5LGNW7NU8t3swvFmVRaqd0mmqQlu6mef1aEXHhoXCKzySJApm5Bby2ejffvbgjA9o3cbocR9Wpmcjztwzi7ss789pne7jnH2s4XVzidFkmih0+WcS/Nh9gwsB2Md1cLZD4erZRorRMmbFgI83q1+bhb0dPQ7VQSkgQZoxJYea43ny85QBTX/mcgyfs+rumchZk5Hqaq8XJufm+LPQj0Btf7GF9TgGPX9/LWg/7+d6lnXjl1lS2HzjJxBdWk33whNMlmSijqqS53Axo34QerWK7uVogFvoR5uCJQn6zdCvDujVnbBz0AamMkSmtmHvPJRSeLWPiC6v5fOdhp0syUWR9TgHbDpyM+RbK52KhH2FmLd5M0dkyfjmuj52lch79kpuw4P7LaNmoDrf+9QsWZuQ6XZKJEnPTy5urRf8ZO5VhoR9BPtl+iHfX5XHfiK50SYqNhmqh1L5ZPd6+9zIGdWjKQ3PX8afl2+36u+a8zhSX8t76PEb3bUPDOGiuFoiFfoQoPFvK4+9m0ql5Pe4b0dXpcqJG43o1ef3OoYwf0JbfLdvGI29v5GypXX/XBLZk4z5OFpXE9IXPK2LXyI0QL6/aya5Dp3j9+0NjsqFaKNWukcjvbxpA+2b1+NPH2eQVnOGF7wyK2z05c27lzdWGxklztUBsTz8C7Dp0iudXZnND/7Zc0cMazlWGiPA/117Eryf1ZfWOw0x+6TP2FZxxuiwTQXYfOsUXu+KruVogFvoO8zRUy6R2YgKPj+nldDlR76YhHfjb7UPIOXqGCc+vZlPecadLMhFi3ho3CQI3Do6f5mqBWOg77L0N+/jP9kP8ZNRFtGwUP02fQumKHknMu/dSAKa8/Bmrttk1GuJdSWkZ89fkMOKilrSK89eZhb6Djhee5Zfvb6JfcmO+c3FHp8uJKb3aNGLhA8No36we3/97OnPT9zpdknHQv7fnc+B4Udyem+/LQt9Bv1u6lcMni5g1vi+JCfE7xxgqrRvXIe2eSxjWrQU/e3sjzyzdaqd0xqm09Bxvc7XYvQhRsCz0HbIh5xivf76H713aib7JjZ0uJ2Y1rFOTv96WytQh7fnzimwemruOohK7/m48OeRtrjZxUPw1VwvETtl0QGmZ8vMFG0lqUJsfX9vD6XJiXs3EBGZP7Ev7ZvX47dKt7C8o5JVbU2lcz07pjAcLM3IpKVOb2vGytz0H/OOz3WTmHufx61NoZOeSh4WI8MCV3fjj1AFk7D3GxBc/xX3ktNNlmRBTVeamuxnYoQnd47C5WiBBhb6IjBKRrSKSLSLfuMatiHQUkeUiskFEVopIss/9a0RknYhkici91f0Eos2B44U889E2Lu/eguv7xWfvDyeNG9CO1+8cSv6JIia88Cnr3cecLsmE0Dr3MbYfjN/maoFUGPoikgg8D1wHpAA3i4j/FbqfwXPR837ATGC29/59wGWqOgC4GHhEROK6deQv399Ecak1VHPSJV2a8879l1GnZiJTX/mcZZsOOF2SCZE0l5u6NRNtB8tHMHv6Q4FsVd2pqsXAW8A4vzEpwHLv7RXly1W1WFWLvPfXDnJ9MWvVtnze37CP6Vd2o1OL+k6XE9e6tWzIgvuH0b1VA6b9w8XfP93ldEmmmp0uLuG99fsY0y9+m6sFEkwItwPcPj/neO/ztR6Y5L09AWgoIs0BRKS9iGzw/o5fq2qe/wpEZJqIuETElZ8fm1+kKTxbyhPvZtKlRX3uGd7F6XIMkNSwNm9Nu4Sre7biF+9t4pfvb6LMrr8bM5Zs3M/JohKb2vETTOgHmoPwf2U8DAwXkQxgOJALlACoqts77dMNuE1EvnEVYlV9RVVTVTU1KSk2e8+8sCKbPYdP89T4PtSuYQ3VIkW9WjV4+dbB3H5ZJ/76yS7u/7+1FJ61UzpjQZrLTecW9RnSqanTpUSUYEI/B/B9q0wGvra3rqp5qjpRVQcCM7z3FfiPAbKAy6tUcRTakX+SF1ftYPyAtlzWrYXT5Rg/iQnCkzek8NiYXizdtJ+b//I5h08WVfxAE7F2HTrFl7uOMDk12Y6d+Qkm9NOB7iLSWURqAVOBRb4DRKSFiJT/rkeBOd77k0Wkrvd2U2AYsLW6io8GqsrjCzOpUzORGWP8j3+bSCEi3HV5F164ZRCb8o4z8cXV7Mw/6XRZppLmudwkJgg3Dorv5mqBVBj6qloCTAeWApuBNFXNEpGZIjLWO2wEsFVEtgGtgFne+3sBX4jIemAV8Iyqbqzm5xDR3l2Xx+odh/nZqJ4kNaztdDmmAtf1bcMbd1/CicISJr64GtfuI06XZC7QV83VeiRZE8MAJNJ6kaSmpqrL5XK6jGpRcPosVz+7knZN67HgvstIsP46UWP3oVPc8fd0co+d4dkp/bm+X1yfaRxVlm8+wJ2vuXj51sF8u3drp8sJGxFZo6qpFY2L61MoQ+03S7dw5FQxs8b3scCPMp1a1Oft+y6jX7vGTH8jg5dW7bBmbVEizeWmRQNrrnYuFvohkrH3KG98uZfbL+tMn3bWUC0aNatfi3/edTFj+rbh6Q+28NjCTErs+rsRLf9EEcs3H2TioGRqJlq8BWIN10KgpLSMGQsyadWwjjVUi3J1aibyp5sHktysLi+v2smhk0X8+ZZBFigR6r/N1ewA7rnYX24IvPbZHjbtO86TN6TQoLa9r0a7hATh0et68fj1KSzNOsD0N9Zy1vb4I46qMtflZlCHJnRrac3VzsVCv5rtKzjDsx9tZcRFSYzqEz8HkeLBnd/qzBMW/BErw32MbGuuViEL/Wo2871NlJQpM8daQ7VY9H2f4P/BGxkW/BEkLd1NvVqJXN/fzrQ6Hwv9arRiy0E+yNzPg1d3p0Pzek6XY0Lk+9/qzOPXp/Bh1n4L/gjhaa6Wx5i+bWxKtQIW+tXkTHEpTyzKpFvLBtx9uTVUi3V3WvBHlMUb9nGquJQpQ2xqpyIW+tXkzyu24z5yhqfG97HrcMYJ3+B/8E0LfifNc+XQpUV9Ujtac7WKWDpVg+0HTvDKv3cycVA7LunS3OlyTBjd+a3OPDaml2daz4LfETvzT/Ll7iNMTm1vx9GCYKFfRarKYwszqVerBj8f3cvpcowD7rq8y1fB/8O3LPjDLc2VQ2KCMGmQ/2U+TCB2xKOK3lmbyxe7jjB7Yl9aNLCGavHqLu9xnKcWbwYy+OPUgfYFrjAoKS3j7bU5XHmRNVcLloV+FRw7XcysJZsZ1KEJN9m5wXHPgj/8Vm7NJ/9EkZ2bfwEs9Kvg1x9uoeDMWWZN6GsN1Qzw9eAX1vGHqQMs+EPI01ytNldac7WgWehX0po9R3jzSzd3X96ZXm0aOV2OiSBf3+PHgj9E8k8U8fGWg9z5rc62fS+AhX4lnPU2VGvTuA4PjbSGauab7rq8C6owa4kFf6gsyMihpEyZbFM7F8RCvxL+/ulutuw/wcu3Dqa+ffvPnMPdV3j2+MuD/49TB1DDgr9aqCpz090M7tiUbi0bOF1OVAnqL1BERonIVhHJFpFHAizvKCLLRWSDiKwUkWTv/QNE5DMRyfIuu6m6n0C45R47w+//tY2RvVpybUorp8sxEe7uK7rw89E9WbxxHz98a531468ma/ceY0f+KTuBohIq3E0VkUTgeeAaIAdIF5FFqrrJZ9gzwOuq+pqIXAXMBm4FTgPfU9XtItIWWCMiS1X1WLU/kzD530VZlKny5A297YsgJijTrugKwK+WbAGBP95ke/xVVd5cbXS/Nk6XEnWCmZsYCmSr6k4AEXkLGAf4hn4K8CPv7RXAQgBV3VY+QFXzROQgkAREZej/a9MBPtp0gJ+N6kn7ZtZQzQTva8GPBX9VnCoq4f0NeVzfz5qrVUYwf3XtALfPzzne+3ytByZ5b08AGorI1/oRiMhQoBaww38FIjJNRFwi4srPzw+29rA6XVzCk4uy6NGqAXdd3tnpckwUmnZFVx69rieLN+zjh3NtqqeyFm/0NlezqZ1KCSb0A81h+F8h+mFguIhkAMOBXKDkq18g0gb4B3CHqn7jL11VX1HVVFVNTUpKCrr4cHpueTa5x87w1Pi+dhaGqbR7hv83+B+y4K+UeS43XZLqM9iaq1VKMJ+NcgDft9RkIM93gKrmARMBRKQBMElVC7w/NwIWA4+p6ufVUXS4bd1/glf/s5MpqckM7dzM6XJMlLtnuGeqZ/YHnqmeP9hUT9B25J8kffdRHrmupx1Tq6RgQj8d6C4infHswU8FbvEdICItgCPevfhHgTne+2sBC/Ac5J1XnYWHS1mZ8tjCjTSoU4NHrrOGaqZ63DO8Kwo8/cEWRITfT+lvwR+ENJebxARhojVXq7QKQ19VS0RkOrAUSATmqGqWiMwEXKq6CBgBzBYRBf4NPOB9+BTgCqC5iNzuve92VV1XvU8jdOavySF991F+M6kfzerXcrozEv3vAAAP10lEQVQcE0Pu9e7xP+3d47fgP7+zpWW8vSaXKy9qScuG1lytsoI69K2qS4Alfvc94XN7PjA/wOP+CfyzijU65sipYmZ/sJkhnZpy4+Bkp8sxMciCP3grt+Zz6GQRN9nVsarEznc6j6c/2MyJwhKeGm8N1Uzo3Du8K6qeBn4CPGvBH1B5c7URF0XmyR7RwkL/HL7cdYQ0Vw73DO/CRa0bOl2OiXH3jfDs8f/6Q88evwX/1x08UcjHWw5y1+XWXK2qLPQDKC4p47GFG2nXpC4/vLq70+WYOHHfiK4oym8+3ApY8PtasDaX0jJl8mCb2qkqC/0A/vrJLrYdOMmr30ulXi3bRCZ87h/RDYDffLgVEfjdZAt+VWWuy02qNVerFpZoftxHTvPH5du4NqUVI62hmnGAb/CDBf/avUfZmX+Ke2/s6nQpMcFC34eq8otFWSSI8OTY3k6XY+LY/SO6oQq/XVo+1TOAxDg9mWBuupv6tRIZ09eaq1UHC30fH206wPItB/n56J60a1LX6XJMnHvgSs8efzwHv6e52j5u6NfWrl1RTWwrep0qKuEXi7Lo2bohdwyzhmomMsR78C/esI/TxaVMGWLfk6kuFvpef1y+nX0Fhfz5loF2SpiJKL7BL8Dv4ij457rcdE2qz6AO1lytuljoA5v3Heevn+zi5qHtGdzRGqqZyOO/xx8PwZ998CRr9hzlUWuuVq3iPvTLypQZCzbSuG5Nfjaqp9PlGHNOD1zZDVXlmY+2ISI8M7l/TAf/vK+aq9nUTnWK+9Cf63Kzdu8xnpncnyb1rKGaiWzTr/J8WfCZjzwXpYvV4D9bWsbba3O5qmdLkhrWdrqcmBLXoX/oZBFPf7CFizs3Y5K1ajVRIh6Cf8WWg57manZ1rGoX16E/e8kWTheXMGtCH5szNFFl+lXdUYXfLduGAL+NseBPc+WQ1NCaq4VC3Ib+ZzsO8/baHB64sivdWlpDNRN9fuDtC/W7ZZ49/lgJ/oPHC1mx9SB3X94lrr+JHCpxGfrlDdWSm9Zl+pXWUM1Er1gM/ncyvM3VUu0AbijEZej/5T872ZF/ir/dPoS6tRKdLseYKvnB1d1R4Nll20DgtzdGb/CrKmnpboZ0akrXJGuuFgpBfXYSkVEislVEskXkkQDLO4rIchHZICIrRSTZZ9mHInJMRN6vzsIra+/h0zy3fDvX9WnNlT1bOl2OMdXiwau78+NrevDO2lx+Mn89pWXqdEmVsmbPUXYeOsUUO4AbMhXu6YtIIvA8cA2QA6SLyCJV3eQz7Bk8Fz9/TUSuAmYDt3qX/RaoB9xTrZVXgqryxKJMaiQIT9yQ4nQ5xlSrB71TPc8u24Yg/ObGflG3x1/eXG20NVcLmWCmd4YC2aq6E0BE3gLGAb6hnwL8yHt7BbCwfIGqLheREdVSbRV9mLmflVvzefz6FNo0toZqJvY8eLXnrJ7f/8szxx9NwX+yqITFG/cxtr81VwulYKZ32gFun59zvPf5Wg9M8t6eADQUkebBFiEi00TEJSKu/Pz8YB92QU4WlfCL97JIadOI2y7tGJJ1GBMJfjiyOz8a2YO31+bw0/kbomaqZ/GGPE4XlzLZpnZCKpjQD7Sb4P9X9DAwXEQygOFALlASbBGq+oqqpqpqalJSaM7LffajbRw8UcSsCX3sNDAT8344sjsPjezO22tz+Nnb0RH8c9PddGvZgEEdmjhdSkwL5jNUDuD71psM5PkOUNU8YCKAiDQAJqlqQXUVWVWZuQX8ffUubhnagYHWrc/EiYdG9gDgD//aDsCvJ0XuVE/2wROs3XuMn4+25mqhFkzopwPdRaQznj34qcAtvgNEpAVwRFXLgEeBOdVdaGWVlikzFmbSrH4tfvpta6hm4otv8Aue4E+IwOBPc+VQI0GYMNDOzQ+1CkNfVUtEZDqwFEgE5qhqlojMBFyquggYAcwWEQX+DTxQ/ngR+Q/QE2ggIjnAnaq6tPqfSmBvfrmX9e5j/P6m/jSuVzNcqzUmYjw0sgeqnmtGQOQF/9nSMt5Zm2PN1cIkqEPkqroEWOJ33xM+t+cD88/x2MurUmBV5J8o4tcfbuHSLs0ZP8Aaqpn49aNrPHv8kRj8H285yKGTxdw0xA7ghkNMnxc1a/Emis6W8ZQ1VDMmYoN/nstNy4a1Gd7DmquFQ8yG/ursQyxcl8eDV3Wzr3Mb4xVpwe9prpbPtCusuVq4xGToF5WU8tjCTDo2r8f93svMGWM8fnRNDxR4LgKC/+21nuZq1nYhfGIy9F9etZOdh07x2veHUqemNVQzxt+PRnpaNjy3fDsi8PTE8Ae/qjLP5WZop2Z0blE/rOuOZzEX+rsPneLPK7IZ06+NzREacw4i8rXgh/AHv8vbXM0+jYdXTIW+qvL4u5nUSkzgieutoZox5/NV8Kvy3MfZCMLsiX3DFvxz0900qF2D0X1bh2V9xiOmQn/xxn38Z/shfnFDCq0a1XG6HGMinoh8dXD3uY+zAcIS/CcKz7J4wz7GD2xLvVoxFUMRL2a29vHCs8x8bxN92jXi1ks7OV2OMVHDieBfvGEfZ85aczUnxEzoF54tpV9yY35wVfeI7S9iTKQqD34F/vRxNiLwqwmhC/65LjfdWzZgYHtrrhZuMRP6LRvW4dXbhjhdhjFRS0T4sXeP/0/ePf5QBP/2AyfI2HuMGaN72ZcmHRAzoW+MqTr/4BeBWeOrN/jTXG5Pc7VB1hrFCRb6xpivKQ9+VfjzCs8ef3UFv6e5Wi5X92pJiwbWXM0JFvrGmG8QEf7nWs8ef3UG//LNBzl8ypqrOclC3xgTUHnwK8rzK3YAwqzxfaoU/OXN1a7obl+cdIqFvjHmnESEh6+9CMAb/FQ6+A8cL2TF1oPcO7yrNVdzkIW+Mea8qiv4316bQ5lizdUcZqFvjKlQefCrwgsrdyACT40LPvg9zdVyGNq5GZ2suZqjgvqMJSKjRGSriGSLyCMBlncUkeUiskFEVopIss+y20Rku/ffbdVZvDEmfESEn3z7Iu4f0ZU3vtjLY+9mUlamQT32y11H2HXoFDfZXr7jKtzTF5FE4HngGiAHSBeRRaq6yWfYM8DrqvqaiFwFzAZuFZFmwJNAKqDAGu9jj1b3EzHGhF558IN3jx/4ZRB7/GmuHBrUrsF11lzNccFM7wwFslV1J4CIvAWMA3xDPwX4kff2CmCh9/a3gWWqesT72GXAKODNqpdujHFCefAr8OJKzxz/+YL/ROFZlmzcx/iB7ay5WgQI5v9AO8Dt83MOcLHfmPXAJOCPwASgoYg0P8djv/E1PBGZBkwD6NChQ7C1G2McIiL81LvHX1Hwv+9trjYlNfkby0z4BTOnH+jt238i72FguIhkAMOBXKAkyMeiqq+oaqqqpiYl2fm7xkSD8uC/b0RX/u+LvTyxKPAc/9x0Nz1aNWCANVeLCMHs6ecAvkdfkoE83wGqmgdMBBCRBsAkVS0QkRxghN9jV1ahXmNMBCkPflV4adV/9/jLG6ltO3CCde5jPDbGmqtFimBCPx3oLiKd8ezBTwVu8R0gIi2AI6paBjwKzPEuWgr8SkSaen++1rvcGBMjRISfjfJM9fgHf1q6t7naQGuuFikqDH1VLRGR6XgCPBGYo6pZIjITcKnqIjx787NFRIF/Aw94H3tERH6J540DYGb5QV1jTOwoD35FeXnVTgAevz6FBRm5jOzViubWXC1iBHUoXVWXAEv87nvC5/Z8YP45HjuH/+75G2NilIjwyKieALy8aidZecetuVoEsvOnjDHVxj/4WzWqzeXdWzhclfFloW+MqVblwZ/cpC5tm9S15moRxkLfGFPtRIRbL+3kdBkmAHsLNsaYOGKhb4wxccRC3xhj4oiFvjHGxBELfWOMiSMW+sYYE0cs9I0xJo5Y6BtjTBwR1eCucRkuIpIP7KnCr2gBHKqmcqqT1XVhrK4LY3VdmFisq6OqVnhBkogL/aoSEZeqpjpdhz+r68JYXRfG6row8VyXTe8YY0wcsdA3xpg4Eouh/4rTBZyD1XVhrK4LY3VdmLitK+bm9I0xxpxbLO7pG2OMOYeoDH0RGSUiW0UkW0QeCbC8tojM9S7/QkQ6RUhdt4tIvois8/67K0x1zRGRgyKSeY7lIiLPeeveICKDIqSuESJS4LO9ngg0LgR1tReRFSKyWUSyROSHAcaEfZsFWVfYt5mI1BGRL0Vkvbeu/w0wJuyvySDrcuQ16V13oohkiMj7AZaFbnupalT9w3Nx9h1AF6AWsB5I8RtzP/CS9/ZUYG6E1HU78GcHttkVwCAg8xzLRwMfAAJcAnwRIXWNAN53YHu1AQZ5bzcEtgX4fxn2bRZkXWHfZt5t0MB7uybwBXCJ3xgnXpPB1OXIa9K77h8DbwT6/xXK7RWNe/pDgWxV3amqxcBbwDi/MeOA17y35wNXi4hEQF2OUNV/A0fOM2Qc8Lp6fA40EZE2EVCXI1R1n6qu9d4+AWwG2vkNC/s2C7KusPNug5PeH2t6//kfLAz7azLIuhwhIsnAGODVcwwJ2faKxtBvB7h9fs7hm3/4X41R1RKgAGgeAXUBTPJOB8wXkfYhrilYwdbuhEu9H88/EJHe4V6592P1QDx7ib4c3WbnqQsc2GbeqYp1wEFgmaqec3uF8TUZTF3gzGvyD8BPgbJzLA/Z9orG0A/0buf/7h3MmOoWzDrfAzqpaj/gX/z3ndxpTmyvYKzF89Xy/sCfgIXhXLmINADeBh5S1eP+iwM8JCzbrIK6HNlmqlqqqgOAZGCoiPTxG+LI9gqirrC/JkXkeuCgqq4537AA91XL9orG0M8BfN+Nk4G8c40RkRpAY0I/jVBhXap6WFWLvD/+BRgc4pqCFcw2DTtVPV7+8VxVlwA1RaRFONYtIjXxBOv/qeo7AYY4ss0qqsvJbeZd5zFgJTDKb5ETr8kK63LoNTkMGCsiu/FMA18lIv/0GxOy7RWNoZ8OdBeRziJSC89BjkV+YxYBt3lv3wh8rN4jIk7W5TfnOxbPnGwkWAR8z3tGyiVAgaruc7ooEWldPo8pIkPx/L0eDsN6BfgrsFlVnz3HsLBvs2DqcmKbiUiSiDTx3q4LjAS2+A0L+2symLqceE2q6qOqmqyqnfDkxMeq+l2/YSHbXjWq45eEk6qWiMh0YCmeM2bmqGqWiMwEXKq6CM8L4x8iko3n3XFqhNT1oIiMBUq8dd0e6roARORNPGd1tBCRHOBJPAe1UNWXgCV4zkbJBk4Dd0RIXTcC94lICXAGmBqGN2/w7IndCmz0zgcD/Bzo4FObE9ssmLqc2GZtgNdEJBHPm0yaqr7v9GsyyLoceU0GEq7tZd/INcaYOBKN0zvGGGMqyULfGGPiiIW+McbEEQt9Y4yJIxb6xhgTRyz0jTEmjljoG2NMHLHQN8aYOPL/XubKzpH96I4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(5),scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9310184466795507"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append('Random Forest')\n",
    "value.append(scores.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['SVM', 'Decision Tree', 'Naive-Bayes', 'K-NN', 'Random Forest'],\n",
       " [96.13061735012955,\n",
       "  88.5673846906196,\n",
       "  49.33788505033691,\n",
       "  89.2324620180846,\n",
       "  93.10184466795506])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models,value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-fold Cross-validation for AdaBoost Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = tree.DecisionTreeClassifier(min_samples_split = 10)\n",
    "adabst = AdaBoostClassifier(base_estimator = dtree, n_estimators = 5000, learning_rate = 0.005, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(adabst,my_file,mylabel,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92857143, 0.92857143, 0.92682927, 0.87179487, 0.97368421])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f257eb03748>]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(5),scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9258902415513456"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append('AdaBoost')\n",
    "value.append(scores.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['SVM', 'Decision Tree', 'Naive-Bayes', 'K-NN', 'Random Forest', 'AdaBoost'],\n",
       " [96.13061735012955,\n",
       "  88.5673846906196,\n",
       "  49.33788505033691,\n",
       "  89.2324620180846,\n",
       "  93.10184466795506,\n",
       "  92.58902415513455])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models,value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of diiferent classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SVM', 'Decision Tree', 'Naive-Bayes', 'K-NN', 'Random Forest', 'AdaBoost']"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[96.13061735012955,\n",
       " 88.5673846906196,\n",
       " 49.33788505033691,\n",
       " 89.2324620180846,\n",
       " 93.10184466795506,\n",
       " 92.58902415513455]"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, list)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(models),type(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = np.asarray(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_label = np.arange(len(models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Average accuracy chart of different classification models')"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_label,value)\n",
    "plt.xticks(x_label,models)\n",
    "plt.xlabel('Classification Models')\n",
    "plt.ylabel('Accuracy-score')\n",
    "plt.title('Average accuracy chart of different classification models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Average accuracy chart of different classification models')"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(x_label,value,align = 'center', alpha = 0.5)\n",
    "plt.xticks(x_label,models)\n",
    "plt.xlabel('Classification Models')\n",
    "plt.ylabel('Accuracy-score')\n",
    "plt.title('Average accuracy chart of different classification models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Average accuracy chart of different classification models')"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_label,value)\n",
    "plt.xticks(x_label,models)\n",
    "plt.xlabel('Classification Models')\n",
    "plt.ylabel('Accuracy-score')\n",
    "plt.title('Average accuracy chart of different classification models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
