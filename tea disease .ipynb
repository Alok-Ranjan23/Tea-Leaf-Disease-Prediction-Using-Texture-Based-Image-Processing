{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mahotas as mt\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import count\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "### A set of 202 diseased(1- algal leaf spot, 2- blister blight, 3- grey spot) and healthy(0) tea leaves are collected as dataset from High Field Tea Estate, Coonoor, Tamil Nadu, India.\n",
    "\n",
    "## The Next Step is Image Segmentation.\n",
    "\n",
    "#### A python script file is used for background removal and extraction of area of interest.\n",
    "\n",
    "## The Next Step is the Feature Extraction. \n",
    "\n",
    "#### 13 Texture Features( Haralick features are used).\n",
    "#### Color Features\n",
    "#### Shape Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(image):\n",
    "\t\n",
    "\t##Color Feature\n",
    "\t(mean,std) = cv.meanStdDev(image)\n",
    "\t\n",
    "\tprint(len(mean), type(mean))\n",
    "\t\n",
    "\tprint(len(std), type(std))\n",
    "\t\n",
    "\tcolor_feature = np.array(mean)\n",
    "\t\n",
    "\tcolor_feature = np.concatenate([color_feature,std]).flatten()\n",
    "\t\n",
    "\tprint(len(color_feature))\n",
    "\t\n",
    "\t##Texture Feature\n",
    "\tgray = cv.cvtColor(image,cv.COLOR_BGR2GRAY)\n",
    "\t\n",
    "\ttextures = mt.features.haralick(gray)\n",
    "\t\n",
    "\tht_mean = textures.mean(axis = 0)\n",
    "\t\n",
    "\tprint(len(ht_mean), type(ht_mean))\n",
    "\t\n",
    "\t\n",
    "\t## Shape Features\n",
    "\tret,thresh = cv.threshold(gray,127,255,0)\n",
    "\t\n",
    "\tx,contours, hierarchy =   cv.findContours(thresh.copy(),1,2)\n",
    "\t\n",
    "\tcnt = contours[0]\n",
    "\t\n",
    "\tarea = cv.contourArea(cnt)\n",
    "\tprint(type(area))\n",
    "\t\n",
    "\tperimeter = cv.arcLength(cnt,True)\n",
    "\tprint(type(perimeter))\n",
    "\t\n",
    "\tshape = np.array([])\n",
    "\tshape = np.append(shape,area)\n",
    "\tshape = np.append(shape,perimeter)\n",
    "\tprint(len(shape))\n",
    "\t\n",
    "\t\n",
    "\tprint(len(ht_mean) + len(std) + len(mean) + len(shape))\n",
    "\t\n",
    "\tht_mean = np.concatenate([ht_mean,color_feature]).flatten()\n",
    "\t\n",
    "\tht_mean = np.concatenate([ht_mean,shape]).flatten()\n",
    "\t\n",
    "\tprint(len(ht_mean),ht_mean.shape)\n",
    "\t\n",
    "\treturn(ht_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Comma-Seperating file\n",
    "\n",
    "#### A CSV file, having 21 features (13 texture features, 6 color features and 2 shape featrures) and appropriate label(0- Healthy, 1- Algal Leaf Spot, 2- blister blight, 3- Grey Spot), is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv():\t\n",
    "\t\n",
    "\tfiles = count.images()\n",
    "\tmydata = [['energy','contrast','correlation','variance','inverse difference moment','sum average','sum variance','sum entropy','entropy','difference variance','difference entropy','info_corr',\n",
    "\t\t\t   'maximal_corr_coeff','mean_B','mean_G','mean_R','std_B','std_G','std_R','area','perimeter','label']]\n",
    "\t\n",
    "\tpath = '/home/ln-2/Desktop/Alok/SVM/alok1/results'\n",
    "\tfor file in files:\t\n",
    "\t\tprint(path+ file)\n",
    "\t\timage = cv.imread(path + '/' + file)\n",
    "\t\tprint(file)\n",
    "\t\t#gray = cv.cvtColor(image,cv.COLOR_BGR2GRAY)\n",
    "\t\t#means = cv.mean(image)\n",
    "\t\t#print(len(means))\n",
    "\t\tprint(image.shape)\n",
    "\t\tdim = (512,512)\n",
    "\t\tr_img = cv.resize(image,dim)\n",
    "\t\tprint(r_img.shape)\n",
    "\t\tfeature = extract_feature(r_img)\n",
    "\t\tlabel = 0\n",
    "\t\t\n",
    "\t\t## Healthy leaf is labeled as 0.\n",
    "\t\tif(re.search('test[1-9]+',file)):\n",
    "\t\t\tlabel = 0\n",
    "\t\telse:\n",
    "\t\t\t## Algal leaf spot is labeled as 1.\n",
    "\t\t\tif(re.search('algal[1-9]+',file)):\n",
    "\t\t\t\tlabel = 1\n",
    "\t\t\t## Blister Blight is labeled as 2.\t\n",
    "\t\t\telif(re.search('blister[1-9]+',file)):\n",
    "\t\t\t\tlabel = 2\n",
    "\t\t\t## Grey Spot is labled as 3.\t\n",
    "\t\t\telif(re.search('grey[1-9]+',file)):\n",
    "\t\t\t\tlabel = 3\n",
    "\t\t\n",
    "\t\tfeature = np.append(feature,label)\n",
    "\t\tprint()\n",
    "\t\tprint(len(feature))\n",
    "\t\tfeature = feature.tolist()\n",
    "\t\tmydata.append(feature)\n",
    "\t\t\n",
    "\tmyfile = open('mycsv.csv','w')\n",
    "\twith myfile:\n",
    "\t\twriter = csv.writer(myfile)\n",
    "\t\twriter.writerows(mydata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey34.jpg\n",
      "grey34.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest69.jpg\n",
      "test69.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest119.jpg\n",
      "test119.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest28.jpg\n",
      "test28.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey1.jpg\n",
      "grey1.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey11.jpg\n",
      "grey11.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsalgal4.jpg\n",
      "algal4.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey7.jpg\n",
      "grey7.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest66.jpg\n",
      "test66.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest64.jpg\n",
      "test64.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest44.jpg\n",
      "test44.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest110.jpg\n",
      "test110.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey9.jpg\n",
      "grey9.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest94.jpg\n",
      "test94.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest109.jpg\n",
      "test109.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest27.jpg\n",
      "test27.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsblister2.jpg\n",
      "blister2.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsalgal3.jpg\n",
      "algal3.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey12.jpg\n",
      "grey12.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest136.jpg\n",
      "test136.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest134.jpg\n",
      "test134.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest101.jpg\n",
      "test101.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey3.jpg\n",
      "grey3.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest85.jpg\n",
      "test85.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest10.jpg\n",
      "test10.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest25.jpg\n",
      "test25.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey22.jpg\n",
      "grey22.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest63.jpg\n",
      "test63.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest3.jpg\n",
      "test3.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest36.jpg\n",
      "test36.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest149.jpg\n",
      "test149.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest153.jpg\n",
      "test153.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest125.jpg\n",
      "test125.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest59.jpg\n",
      "test59.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest72.jpg\n",
      "test72.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest74.jpg\n",
      "test74.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest141.jpg\n",
      "test141.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest117.jpg\n",
      "test117.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest114.jpg\n",
      "test114.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey10.jpg\n",
      "grey10.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest24.jpg\n",
      "test24.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey4.jpg\n",
      "grey4.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey21.jpg\n",
      "grey21.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest51.jpg\n",
      "test51.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest144.jpg\n",
      "test144.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsblister6.jpg\n",
      "blister6.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest45.jpg\n",
      "test45.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest131.jpg\n",
      "test131.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest113.jpg\n",
      "test113.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest61.jpg\n",
      "test61.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest41.jpg\n",
      "test41.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest84.jpg\n",
      "test84.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest111.jpg\n",
      "test111.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest73.jpg\n",
      "test73.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest60.jpg\n",
      "test60.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest143.jpg\n",
      "test143.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest54.jpg\n",
      "test54.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey14.jpg\n",
      "grey14.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest146.jpg\n",
      "test146.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest17.jpg\n",
      "test17.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest142.jpg\n",
      "test142.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest96.jpg\n",
      "test96.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest11.jpg\n",
      "test11.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest22.jpg\n",
      "test22.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest58.jpg\n",
      "test58.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest115.jpg\n",
      "test115.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey16.jpg\n",
      "grey16.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest122.jpg\n",
      "test122.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest100.jpg\n",
      "test100.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest13.jpg\n",
      "test13.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest106.jpg\n",
      "test106.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest57.jpg\n",
      "test57.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest127.jpg\n",
      "test127.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey28.jpg\n",
      "grey28.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest40.jpg\n",
      "test40.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest1.jpg\n",
      "test1.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest16.jpg\n",
      "test16.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest8.jpg\n",
      "test8.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest97.jpg\n",
      "test97.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsalgal6.jpg\n",
      "algal6.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey18.jpg\n",
      "grey18.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest87.jpg\n",
      "test87.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest7.jpg\n",
      "test7.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest42.jpg\n",
      "test42.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest120.jpg\n",
      "test120.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsblister8.jpg\n",
      "blister8.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest32.jpg\n",
      "test32.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest37.jpg\n",
      "test37.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest83.jpg\n",
      "test83.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest56.jpg\n",
      "test56.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest50.jpg\n",
      "test50.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest49.jpg\n",
      "test49.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey24.jpg\n",
      "grey24.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest123.jpg\n",
      "test123.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest89.jpg\n",
      "test89.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsblister3.jpg\n",
      "blister3.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest132.jpg\n",
      "test132.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest79.jpg\n",
      "test79.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest129.jpg\n",
      "test129.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest140.jpg\n",
      "test140.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest98.jpg\n",
      "test98.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey13.jpg\n",
      "grey13.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest46.jpg\n",
      "test46.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest78.jpg\n",
      "test78.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey23.jpg\n",
      "grey23.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest14.jpg\n",
      "test14.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest9.jpg\n",
      "test9.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest65.jpg\n",
      "test65.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest104.jpg\n",
      "test104.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest34.jpg\n",
      "test34.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest52.jpg\n",
      "test52.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest86.jpg\n",
      "test86.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest151.jpg\n",
      "test151.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey15.jpg\n",
      "grey15.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest48.jpg\n",
      "test48.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest116.jpg\n",
      "test116.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest108.jpg\n",
      "test108.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest21.jpg\n",
      "test21.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsalgal5.jpg\n",
      "algal5.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest2.jpg\n",
      "test2.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest103.jpg\n",
      "test103.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsalgal2.jpg\n",
      "algal2.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey8.jpg\n",
      "grey8.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest124.jpg\n",
      "test124.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey27.jpg\n",
      "grey27.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest118.jpg\n",
      "test118.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsalgal7.jpg\n",
      "algal7.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest152.jpg\n",
      "test152.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest138.jpg\n",
      "test138.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest93.jpg\n",
      "test93.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest135.jpg\n",
      "test135.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest81.jpg\n",
      "test81.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest150.jpg\n",
      "test150.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest23.jpg\n",
      "test23.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey19.jpg\n",
      "grey19.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest75.jpg\n",
      "test75.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest39.jpg\n",
      "test39.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest4.jpg\n",
      "test4.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest31.jpg\n",
      "test31.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest62.jpg\n",
      "test62.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest20.jpg\n",
      "test20.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest139.jpg\n",
      "test139.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsblister5.jpg\n",
      "blister5.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest126.jpg\n",
      "test126.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey20.jpg\n",
      "grey20.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest77.jpg\n",
      "test77.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey6.jpg\n",
      "grey6.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey5.jpg\n",
      "grey5.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsblister4.jpg\n",
      "blister4.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey29.jpg\n",
      "grey29.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest29.jpg\n",
      "test29.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest145.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test145.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest92.jpg\n",
      "test92.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey26.jpg\n",
      "grey26.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest35.jpg\n",
      "test35.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey30.jpg\n",
      "grey30.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest112.jpg\n",
      "test112.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest68.jpg\n",
      "test68.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest5.jpg\n",
      "test5.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey17.jpg\n",
      "grey17.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey31.jpg\n",
      "grey31.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest121.jpg\n",
      "test121.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest82.jpg\n",
      "test82.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest130.jpg\n",
      "test130.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest99.jpg\n",
      "test99.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest91.jpg\n",
      "test91.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest30.jpg\n",
      "test30.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest18.jpg\n",
      "test18.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey33.jpg\n",
      "grey33.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest102.jpg\n",
      "test102.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey2.jpg\n",
      "grey2.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest105.jpg\n",
      "test105.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest95.jpg\n",
      "test95.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest147.jpg\n",
      "test147.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest80.jpg\n",
      "test80.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest38.jpg\n",
      "test38.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest128.jpg\n",
      "test128.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest43.jpg\n",
      "test43.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest88.jpg\n",
      "test88.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest148.jpg\n",
      "test148.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest67.jpg\n",
      "test67.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest107.jpg\n",
      "test107.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest19.jpg\n",
      "test19.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey32.jpg\n",
      "grey32.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsgrey25.jpg\n",
      "grey25.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest90.jpg\n",
      "test90.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest6.jpg\n",
      "test6.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest26.jpg\n",
      "test26.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest53.jpg\n",
      "test53.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest55.jpg\n",
      "test55.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsblister1.jpg\n",
      "blister1.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest33.jpg\n",
      "test33.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest137.jpg\n",
      "test137.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest71.jpg\n",
      "test71.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest70.jpg\n",
      "test70.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsblister7.jpg\n",
      "blister7.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest15.jpg\n",
      "test15.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultsalgal1.jpg\n",
      "algal1.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest47.jpg\n",
      "test47.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest12.jpg\n",
      "test12.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest76.jpg\n",
      "test76.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n",
      "/home/ln-2/Desktop/Alok/SVM/alok1/resultstest133.jpg\n",
      "test133.jpg\n",
      "(752, 1040, 3)\n",
      "(512, 512, 3)\n",
      "3 <class 'numpy.ndarray'>\n",
      "3 <class 'numpy.ndarray'>\n",
      "6\n",
      "13 <class 'numpy.ndarray'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "21\n",
      "21 (21,)\n",
      "\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "create_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Panda Library and matplotlib library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile = pd.read_csv('mycsv.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy</th>\n",
       "      <th>contrast</th>\n",
       "      <th>correlation</th>\n",
       "      <th>variance</th>\n",
       "      <th>inverse difference moment</th>\n",
       "      <th>sum average</th>\n",
       "      <th>sum variance</th>\n",
       "      <th>sum entropy</th>\n",
       "      <th>entropy</th>\n",
       "      <th>difference variance</th>\n",
       "      <th>...</th>\n",
       "      <th>maximal_corr_coeff</th>\n",
       "      <th>mean_B</th>\n",
       "      <th>mean_G</th>\n",
       "      <th>mean_R</th>\n",
       "      <th>std_B</th>\n",
       "      <th>std_G</th>\n",
       "      <th>std_R</th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.151255</td>\n",
       "      <td>83.682817</td>\n",
       "      <td>0.992531</td>\n",
       "      <td>5602.660453</td>\n",
       "      <td>0.524024</td>\n",
       "      <td>166.271382</td>\n",
       "      <td>22326.958994</td>\n",
       "      <td>5.860651</td>\n",
       "      <td>8.105537</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.994969</td>\n",
       "      <td>29.549824</td>\n",
       "      <td>94.431873</td>\n",
       "      <td>80.634457</td>\n",
       "      <td>37.648830</td>\n",
       "      <td>84.138807</td>\n",
       "      <td>74.804819</td>\n",
       "      <td>2.5</td>\n",
       "      <td>12.242641</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.701767</td>\n",
       "      <td>42.595679</td>\n",
       "      <td>0.992800</td>\n",
       "      <td>2957.291822</td>\n",
       "      <td>0.891638</td>\n",
       "      <td>41.561557</td>\n",
       "      <td>11786.571609</td>\n",
       "      <td>1.974422</td>\n",
       "      <td>2.473410</td>\n",
       "      <td>0.002914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.941292</td>\n",
       "      <td>21.951992</td>\n",
       "      <td>27.125298</td>\n",
       "      <td>7.671936</td>\n",
       "      <td>57.780391</td>\n",
       "      <td>69.075932</td>\n",
       "      <td>34.431439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.531359</td>\n",
       "      <td>58.631216</td>\n",
       "      <td>0.990318</td>\n",
       "      <td>3027.364926</td>\n",
       "      <td>0.816442</td>\n",
       "      <td>56.930850</td>\n",
       "      <td>12050.828487</td>\n",
       "      <td>3.107701</td>\n",
       "      <td>3.969937</td>\n",
       "      <td>0.002338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.980912</td>\n",
       "      <td>28.331081</td>\n",
       "      <td>37.507488</td>\n",
       "      <td>10.485035</td>\n",
       "      <td>56.147817</td>\n",
       "      <td>69.558627</td>\n",
       "      <td>32.493657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.021569</td>\n",
       "      <td>168.613335</td>\n",
       "      <td>0.979423</td>\n",
       "      <td>4100.030050</td>\n",
       "      <td>0.400747</td>\n",
       "      <td>240.799945</td>\n",
       "      <td>16231.506865</td>\n",
       "      <td>7.509348</td>\n",
       "      <td>10.394752</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998087</td>\n",
       "      <td>25.628231</td>\n",
       "      <td>148.881607</td>\n",
       "      <td>99.524345</td>\n",
       "      <td>45.078397</td>\n",
       "      <td>75.205177</td>\n",
       "      <td>61.267747</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.130438</td>\n",
       "      <td>72.451101</td>\n",
       "      <td>0.974628</td>\n",
       "      <td>1427.872261</td>\n",
       "      <td>0.550085</td>\n",
       "      <td>84.710300</td>\n",
       "      <td>5639.037943</td>\n",
       "      <td>5.681062</td>\n",
       "      <td>7.755388</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.994639</td>\n",
       "      <td>17.876900</td>\n",
       "      <td>47.727833</td>\n",
       "      <td>40.773682</td>\n",
       "      <td>20.793650</td>\n",
       "      <td>42.261234</td>\n",
       "      <td>38.057497</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.828427</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     energy    contrast  correlation     variance  inverse difference moment  \\\n",
       "0  0.151255   83.682817     0.992531  5602.660453                   0.524024   \n",
       "1  0.701767   42.595679     0.992800  2957.291822                   0.891638   \n",
       "2  0.531359   58.631216     0.990318  3027.364926                   0.816442   \n",
       "3  0.021569  168.613335     0.979423  4100.030050                   0.400747   \n",
       "4  0.130438   72.451101     0.974628  1427.872261                   0.550085   \n",
       "\n",
       "   sum average  sum variance  sum entropy    entropy  difference variance  \\\n",
       "0   166.271382  22326.958994     5.860651   8.105537             0.000905   \n",
       "1    41.561557  11786.571609     1.974422   2.473410             0.002914   \n",
       "2    56.930850  12050.828487     3.107701   3.969937             0.002338   \n",
       "3   240.799945  16231.506865     7.509348  10.394752             0.000551   \n",
       "4    84.710300   5639.037943     5.681062   7.755388             0.000977   \n",
       "\n",
       "   ...    maximal_corr_coeff     mean_B      mean_G     mean_R      std_B  \\\n",
       "0  ...              0.994969  29.549824   94.431873  80.634457  37.648830   \n",
       "1  ...              0.941292  21.951992   27.125298   7.671936  57.780391   \n",
       "2  ...              0.980912  28.331081   37.507488  10.485035  56.147817   \n",
       "3  ...              0.998087  25.628231  148.881607  99.524345  45.078397   \n",
       "4  ...              0.994639  17.876900   47.727833  40.773682  20.793650   \n",
       "\n",
       "       std_G      std_R  area  perimeter  label  \n",
       "0  84.138807  74.804819   2.5  12.242641    3.0  \n",
       "1  69.075932  34.431439   0.0   0.000000    0.0  \n",
       "2  69.558627  32.493657   0.0   0.000000    0.0  \n",
       "3  75.205177  61.267747   2.0   5.656854    0.0  \n",
       "4  42.261234  38.057497   4.0  10.828427    3.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy</th>\n",
       "      <th>contrast</th>\n",
       "      <th>correlation</th>\n",
       "      <th>variance</th>\n",
       "      <th>inverse difference moment</th>\n",
       "      <th>sum average</th>\n",
       "      <th>sum variance</th>\n",
       "      <th>sum entropy</th>\n",
       "      <th>entropy</th>\n",
       "      <th>difference variance</th>\n",
       "      <th>...</th>\n",
       "      <th>maximal_corr_coeff</th>\n",
       "      <th>mean_B</th>\n",
       "      <th>mean_G</th>\n",
       "      <th>mean_R</th>\n",
       "      <th>std_B</th>\n",
       "      <th>std_G</th>\n",
       "      <th>std_R</th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.029560</td>\n",
       "      <td>88.591990</td>\n",
       "      <td>0.959792</td>\n",
       "      <td>1102.015195</td>\n",
       "      <td>0.577856</td>\n",
       "      <td>103.310454</td>\n",
       "      <td>4319.468789</td>\n",
       "      <td>6.757758</td>\n",
       "      <td>8.729105</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998881</td>\n",
       "      <td>35.178432</td>\n",
       "      <td>52.905010</td>\n",
       "      <td>54.959171</td>\n",
       "      <td>27.326199</td>\n",
       "      <td>33.259695</td>\n",
       "      <td>36.639568</td>\n",
       "      <td>23.5</td>\n",
       "      <td>43.213203</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.109290</td>\n",
       "      <td>105.497714</td>\n",
       "      <td>0.990920</td>\n",
       "      <td>5810.045547</td>\n",
       "      <td>0.573776</td>\n",
       "      <td>196.124179</td>\n",
       "      <td>23134.684474</td>\n",
       "      <td>6.207205</td>\n",
       "      <td>8.071277</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998546</td>\n",
       "      <td>54.409065</td>\n",
       "      <td>118.513771</td>\n",
       "      <td>73.734535</td>\n",
       "      <td>66.565131</td>\n",
       "      <td>90.355411</td>\n",
       "      <td>60.412988</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.234705</td>\n",
       "      <td>152.098099</td>\n",
       "      <td>0.983940</td>\n",
       "      <td>4735.327389</td>\n",
       "      <td>0.599432</td>\n",
       "      <td>128.114749</td>\n",
       "      <td>18789.211456</td>\n",
       "      <td>4.912750</td>\n",
       "      <td>6.854427</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987966</td>\n",
       "      <td>23.898781</td>\n",
       "      <td>86.202984</td>\n",
       "      <td>35.382290</td>\n",
       "      <td>44.373544</td>\n",
       "      <td>89.599111</td>\n",
       "      <td>48.247114</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.766612</td>\n",
       "      <td>43.470814</td>\n",
       "      <td>0.987879</td>\n",
       "      <td>1792.762001</td>\n",
       "      <td>0.921410</td>\n",
       "      <td>27.683495</td>\n",
       "      <td>7127.577188</td>\n",
       "      <td>1.515934</td>\n",
       "      <td>1.856504</td>\n",
       "      <td>0.003492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.908212</td>\n",
       "      <td>15.858822</td>\n",
       "      <td>19.659817</td>\n",
       "      <td>1.515675</td>\n",
       "      <td>50.281453</td>\n",
       "      <td>60.100835</td>\n",
       "      <td>9.040244</td>\n",
       "      <td>11927.0</td>\n",
       "      <td>851.033612</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.625702</td>\n",
       "      <td>56.327930</td>\n",
       "      <td>0.991809</td>\n",
       "      <td>3437.573504</td>\n",
       "      <td>0.865713</td>\n",
       "      <td>55.309109</td>\n",
       "      <td>13693.966084</td>\n",
       "      <td>2.409132</td>\n",
       "      <td>3.005656</td>\n",
       "      <td>0.003102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964397</td>\n",
       "      <td>21.811867</td>\n",
       "      <td>34.595039</td>\n",
       "      <td>15.985023</td>\n",
       "      <td>46.840741</td>\n",
       "      <td>72.178082</td>\n",
       "      <td>43.275999</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.414214</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       energy    contrast  correlation     variance  \\\n",
       "197  0.029560   88.591990     0.959792  1102.015195   \n",
       "198  0.109290  105.497714     0.990920  5810.045547   \n",
       "199  0.234705  152.098099     0.983940  4735.327389   \n",
       "200  0.766612   43.470814     0.987879  1792.762001   \n",
       "201  0.625702   56.327930     0.991809  3437.573504   \n",
       "\n",
       "     inverse difference moment  sum average  sum variance  sum entropy  \\\n",
       "197                   0.577856   103.310454   4319.468789     6.757758   \n",
       "198                   0.573776   196.124179  23134.684474     6.207205   \n",
       "199                   0.599432   128.114749  18789.211456     4.912750   \n",
       "200                   0.921410    27.683495   7127.577188     1.515934   \n",
       "201                   0.865713    55.309109  13693.966084     2.409132   \n",
       "\n",
       "      entropy  difference variance  ...    maximal_corr_coeff     mean_B  \\\n",
       "197  8.729105             0.001050  ...              0.998881  35.178432   \n",
       "198  8.071277             0.001130  ...              0.998546  54.409065   \n",
       "199  6.854427             0.001165  ...              0.987966  23.898781   \n",
       "200  1.856504             0.003492  ...              0.908212  15.858822   \n",
       "201  3.005656             0.003102  ...              0.964397  21.811867   \n",
       "\n",
       "         mean_G     mean_R      std_B      std_G      std_R     area  \\\n",
       "197   52.905010  54.959171  27.326199  33.259695  36.639568     23.5   \n",
       "198  118.513771  73.734535  66.565131  90.355411  60.412988      2.0   \n",
       "199   86.202984  35.382290  44.373544  89.599111  48.247114      2.0   \n",
       "200   19.659817   1.515675  50.281453  60.100835   9.040244  11927.0   \n",
       "201   34.595039  15.985023  46.840741  72.178082  43.275999      0.5   \n",
       "\n",
       "      perimeter  label  \n",
       "197   43.213203    1.0  \n",
       "198    5.656854    0.0  \n",
       "199    5.656854    0.0  \n",
       "200  851.033612    0.0  \n",
       "201    3.414214    0.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfile.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile = myfile.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy</th>\n",
       "      <th>contrast</th>\n",
       "      <th>correlation</th>\n",
       "      <th>variance</th>\n",
       "      <th>inverse difference moment</th>\n",
       "      <th>sum average</th>\n",
       "      <th>sum variance</th>\n",
       "      <th>sum entropy</th>\n",
       "      <th>entropy</th>\n",
       "      <th>difference variance</th>\n",
       "      <th>...</th>\n",
       "      <th>maximal_corr_coeff</th>\n",
       "      <th>mean_B</th>\n",
       "      <th>mean_G</th>\n",
       "      <th>mean_R</th>\n",
       "      <th>std_B</th>\n",
       "      <th>std_G</th>\n",
       "      <th>std_R</th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.192417</td>\n",
       "      <td>72.897108</td>\n",
       "      <td>0.993289</td>\n",
       "      <td>5431.398748</td>\n",
       "      <td>0.614740</td>\n",
       "      <td>149.330414</td>\n",
       "      <td>21652.697885</td>\n",
       "      <td>5.561483</td>\n",
       "      <td>7.304616</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997275</td>\n",
       "      <td>24.334641</td>\n",
       "      <td>94.499355</td>\n",
       "      <td>54.225159</td>\n",
       "      <td>41.756239</td>\n",
       "      <td>92.422277</td>\n",
       "      <td>56.412872</td>\n",
       "      <td>5.5</td>\n",
       "      <td>9.071068</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.228674</td>\n",
       "      <td>22.062686</td>\n",
       "      <td>0.997575</td>\n",
       "      <td>4547.956061</td>\n",
       "      <td>0.684219</td>\n",
       "      <td>121.122067</td>\n",
       "      <td>18169.761557</td>\n",
       "      <td>5.376793</td>\n",
       "      <td>6.793665</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998274</td>\n",
       "      <td>38.379612</td>\n",
       "      <td>65.333393</td>\n",
       "      <td>59.050583</td>\n",
       "      <td>46.733073</td>\n",
       "      <td>71.787567</td>\n",
       "      <td>68.684190</td>\n",
       "      <td>5.5</td>\n",
       "      <td>12.242641</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.153598</td>\n",
       "      <td>63.630726</td>\n",
       "      <td>0.992953</td>\n",
       "      <td>4514.795818</td>\n",
       "      <td>0.531286</td>\n",
       "      <td>145.546529</td>\n",
       "      <td>17995.552545</td>\n",
       "      <td>5.825308</td>\n",
       "      <td>8.031944</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995106</td>\n",
       "      <td>79.750870</td>\n",
       "      <td>93.388336</td>\n",
       "      <td>28.942642</td>\n",
       "      <td>74.961494</td>\n",
       "      <td>84.473642</td>\n",
       "      <td>37.316142</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.242641</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.769301</td>\n",
       "      <td>34.285448</td>\n",
       "      <td>0.992006</td>\n",
       "      <td>2143.851081</td>\n",
       "      <td>0.928766</td>\n",
       "      <td>30.900895</td>\n",
       "      <td>8541.118877</td>\n",
       "      <td>1.511281</td>\n",
       "      <td>1.812599</td>\n",
       "      <td>0.003550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.915109</td>\n",
       "      <td>16.005070</td>\n",
       "      <td>21.314579</td>\n",
       "      <td>3.576118</td>\n",
       "      <td>48.680908</td>\n",
       "      <td>62.979935</td>\n",
       "      <td>18.673438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.256946</td>\n",
       "      <td>75.104632</td>\n",
       "      <td>0.995231</td>\n",
       "      <td>7873.304376</td>\n",
       "      <td>0.688725</td>\n",
       "      <td>151.374337</td>\n",
       "      <td>31418.112874</td>\n",
       "      <td>5.162098</td>\n",
       "      <td>6.603945</td>\n",
       "      <td>0.001497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997585</td>\n",
       "      <td>24.964520</td>\n",
       "      <td>87.532627</td>\n",
       "      <td>71.131737</td>\n",
       "      <td>59.350869</td>\n",
       "      <td>100.544815</td>\n",
       "      <td>86.047213</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.034585</td>\n",
       "      <td>211.007311</td>\n",
       "      <td>0.977193</td>\n",
       "      <td>4627.618620</td>\n",
       "      <td>0.404178</td>\n",
       "      <td>233.767679</td>\n",
       "      <td>18299.467171</td>\n",
       "      <td>7.301754</td>\n",
       "      <td>10.246600</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997454</td>\n",
       "      <td>27.689655</td>\n",
       "      <td>144.590858</td>\n",
       "      <td>95.801785</td>\n",
       "      <td>47.251831</td>\n",
       "      <td>80.248106</td>\n",
       "      <td>63.827009</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.772205</td>\n",
       "      <td>32.265973</td>\n",
       "      <td>0.993166</td>\n",
       "      <td>2360.266368</td>\n",
       "      <td>0.908587</td>\n",
       "      <td>32.436979</td>\n",
       "      <td>9408.799500</td>\n",
       "      <td>1.552231</td>\n",
       "      <td>1.978297</td>\n",
       "      <td>0.003104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.900063</td>\n",
       "      <td>15.597744</td>\n",
       "      <td>19.756485</td>\n",
       "      <td>9.349380</td>\n",
       "      <td>46.795882</td>\n",
       "      <td>58.779602</td>\n",
       "      <td>31.145390</td>\n",
       "      <td>99.5</td>\n",
       "      <td>53.556349</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.651938</td>\n",
       "      <td>44.382059</td>\n",
       "      <td>0.991639</td>\n",
       "      <td>2653.426582</td>\n",
       "      <td>0.883038</td>\n",
       "      <td>46.206624</td>\n",
       "      <td>10569.324269</td>\n",
       "      <td>2.183957</td>\n",
       "      <td>2.708647</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954167</td>\n",
       "      <td>22.975254</td>\n",
       "      <td>29.661224</td>\n",
       "      <td>10.041504</td>\n",
       "      <td>51.726987</td>\n",
       "      <td>65.063372</td>\n",
       "      <td>29.985131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.146658</td>\n",
       "      <td>50.129835</td>\n",
       "      <td>0.996713</td>\n",
       "      <td>7626.291149</td>\n",
       "      <td>0.658985</td>\n",
       "      <td>198.008494</td>\n",
       "      <td>30455.034760</td>\n",
       "      <td>5.977753</td>\n",
       "      <td>7.546238</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998951</td>\n",
       "      <td>74.070999</td>\n",
       "      <td>109.381493</td>\n",
       "      <td>87.345341</td>\n",
       "      <td>74.873640</td>\n",
       "      <td>95.165669</td>\n",
       "      <td>78.769876</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.485281</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.040459</td>\n",
       "      <td>148.225557</td>\n",
       "      <td>0.986774</td>\n",
       "      <td>5605.183896</td>\n",
       "      <td>0.420295</td>\n",
       "      <td>237.118255</td>\n",
       "      <td>22272.510027</td>\n",
       "      <td>7.397180</td>\n",
       "      <td>10.134563</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998695</td>\n",
       "      <td>29.388966</td>\n",
       "      <td>141.190071</td>\n",
       "      <td>107.218483</td>\n",
       "      <td>52.567308</td>\n",
       "      <td>85.176159</td>\n",
       "      <td>72.846905</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.790151</td>\n",
       "      <td>29.335108</td>\n",
       "      <td>0.991579</td>\n",
       "      <td>1741.422062</td>\n",
       "      <td>0.929646</td>\n",
       "      <td>26.289397</td>\n",
       "      <td>6936.353138</td>\n",
       "      <td>1.366241</td>\n",
       "      <td>1.678061</td>\n",
       "      <td>0.003232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.889809</td>\n",
       "      <td>15.375862</td>\n",
       "      <td>18.196686</td>\n",
       "      <td>2.246880</td>\n",
       "      <td>49.031662</td>\n",
       "      <td>57.354588</td>\n",
       "      <td>14.433809</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.624685</td>\n",
       "      <td>45.789648</td>\n",
       "      <td>0.993797</td>\n",
       "      <td>3690.458582</td>\n",
       "      <td>0.874884</td>\n",
       "      <td>57.013833</td>\n",
       "      <td>14716.044680</td>\n",
       "      <td>2.389257</td>\n",
       "      <td>2.962654</td>\n",
       "      <td>0.002748</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964616</td>\n",
       "      <td>30.256279</td>\n",
       "      <td>39.078838</td>\n",
       "      <td>6.807224</td>\n",
       "      <td>66.388570</td>\n",
       "      <td>82.963680</td>\n",
       "      <td>26.472614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.694144</td>\n",
       "      <td>45.875700</td>\n",
       "      <td>0.992168</td>\n",
       "      <td>2928.179448</td>\n",
       "      <td>0.895989</td>\n",
       "      <td>43.435683</td>\n",
       "      <td>11666.842094</td>\n",
       "      <td>2.002402</td>\n",
       "      <td>2.469971</td>\n",
       "      <td>0.002945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947141</td>\n",
       "      <td>23.631935</td>\n",
       "      <td>30.025379</td>\n",
       "      <td>4.466053</td>\n",
       "      <td>60.617565</td>\n",
       "      <td>74.391924</td>\n",
       "      <td>21.000358</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.644294</td>\n",
       "      <td>41.037713</td>\n",
       "      <td>0.995397</td>\n",
       "      <td>4457.005257</td>\n",
       "      <td>0.877984</td>\n",
       "      <td>60.466947</td>\n",
       "      <td>17786.983314</td>\n",
       "      <td>2.283116</td>\n",
       "      <td>2.834027</td>\n",
       "      <td>0.002828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.959227</td>\n",
       "      <td>22.772503</td>\n",
       "      <td>33.340370</td>\n",
       "      <td>26.682697</td>\n",
       "      <td>53.953452</td>\n",
       "      <td>73.180149</td>\n",
       "      <td>59.572962</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.143089</td>\n",
       "      <td>89.805130</td>\n",
       "      <td>0.993975</td>\n",
       "      <td>7452.906786</td>\n",
       "      <td>0.566768</td>\n",
       "      <td>200.648778</td>\n",
       "      <td>29721.822014</td>\n",
       "      <td>5.979531</td>\n",
       "      <td>7.931707</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997553</td>\n",
       "      <td>54.330463</td>\n",
       "      <td>119.518723</td>\n",
       "      <td>79.261734</td>\n",
       "      <td>68.131779</td>\n",
       "      <td>101.136027</td>\n",
       "      <td>70.536433</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.029560</td>\n",
       "      <td>88.591990</td>\n",
       "      <td>0.959792</td>\n",
       "      <td>1102.015195</td>\n",
       "      <td>0.577856</td>\n",
       "      <td>103.310454</td>\n",
       "      <td>4319.468789</td>\n",
       "      <td>6.757758</td>\n",
       "      <td>8.729105</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998881</td>\n",
       "      <td>35.178432</td>\n",
       "      <td>52.905010</td>\n",
       "      <td>54.959171</td>\n",
       "      <td>27.326199</td>\n",
       "      <td>33.259695</td>\n",
       "      <td>36.639568</td>\n",
       "      <td>23.5</td>\n",
       "      <td>43.213203</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.109290</td>\n",
       "      <td>105.497714</td>\n",
       "      <td>0.990920</td>\n",
       "      <td>5810.045547</td>\n",
       "      <td>0.573776</td>\n",
       "      <td>196.124179</td>\n",
       "      <td>23134.684474</td>\n",
       "      <td>6.207205</td>\n",
       "      <td>8.071277</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998546</td>\n",
       "      <td>54.409065</td>\n",
       "      <td>118.513771</td>\n",
       "      <td>73.734535</td>\n",
       "      <td>66.565131</td>\n",
       "      <td>90.355411</td>\n",
       "      <td>60.412988</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.234705</td>\n",
       "      <td>152.098099</td>\n",
       "      <td>0.983940</td>\n",
       "      <td>4735.327389</td>\n",
       "      <td>0.599432</td>\n",
       "      <td>128.114749</td>\n",
       "      <td>18789.211456</td>\n",
       "      <td>4.912750</td>\n",
       "      <td>6.854427</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987966</td>\n",
       "      <td>23.898781</td>\n",
       "      <td>86.202984</td>\n",
       "      <td>35.382290</td>\n",
       "      <td>44.373544</td>\n",
       "      <td>89.599111</td>\n",
       "      <td>48.247114</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.766612</td>\n",
       "      <td>43.470814</td>\n",
       "      <td>0.987879</td>\n",
       "      <td>1792.762001</td>\n",
       "      <td>0.921410</td>\n",
       "      <td>27.683495</td>\n",
       "      <td>7127.577188</td>\n",
       "      <td>1.515934</td>\n",
       "      <td>1.856504</td>\n",
       "      <td>0.003492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.908212</td>\n",
       "      <td>15.858822</td>\n",
       "      <td>19.659817</td>\n",
       "      <td>1.515675</td>\n",
       "      <td>50.281453</td>\n",
       "      <td>60.100835</td>\n",
       "      <td>9.040244</td>\n",
       "      <td>11927.0</td>\n",
       "      <td>851.033612</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.625702</td>\n",
       "      <td>56.327930</td>\n",
       "      <td>0.991809</td>\n",
       "      <td>3437.573504</td>\n",
       "      <td>0.865713</td>\n",
       "      <td>55.309109</td>\n",
       "      <td>13693.966084</td>\n",
       "      <td>2.409132</td>\n",
       "      <td>3.005656</td>\n",
       "      <td>0.003102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964397</td>\n",
       "      <td>21.811867</td>\n",
       "      <td>34.595039</td>\n",
       "      <td>15.985023</td>\n",
       "      <td>46.840741</td>\n",
       "      <td>72.178082</td>\n",
       "      <td>43.275999</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.414214</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       energy    contrast  correlation     variance  \\\n",
       "182  0.192417   72.897108     0.993289  5431.398748   \n",
       "183  0.228674   22.062686     0.997575  4547.956061   \n",
       "184  0.153598   63.630726     0.992953  4514.795818   \n",
       "185  0.769301   34.285448     0.992006  2143.851081   \n",
       "186  0.256946   75.104632     0.995231  7873.304376   \n",
       "187  0.034585  211.007311     0.977193  4627.618620   \n",
       "188  0.772205   32.265973     0.993166  2360.266368   \n",
       "189  0.651938   44.382059     0.991639  2653.426582   \n",
       "190  0.146658   50.129835     0.996713  7626.291149   \n",
       "191  0.040459  148.225557     0.986774  5605.183896   \n",
       "192  0.790151   29.335108     0.991579  1741.422062   \n",
       "193  0.624685   45.789648     0.993797  3690.458582   \n",
       "194  0.694144   45.875700     0.992168  2928.179448   \n",
       "195  0.644294   41.037713     0.995397  4457.005257   \n",
       "196  0.143089   89.805130     0.993975  7452.906786   \n",
       "197  0.029560   88.591990     0.959792  1102.015195   \n",
       "198  0.109290  105.497714     0.990920  5810.045547   \n",
       "199  0.234705  152.098099     0.983940  4735.327389   \n",
       "200  0.766612   43.470814     0.987879  1792.762001   \n",
       "201  0.625702   56.327930     0.991809  3437.573504   \n",
       "\n",
       "     inverse difference moment  sum average  sum variance  sum entropy  \\\n",
       "182                   0.614740   149.330414  21652.697885     5.561483   \n",
       "183                   0.684219   121.122067  18169.761557     5.376793   \n",
       "184                   0.531286   145.546529  17995.552545     5.825308   \n",
       "185                   0.928766    30.900895   8541.118877     1.511281   \n",
       "186                   0.688725   151.374337  31418.112874     5.162098   \n",
       "187                   0.404178   233.767679  18299.467171     7.301754   \n",
       "188                   0.908587    32.436979   9408.799500     1.552231   \n",
       "189                   0.883038    46.206624  10569.324269     2.183957   \n",
       "190                   0.658985   198.008494  30455.034760     5.977753   \n",
       "191                   0.420295   237.118255  22272.510027     7.397180   \n",
       "192                   0.929646    26.289397   6936.353138     1.366241   \n",
       "193                   0.874884    57.013833  14716.044680     2.389257   \n",
       "194                   0.895989    43.435683  11666.842094     2.002402   \n",
       "195                   0.877984    60.466947  17786.983314     2.283116   \n",
       "196                   0.566768   200.648778  29721.822014     5.979531   \n",
       "197                   0.577856   103.310454   4319.468789     6.757758   \n",
       "198                   0.573776   196.124179  23134.684474     6.207205   \n",
       "199                   0.599432   128.114749  18789.211456     4.912750   \n",
       "200                   0.921410    27.683495   7127.577188     1.515934   \n",
       "201                   0.865713    55.309109  13693.966084     2.409132   \n",
       "\n",
       "       entropy  difference variance  ...    maximal_corr_coeff     mean_B  \\\n",
       "182   7.304616             0.001173  ...              0.997275  24.334641   \n",
       "183   6.793665             0.001711  ...              0.998274  38.379612   \n",
       "184   8.031944             0.000964  ...              0.995106  79.750870   \n",
       "185   1.812599             0.003550  ...              0.915109  16.005070   \n",
       "186   6.603945             0.001497  ...              0.997585  24.964520   \n",
       "187  10.246600             0.000536  ...              0.997454  27.689655   \n",
       "188   1.978297             0.003104  ...              0.900063  15.597744   \n",
       "189   2.708647             0.002790  ...              0.954167  22.975254   \n",
       "190   7.546238             0.001335  ...              0.998951  74.070999   \n",
       "191  10.134563             0.000572  ...              0.998695  29.388966   \n",
       "192   1.678061             0.003232  ...              0.889809  15.375862   \n",
       "193   2.962654             0.002748  ...              0.964616  30.256279   \n",
       "194   2.469971             0.002945  ...              0.947141  23.631935   \n",
       "195   2.834027             0.002828  ...              0.959227  22.772503   \n",
       "196   7.931707             0.001038  ...              0.997553  54.330463   \n",
       "197   8.729105             0.001050  ...              0.998881  35.178432   \n",
       "198   8.071277             0.001130  ...              0.998546  54.409065   \n",
       "199   6.854427             0.001165  ...              0.987966  23.898781   \n",
       "200   1.856504             0.003492  ...              0.908212  15.858822   \n",
       "201   3.005656             0.003102  ...              0.964397  21.811867   \n",
       "\n",
       "         mean_G      mean_R      std_B       std_G      std_R     area  \\\n",
       "182   94.499355   54.225159  41.756239   92.422277  56.412872      5.5   \n",
       "183   65.333393   59.050583  46.733073   71.787567  68.684190      5.5   \n",
       "184   93.388336   28.942642  74.961494   84.473642  37.316142      0.5   \n",
       "185   21.314579    3.576118  48.680908   62.979935  18.673438      0.0   \n",
       "186   87.532627   71.131737  59.350869  100.544815  86.047213      2.0   \n",
       "187  144.590858   95.801785  47.251831   80.248106  63.827009      2.0   \n",
       "188   19.756485    9.349380  46.795882   58.779602  31.145390     99.5   \n",
       "189   29.661224   10.041504  51.726987   65.063372  29.985131      0.0   \n",
       "190  109.381493   87.345341  74.873640   95.165669  78.769876     10.0   \n",
       "191  141.190071  107.218483  52.567308   85.176159  72.846905      2.0   \n",
       "192   18.196686    2.246880  49.031662   57.354588  14.433809      2.0   \n",
       "193   39.078838    6.807224  66.388570   82.963680  26.472614      0.0   \n",
       "194   30.025379    4.466053  60.617565   74.391924  21.000358      2.0   \n",
       "195   33.340370   26.682697  53.953452   73.180149  59.572962      2.0   \n",
       "196  119.518723   79.261734  68.131779  101.136027  70.536433      2.0   \n",
       "197   52.905010   54.959171  27.326199   33.259695  36.639568     23.5   \n",
       "198  118.513771   73.734535  66.565131   90.355411  60.412988      2.0   \n",
       "199   86.202984   35.382290  44.373544   89.599111  48.247114      2.0   \n",
       "200   19.659817    1.515675  50.281453   60.100835   9.040244  11927.0   \n",
       "201   34.595039   15.985023  46.840741   72.178082  43.275999      0.5   \n",
       "\n",
       "      perimeter  label  \n",
       "182    9.071068    0.0  \n",
       "183   12.242641    3.0  \n",
       "184    8.242641    3.0  \n",
       "185    0.000000    0.0  \n",
       "186    5.656854    0.0  \n",
       "187    5.656854    0.0  \n",
       "188   53.556349    0.0  \n",
       "189    0.000000    0.0  \n",
       "190   12.485281    2.0  \n",
       "191    5.656854    0.0  \n",
       "192    5.656854    0.0  \n",
       "193    0.000000    0.0  \n",
       "194    5.656854    0.0  \n",
       "195    5.656854    2.0  \n",
       "196    5.656854    0.0  \n",
       "197   43.213203    1.0  \n",
       "198    5.656854    0.0  \n",
       "199    5.656854    0.0  \n",
       "200  851.033612    0.0  \n",
       "201    3.414214    0.0  \n",
       "\n",
       "[20 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfile[182:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperating the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file = myfile.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylabel = myfile.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylabel = mylabel.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy</th>\n",
       "      <th>contrast</th>\n",
       "      <th>correlation</th>\n",
       "      <th>variance</th>\n",
       "      <th>inverse difference moment</th>\n",
       "      <th>sum average</th>\n",
       "      <th>sum variance</th>\n",
       "      <th>sum entropy</th>\n",
       "      <th>entropy</th>\n",
       "      <th>difference variance</th>\n",
       "      <th>...</th>\n",
       "      <th>info_corr</th>\n",
       "      <th>maximal_corr_coeff</th>\n",
       "      <th>mean_B</th>\n",
       "      <th>mean_G</th>\n",
       "      <th>mean_R</th>\n",
       "      <th>std_B</th>\n",
       "      <th>std_G</th>\n",
       "      <th>std_R</th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.192417</td>\n",
       "      <td>72.897108</td>\n",
       "      <td>0.993289</td>\n",
       "      <td>5431.398748</td>\n",
       "      <td>0.614740</td>\n",
       "      <td>149.330414</td>\n",
       "      <td>21652.697885</td>\n",
       "      <td>5.561483</td>\n",
       "      <td>7.304616</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.527975</td>\n",
       "      <td>0.997275</td>\n",
       "      <td>24.334641</td>\n",
       "      <td>94.499355</td>\n",
       "      <td>54.225159</td>\n",
       "      <td>41.756239</td>\n",
       "      <td>92.422277</td>\n",
       "      <td>56.412872</td>\n",
       "      <td>5.5</td>\n",
       "      <td>9.071068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.228674</td>\n",
       "      <td>22.062686</td>\n",
       "      <td>0.997575</td>\n",
       "      <td>4547.956061</td>\n",
       "      <td>0.684219</td>\n",
       "      <td>121.122067</td>\n",
       "      <td>18169.761557</td>\n",
       "      <td>5.376793</td>\n",
       "      <td>6.793665</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.591206</td>\n",
       "      <td>0.998274</td>\n",
       "      <td>38.379612</td>\n",
       "      <td>65.333393</td>\n",
       "      <td>59.050583</td>\n",
       "      <td>46.733073</td>\n",
       "      <td>71.787567</td>\n",
       "      <td>68.684190</td>\n",
       "      <td>5.5</td>\n",
       "      <td>12.242641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.153598</td>\n",
       "      <td>63.630726</td>\n",
       "      <td>0.992953</td>\n",
       "      <td>4514.795818</td>\n",
       "      <td>0.531286</td>\n",
       "      <td>145.546529</td>\n",
       "      <td>17995.552545</td>\n",
       "      <td>5.825308</td>\n",
       "      <td>8.031944</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.450169</td>\n",
       "      <td>0.995106</td>\n",
       "      <td>79.750870</td>\n",
       "      <td>93.388336</td>\n",
       "      <td>28.942642</td>\n",
       "      <td>74.961494</td>\n",
       "      <td>84.473642</td>\n",
       "      <td>37.316142</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.242641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.769301</td>\n",
       "      <td>34.285448</td>\n",
       "      <td>0.992006</td>\n",
       "      <td>2143.851081</td>\n",
       "      <td>0.928766</td>\n",
       "      <td>30.900895</td>\n",
       "      <td>8541.118877</td>\n",
       "      <td>1.511281</td>\n",
       "      <td>1.812599</td>\n",
       "      <td>0.003550</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.669718</td>\n",
       "      <td>0.915109</td>\n",
       "      <td>16.005070</td>\n",
       "      <td>21.314579</td>\n",
       "      <td>3.576118</td>\n",
       "      <td>48.680908</td>\n",
       "      <td>62.979935</td>\n",
       "      <td>18.673438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.256946</td>\n",
       "      <td>75.104632</td>\n",
       "      <td>0.995231</td>\n",
       "      <td>7873.304376</td>\n",
       "      <td>0.688725</td>\n",
       "      <td>151.374337</td>\n",
       "      <td>31418.112874</td>\n",
       "      <td>5.162098</td>\n",
       "      <td>6.603945</td>\n",
       "      <td>0.001497</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.577850</td>\n",
       "      <td>0.997585</td>\n",
       "      <td>24.964520</td>\n",
       "      <td>87.532627</td>\n",
       "      <td>71.131737</td>\n",
       "      <td>59.350869</td>\n",
       "      <td>100.544815</td>\n",
       "      <td>86.047213</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.034585</td>\n",
       "      <td>211.007311</td>\n",
       "      <td>0.977193</td>\n",
       "      <td>4627.618620</td>\n",
       "      <td>0.404178</td>\n",
       "      <td>233.767679</td>\n",
       "      <td>18299.467171</td>\n",
       "      <td>7.301754</td>\n",
       "      <td>10.246600</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.417823</td>\n",
       "      <td>0.997454</td>\n",
       "      <td>27.689655</td>\n",
       "      <td>144.590858</td>\n",
       "      <td>95.801785</td>\n",
       "      <td>47.251831</td>\n",
       "      <td>80.248106</td>\n",
       "      <td>63.827009</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.772205</td>\n",
       "      <td>32.265973</td>\n",
       "      <td>0.993166</td>\n",
       "      <td>2360.266368</td>\n",
       "      <td>0.908587</td>\n",
       "      <td>32.436979</td>\n",
       "      <td>9408.799500</td>\n",
       "      <td>1.552231</td>\n",
       "      <td>1.978297</td>\n",
       "      <td>0.003104</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.592231</td>\n",
       "      <td>0.900063</td>\n",
       "      <td>15.597744</td>\n",
       "      <td>19.756485</td>\n",
       "      <td>9.349380</td>\n",
       "      <td>46.795882</td>\n",
       "      <td>58.779602</td>\n",
       "      <td>31.145390</td>\n",
       "      <td>99.5</td>\n",
       "      <td>53.556349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.651938</td>\n",
       "      <td>44.382059</td>\n",
       "      <td>0.991639</td>\n",
       "      <td>2653.426582</td>\n",
       "      <td>0.883038</td>\n",
       "      <td>46.206624</td>\n",
       "      <td>10569.324269</td>\n",
       "      <td>2.183957</td>\n",
       "      <td>2.708647</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.617529</td>\n",
       "      <td>0.954167</td>\n",
       "      <td>22.975254</td>\n",
       "      <td>29.661224</td>\n",
       "      <td>10.041504</td>\n",
       "      <td>51.726987</td>\n",
       "      <td>65.063372</td>\n",
       "      <td>29.985131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.146658</td>\n",
       "      <td>50.129835</td>\n",
       "      <td>0.996713</td>\n",
       "      <td>7626.291149</td>\n",
       "      <td>0.658985</td>\n",
       "      <td>198.008494</td>\n",
       "      <td>30455.034760</td>\n",
       "      <td>5.977753</td>\n",
       "      <td>7.546238</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.582778</td>\n",
       "      <td>0.998951</td>\n",
       "      <td>74.070999</td>\n",
       "      <td>109.381493</td>\n",
       "      <td>87.345341</td>\n",
       "      <td>74.873640</td>\n",
       "      <td>95.165669</td>\n",
       "      <td>78.769876</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.485281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.040459</td>\n",
       "      <td>148.225557</td>\n",
       "      <td>0.986774</td>\n",
       "      <td>5605.183896</td>\n",
       "      <td>0.420295</td>\n",
       "      <td>237.118255</td>\n",
       "      <td>22272.510027</td>\n",
       "      <td>7.397180</td>\n",
       "      <td>10.134563</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.458772</td>\n",
       "      <td>0.998695</td>\n",
       "      <td>29.388966</td>\n",
       "      <td>141.190071</td>\n",
       "      <td>107.218483</td>\n",
       "      <td>52.567308</td>\n",
       "      <td>85.176159</td>\n",
       "      <td>72.846905</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.790151</td>\n",
       "      <td>29.335108</td>\n",
       "      <td>0.991579</td>\n",
       "      <td>1741.422062</td>\n",
       "      <td>0.929646</td>\n",
       "      <td>26.289397</td>\n",
       "      <td>6936.353138</td>\n",
       "      <td>1.366241</td>\n",
       "      <td>1.678061</td>\n",
       "      <td>0.003232</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.637695</td>\n",
       "      <td>0.889809</td>\n",
       "      <td>15.375862</td>\n",
       "      <td>18.196686</td>\n",
       "      <td>2.246880</td>\n",
       "      <td>49.031662</td>\n",
       "      <td>57.354588</td>\n",
       "      <td>14.433809</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.624685</td>\n",
       "      <td>45.789648</td>\n",
       "      <td>0.993797</td>\n",
       "      <td>3690.458582</td>\n",
       "      <td>0.874884</td>\n",
       "      <td>57.013833</td>\n",
       "      <td>14716.044680</td>\n",
       "      <td>2.389257</td>\n",
       "      <td>2.962654</td>\n",
       "      <td>0.002748</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.622024</td>\n",
       "      <td>0.964616</td>\n",
       "      <td>30.256279</td>\n",
       "      <td>39.078838</td>\n",
       "      <td>6.807224</td>\n",
       "      <td>66.388570</td>\n",
       "      <td>82.963680</td>\n",
       "      <td>26.472614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.694144</td>\n",
       "      <td>45.875700</td>\n",
       "      <td>0.992168</td>\n",
       "      <td>2928.179448</td>\n",
       "      <td>0.895989</td>\n",
       "      <td>43.435683</td>\n",
       "      <td>11666.842094</td>\n",
       "      <td>2.002402</td>\n",
       "      <td>2.469971</td>\n",
       "      <td>0.002945</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.632487</td>\n",
       "      <td>0.947141</td>\n",
       "      <td>23.631935</td>\n",
       "      <td>30.025379</td>\n",
       "      <td>4.466053</td>\n",
       "      <td>60.617565</td>\n",
       "      <td>74.391924</td>\n",
       "      <td>21.000358</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.644294</td>\n",
       "      <td>41.037713</td>\n",
       "      <td>0.995397</td>\n",
       "      <td>4457.005257</td>\n",
       "      <td>0.877984</td>\n",
       "      <td>60.466947</td>\n",
       "      <td>17786.983314</td>\n",
       "      <td>2.283116</td>\n",
       "      <td>2.834027</td>\n",
       "      <td>0.002828</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.617860</td>\n",
       "      <td>0.959227</td>\n",
       "      <td>22.772503</td>\n",
       "      <td>33.340370</td>\n",
       "      <td>26.682697</td>\n",
       "      <td>53.953452</td>\n",
       "      <td>73.180149</td>\n",
       "      <td>59.572962</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.143089</td>\n",
       "      <td>89.805130</td>\n",
       "      <td>0.993975</td>\n",
       "      <td>7452.906786</td>\n",
       "      <td>0.566768</td>\n",
       "      <td>200.648778</td>\n",
       "      <td>29721.822014</td>\n",
       "      <td>5.979531</td>\n",
       "      <td>7.931707</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.507896</td>\n",
       "      <td>0.997553</td>\n",
       "      <td>54.330463</td>\n",
       "      <td>119.518723</td>\n",
       "      <td>79.261734</td>\n",
       "      <td>68.131779</td>\n",
       "      <td>101.136027</td>\n",
       "      <td>70.536433</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.029560</td>\n",
       "      <td>88.591990</td>\n",
       "      <td>0.959792</td>\n",
       "      <td>1102.015195</td>\n",
       "      <td>0.577856</td>\n",
       "      <td>103.310454</td>\n",
       "      <td>4319.468789</td>\n",
       "      <td>6.757758</td>\n",
       "      <td>8.729105</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.523998</td>\n",
       "      <td>0.998881</td>\n",
       "      <td>35.178432</td>\n",
       "      <td>52.905010</td>\n",
       "      <td>54.959171</td>\n",
       "      <td>27.326199</td>\n",
       "      <td>33.259695</td>\n",
       "      <td>36.639568</td>\n",
       "      <td>23.5</td>\n",
       "      <td>43.213203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.109290</td>\n",
       "      <td>105.497714</td>\n",
       "      <td>0.990920</td>\n",
       "      <td>5810.045547</td>\n",
       "      <td>0.573776</td>\n",
       "      <td>196.124179</td>\n",
       "      <td>23134.684474</td>\n",
       "      <td>6.207205</td>\n",
       "      <td>8.071277</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.533876</td>\n",
       "      <td>0.998546</td>\n",
       "      <td>54.409065</td>\n",
       "      <td>118.513771</td>\n",
       "      <td>73.734535</td>\n",
       "      <td>66.565131</td>\n",
       "      <td>90.355411</td>\n",
       "      <td>60.412988</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.234705</td>\n",
       "      <td>152.098099</td>\n",
       "      <td>0.983940</td>\n",
       "      <td>4735.327389</td>\n",
       "      <td>0.599432</td>\n",
       "      <td>128.114749</td>\n",
       "      <td>18789.211456</td>\n",
       "      <td>4.912750</td>\n",
       "      <td>6.854427</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.429480</td>\n",
       "      <td>0.987966</td>\n",
       "      <td>23.898781</td>\n",
       "      <td>86.202984</td>\n",
       "      <td>35.382290</td>\n",
       "      <td>44.373544</td>\n",
       "      <td>89.599111</td>\n",
       "      <td>48.247114</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.766612</td>\n",
       "      <td>43.470814</td>\n",
       "      <td>0.987879</td>\n",
       "      <td>1792.762001</td>\n",
       "      <td>0.921410</td>\n",
       "      <td>27.683495</td>\n",
       "      <td>7127.577188</td>\n",
       "      <td>1.515934</td>\n",
       "      <td>1.856504</td>\n",
       "      <td>0.003492</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.640145</td>\n",
       "      <td>0.908212</td>\n",
       "      <td>15.858822</td>\n",
       "      <td>19.659817</td>\n",
       "      <td>1.515675</td>\n",
       "      <td>50.281453</td>\n",
       "      <td>60.100835</td>\n",
       "      <td>9.040244</td>\n",
       "      <td>11927.0</td>\n",
       "      <td>851.033612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.625702</td>\n",
       "      <td>56.327930</td>\n",
       "      <td>0.991809</td>\n",
       "      <td>3437.573504</td>\n",
       "      <td>0.865713</td>\n",
       "      <td>55.309109</td>\n",
       "      <td>13693.966084</td>\n",
       "      <td>2.409132</td>\n",
       "      <td>3.005656</td>\n",
       "      <td>0.003102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.614612</td>\n",
       "      <td>0.964397</td>\n",
       "      <td>21.811867</td>\n",
       "      <td>34.595039</td>\n",
       "      <td>15.985023</td>\n",
       "      <td>46.840741</td>\n",
       "      <td>72.178082</td>\n",
       "      <td>43.275999</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.414214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       energy    contrast  correlation     variance  \\\n",
       "182  0.192417   72.897108     0.993289  5431.398748   \n",
       "183  0.228674   22.062686     0.997575  4547.956061   \n",
       "184  0.153598   63.630726     0.992953  4514.795818   \n",
       "185  0.769301   34.285448     0.992006  2143.851081   \n",
       "186  0.256946   75.104632     0.995231  7873.304376   \n",
       "187  0.034585  211.007311     0.977193  4627.618620   \n",
       "188  0.772205   32.265973     0.993166  2360.266368   \n",
       "189  0.651938   44.382059     0.991639  2653.426582   \n",
       "190  0.146658   50.129835     0.996713  7626.291149   \n",
       "191  0.040459  148.225557     0.986774  5605.183896   \n",
       "192  0.790151   29.335108     0.991579  1741.422062   \n",
       "193  0.624685   45.789648     0.993797  3690.458582   \n",
       "194  0.694144   45.875700     0.992168  2928.179448   \n",
       "195  0.644294   41.037713     0.995397  4457.005257   \n",
       "196  0.143089   89.805130     0.993975  7452.906786   \n",
       "197  0.029560   88.591990     0.959792  1102.015195   \n",
       "198  0.109290  105.497714     0.990920  5810.045547   \n",
       "199  0.234705  152.098099     0.983940  4735.327389   \n",
       "200  0.766612   43.470814     0.987879  1792.762001   \n",
       "201  0.625702   56.327930     0.991809  3437.573504   \n",
       "\n",
       "     inverse difference moment  sum average  sum variance  sum entropy  \\\n",
       "182                   0.614740   149.330414  21652.697885     5.561483   \n",
       "183                   0.684219   121.122067  18169.761557     5.376793   \n",
       "184                   0.531286   145.546529  17995.552545     5.825308   \n",
       "185                   0.928766    30.900895   8541.118877     1.511281   \n",
       "186                   0.688725   151.374337  31418.112874     5.162098   \n",
       "187                   0.404178   233.767679  18299.467171     7.301754   \n",
       "188                   0.908587    32.436979   9408.799500     1.552231   \n",
       "189                   0.883038    46.206624  10569.324269     2.183957   \n",
       "190                   0.658985   198.008494  30455.034760     5.977753   \n",
       "191                   0.420295   237.118255  22272.510027     7.397180   \n",
       "192                   0.929646    26.289397   6936.353138     1.366241   \n",
       "193                   0.874884    57.013833  14716.044680     2.389257   \n",
       "194                   0.895989    43.435683  11666.842094     2.002402   \n",
       "195                   0.877984    60.466947  17786.983314     2.283116   \n",
       "196                   0.566768   200.648778  29721.822014     5.979531   \n",
       "197                   0.577856   103.310454   4319.468789     6.757758   \n",
       "198                   0.573776   196.124179  23134.684474     6.207205   \n",
       "199                   0.599432   128.114749  18789.211456     4.912750   \n",
       "200                   0.921410    27.683495   7127.577188     1.515934   \n",
       "201                   0.865713    55.309109  13693.966084     2.409132   \n",
       "\n",
       "       entropy  difference variance     ...      info_corr  \\\n",
       "182   7.304616             0.001173     ...      -0.527975   \n",
       "183   6.793665             0.001711     ...      -0.591206   \n",
       "184   8.031944             0.000964     ...      -0.450169   \n",
       "185   1.812599             0.003550     ...      -0.669718   \n",
       "186   6.603945             0.001497     ...      -0.577850   \n",
       "187  10.246600             0.000536     ...      -0.417823   \n",
       "188   1.978297             0.003104     ...      -0.592231   \n",
       "189   2.708647             0.002790     ...      -0.617529   \n",
       "190   7.546238             0.001335     ...      -0.582778   \n",
       "191  10.134563             0.000572     ...      -0.458772   \n",
       "192   1.678061             0.003232     ...      -0.637695   \n",
       "193   2.962654             0.002748     ...      -0.622024   \n",
       "194   2.469971             0.002945     ...      -0.632487   \n",
       "195   2.834027             0.002828     ...      -0.617860   \n",
       "196   7.931707             0.001038     ...      -0.507896   \n",
       "197   8.729105             0.001050     ...      -0.523998   \n",
       "198   8.071277             0.001130     ...      -0.533876   \n",
       "199   6.854427             0.001165     ...      -0.429480   \n",
       "200   1.856504             0.003492     ...      -0.640145   \n",
       "201   3.005656             0.003102     ...      -0.614612   \n",
       "\n",
       "     maximal_corr_coeff     mean_B      mean_G      mean_R      std_B  \\\n",
       "182            0.997275  24.334641   94.499355   54.225159  41.756239   \n",
       "183            0.998274  38.379612   65.333393   59.050583  46.733073   \n",
       "184            0.995106  79.750870   93.388336   28.942642  74.961494   \n",
       "185            0.915109  16.005070   21.314579    3.576118  48.680908   \n",
       "186            0.997585  24.964520   87.532627   71.131737  59.350869   \n",
       "187            0.997454  27.689655  144.590858   95.801785  47.251831   \n",
       "188            0.900063  15.597744   19.756485    9.349380  46.795882   \n",
       "189            0.954167  22.975254   29.661224   10.041504  51.726987   \n",
       "190            0.998951  74.070999  109.381493   87.345341  74.873640   \n",
       "191            0.998695  29.388966  141.190071  107.218483  52.567308   \n",
       "192            0.889809  15.375862   18.196686    2.246880  49.031662   \n",
       "193            0.964616  30.256279   39.078838    6.807224  66.388570   \n",
       "194            0.947141  23.631935   30.025379    4.466053  60.617565   \n",
       "195            0.959227  22.772503   33.340370   26.682697  53.953452   \n",
       "196            0.997553  54.330463  119.518723   79.261734  68.131779   \n",
       "197            0.998881  35.178432   52.905010   54.959171  27.326199   \n",
       "198            0.998546  54.409065  118.513771   73.734535  66.565131   \n",
       "199            0.987966  23.898781   86.202984   35.382290  44.373544   \n",
       "200            0.908212  15.858822   19.659817    1.515675  50.281453   \n",
       "201            0.964397  21.811867   34.595039   15.985023  46.840741   \n",
       "\n",
       "          std_G      std_R     area   perimeter  \n",
       "182   92.422277  56.412872      5.5    9.071068  \n",
       "183   71.787567  68.684190      5.5   12.242641  \n",
       "184   84.473642  37.316142      0.5    8.242641  \n",
       "185   62.979935  18.673438      0.0    0.000000  \n",
       "186  100.544815  86.047213      2.0    5.656854  \n",
       "187   80.248106  63.827009      2.0    5.656854  \n",
       "188   58.779602  31.145390     99.5   53.556349  \n",
       "189   65.063372  29.985131      0.0    0.000000  \n",
       "190   95.165669  78.769876     10.0   12.485281  \n",
       "191   85.176159  72.846905      2.0    5.656854  \n",
       "192   57.354588  14.433809      2.0    5.656854  \n",
       "193   82.963680  26.472614      0.0    0.000000  \n",
       "194   74.391924  21.000358      2.0    5.656854  \n",
       "195   73.180149  59.572962      2.0    5.656854  \n",
       "196  101.136027  70.536433      2.0    5.656854  \n",
       "197   33.259695  36.639568     23.5   43.213203  \n",
       "198   90.355411  60.412988      2.0    5.656854  \n",
       "199   89.599111  48.247114      2.0    5.656854  \n",
       "200   60.100835   9.040244  11927.0  851.033612  \n",
       "201   72.178082  43.275999      0.5    3.414214  \n",
       "\n",
       "[20 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file[182:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182    0\n",
       "183    3\n",
       "184    3\n",
       "185    0\n",
       "186    0\n",
       "187    0\n",
       "188    0\n",
       "189    0\n",
       "190    2\n",
       "191    0\n",
       "192    0\n",
       "193    0\n",
       "194    0\n",
       "195    2\n",
       "196    0\n",
       "197    1\n",
       "198    0\n",
       "199    0\n",
       "200    0\n",
       "201    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mylabel[182:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard = preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.618812\n",
       "std        1.153943\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        0.000000\n",
       "max        3.000000\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mylabel.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.449989\n",
       "std        0.272493\n",
       "min        0.007383\n",
       "25%        0.164645\n",
       "50%        0.555137\n",
       "75%        0.681422\n",
       "max        0.857570\n",
       "Name: energy, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['energy'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ln-2/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "my_file['energy'] = (my_file['energy'] - my_file['energy'].min())/(my_file['energy'].max() - my_file['energy'].min()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.520599\n",
       "std        0.320510\n",
       "min        0.000000\n",
       "25%        0.184974\n",
       "50%        0.644275\n",
       "75%        0.792813\n",
       "max        1.000000\n",
       "Name: energy, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['energy'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean      65.700426\n",
       "std       42.120548\n",
       "min       20.559969\n",
       "25%       36.367697\n",
       "50%       50.444148\n",
       "75%       79.971658\n",
       "max      238.228420\n",
       "Name: contrast, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['contrast'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ln-2/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "my_file['contrast'] = (my_file['contrast'] - my_file['contrast'].min())/(my_file['contrast'].max() - my_file['contrast'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.207382\n",
       "std        0.193508\n",
       "min        0.000000\n",
       "25%        0.072623\n",
       "50%        0.137292\n",
       "75%        0.272946\n",
       "max        1.000000\n",
       "Name: contrast, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['contrast'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.990490\n",
       "std        0.005369\n",
       "min        0.959792\n",
       "25%        0.988503\n",
       "50%        0.991810\n",
       "75%        0.994156\n",
       "max        0.997575\n",
       "Name: correlation, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['correlation'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file = my_file.drop('correlation', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      202.000000\n",
       "mean      3757.872814\n",
       "std       1790.173709\n",
       "min        870.935814\n",
       "25%       2465.082402\n",
       "50%       3499.463468\n",
       "75%       4752.818218\n",
       "max      10266.490134\n",
       "Name: variance, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['variance'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file['variance'] = (my_file['variance'] - my_file['variance'].min())/(my_file['variance'].max() - my_file['variance'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.307266\n",
       "std        0.190534\n",
       "min        0.000000\n",
       "25%        0.169670\n",
       "50%        0.279763\n",
       "75%        0.413162\n",
       "max        1.000000\n",
       "Name: variance, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['variance'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.748944\n",
       "std        0.169738\n",
       "min        0.316277\n",
       "25%        0.598432\n",
       "50%        0.837668\n",
       "75%        0.888959\n",
       "max        0.948041\n",
       "Name: inverse difference moment, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['inverse difference moment'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file['inverse difference moment'] = (my_file['inverse difference moment'] - my_file['inverse difference moment'].min())/(my_file['inverse difference moment'].max() - my_file['inverse difference moment'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.684856\n",
       "std        0.268673\n",
       "min        0.000000\n",
       "25%        0.446615\n",
       "50%        0.825293\n",
       "75%        0.906481\n",
       "max        1.000000\n",
       "Name: inverse difference moment, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['inverse difference moment'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean      97.614647\n",
       "std       71.928711\n",
       "min       16.617906\n",
       "25%       42.179866\n",
       "50%       62.632733\n",
       "75%      148.719413\n",
       "max      286.685535\n",
       "Name: sum average, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['sum average'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file['sum average'] = (my_file['sum average'] - my_file['sum average'].min())/(my_file['sum average'].max() - my_file['sum average'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.299913\n",
       "std        0.266336\n",
       "min        0.000000\n",
       "25%        0.094650\n",
       "50%        0.170383\n",
       "75%        0.489142\n",
       "max        1.000000\n",
       "Name: sum average, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['sum average'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      202.000000\n",
       "mean     14965.790830\n",
       "std       7138.479236\n",
       "min       3457.902315\n",
       "25%       9818.651383\n",
       "50%      13942.149590\n",
       "75%      18848.886987\n",
       "max      40955.804666\n",
       "Name: sum variance, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['sum variance'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file['sum variance'] = (my_file['sum variance'] - my_file['sum variance'].min())/(my_file['sum variance'].max() - my_file['sum variance'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.306894\n",
       "std        0.190370\n",
       "min        0.000000\n",
       "25%        0.169629\n",
       "50%        0.279596\n",
       "75%        0.410449\n",
       "max        1.000000\n",
       "Name: sum variance, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['sum variance'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       3.750295\n",
       "std        2.045991\n",
       "min        0.978486\n",
       "25%        2.049140\n",
       "50%        2.863879\n",
       "75%        5.662932\n",
       "max        7.957388\n",
       "Name: sum entropy, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['sum entropy'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file['sum entropy'] = (my_file['sum entropy'] - my_file['sum entropy'].min())/(my_file['sum entropy'].max() - my_file['sum entropy'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.397170\n",
       "std        0.293168\n",
       "min        0.000000\n",
       "25%        0.153413\n",
       "50%        0.270156\n",
       "75%        0.671230\n",
       "max        1.000000\n",
       "Name: sum entropy, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['sum entropy'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       4.902418\n",
       "std        2.832211\n",
       "min        1.210341\n",
       "25%        2.547233\n",
       "50%        3.492737\n",
       "75%        7.477470\n",
       "max       11.349265\n",
       "Name: entropy, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['entropy'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file['entropy'] = (my_file['entropy'] - my_file['entropy'].min())/(my_file['entropy'].max() - my_file['entropy'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.364149\n",
       "std        0.279340\n",
       "min        0.000000\n",
       "25%        0.131857\n",
       "50%        0.225112\n",
       "75%        0.618126\n",
       "max        1.000000\n",
       "Name: entropy, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['entropy'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.002162\n",
       "std        0.000972\n",
       "min        0.000383\n",
       "25%        0.001173\n",
       "50%        0.002487\n",
       "75%        0.002906\n",
       "max        0.004024\n",
       "Name: difference variance, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['difference variance'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file['difference variance'] = (my_file['difference variance'] - my_file['difference variance'].min())/(my_file['difference variance'].max() - my_file['difference variance'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.488644\n",
       "std        0.267015\n",
       "min        0.000000\n",
       "25%        0.216942\n",
       "50%        0.577768\n",
       "75%        0.692815\n",
       "max        1.000000\n",
       "Name: difference variance, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['difference variance'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       1.844972\n",
       "std        0.914575\n",
       "min        0.592005\n",
       "25%        1.076601\n",
       "50%        1.436997\n",
       "75%        2.581673\n",
       "max        4.194239\n",
       "Name: difference entropy, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['difference entropy'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file['difference entropy'] = (my_file['difference entropy'] - my_file['difference entropy'].min())/(my_file['difference entropy'].max() - my_file['difference entropy'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.347831\n",
       "std        0.253891\n",
       "min        0.000000\n",
       "25%        0.134527\n",
       "50%        0.234574\n",
       "75%        0.552343\n",
       "max        1.000000\n",
       "Name: difference entropy, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['difference entropy'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean      -0.566764\n",
       "std        0.074023\n",
       "min       -0.689997\n",
       "25%       -0.620178\n",
       "50%       -0.587485\n",
       "75%       -0.518922\n",
       "max       -0.324361\n",
       "Name: info_corr, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['info_corr'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file = my_file.drop('info_corr', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.964144\n",
       "std        0.039334\n",
       "min        0.823801\n",
       "25%        0.946784\n",
       "50%        0.974496\n",
       "75%        0.996552\n",
       "max        0.999570\n",
       "Name: maximal_corr_coeff, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['maximal_corr_coeff'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file = my_file.drop('maximal_corr_coeff', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean      28.971899\n",
       "std       15.828901\n",
       "min        3.971340\n",
       "25%       18.062471\n",
       "50%       24.345436\n",
       "75%       35.163239\n",
       "max       85.481976\n",
       "Name: mean_B, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['mean_B'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file['mean_B'] = (my_file['mean_B'] - my_file['mean_B'].min())/(my_file['mean_B'].max() - my_file['mean_B'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.306715\n",
       "std        0.194194\n",
       "min        0.000000\n",
       "25%        0.172875\n",
       "50%        0.249956\n",
       "75%        0.382673\n",
       "max        1.000000\n",
       "Name: mean_B, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['mean_B'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean      59.556504\n",
       "std       42.064186\n",
       "min       11.144627\n",
       "25%       26.601417\n",
       "50%       39.483566\n",
       "75%       92.039097\n",
       "max      168.650845\n",
       "Name: mean_G, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['mean_G'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file['mean_G'] = (my_file['mean_G'] - my_file['mean_G'].min())/(my_file['mean_G'].max() - my_file['mean_G'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.307365\n",
       "std        0.267064\n",
       "min        0.000000\n",
       "25%        0.098134\n",
       "50%        0.179923\n",
       "75%        0.513595\n",
       "max        1.000000\n",
       "Name: mean_G, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['mean_G'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean      34.826111\n",
       "std       35.821593\n",
       "min        0.762230\n",
       "25%        6.179100\n",
       "50%       17.057322\n",
       "75%       66.565775\n",
       "max      130.789558\n",
       "Name: mean_R, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['mean_R'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file['mean_R'] = (my_file['mean_R'] - my_file['mean_R'].min())/(my_file['mean_R'].max() - my_file['mean_R'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.261975\n",
       "std        0.275493\n",
       "min        0.000000\n",
       "25%        0.041659\n",
       "50%        0.125321\n",
       "75%        0.506075\n",
       "max        1.000000\n",
       "Name: mean_R, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['mean_R'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean      51.996351\n",
       "std       14.095391\n",
       "min       13.611756\n",
       "25%       43.921763\n",
       "50%       51.867219\n",
       "75%       61.865402\n",
       "max       92.524352\n",
       "Name: std_B, dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['std_B'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file['std_B'] = (my_file['std_B'] - my_file['std_B'].min())/(my_file['std_B'].max() - my_file['std_B'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.486419\n",
       "std        0.178620\n",
       "min        0.000000\n",
       "25%        0.384096\n",
       "50%        0.484783\n",
       "75%        0.611482\n",
       "max        1.000000\n",
       "Name: std_B, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['std_B'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean      72.999904\n",
       "std       15.286676\n",
       "min       30.477614\n",
       "25%       63.136441\n",
       "50%       73.541901\n",
       "75%       84.413857\n",
       "max      117.730371\n",
       "Name: std_G, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['std_G'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file['std_G'] = (my_file['std_G'] - my_file['std_G'].min())/(my_file['std_G'].max() - my_file['std_G'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.487346\n",
       "std        0.175200\n",
       "min        0.000000\n",
       "25%        0.374301\n",
       "50%        0.493558\n",
       "75%        0.618161\n",
       "max        1.000000\n",
       "Name: std_G, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['std_G'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean      41.956997\n",
       "std       22.791601\n",
       "min        5.189059\n",
       "25%       21.951760\n",
       "50%       39.402918\n",
       "75%       60.352599\n",
       "max       99.574606\n",
       "Name: std_R, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['std_R'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file['std_R'] = (my_file['std_R'] - my_file['std_R'].min())/(my_file['std_R'].max() - my_file['std_R'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean       0.389551\n",
       "std        0.241473\n",
       "min        0.000000\n",
       "25%        0.177598\n",
       "50%        0.362490\n",
       "75%        0.584449\n",
       "max        1.000000\n",
       "Name: std_R, dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['std_R'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      202.000000\n",
       "mean        69.366337\n",
       "std        839.146288\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          2.000000\n",
       "75%          6.000000\n",
       "max      11927.000000\n",
       "Name: area, dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['area'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file = my_file.drop('area', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    202.000000\n",
       "mean      15.348125\n",
       "std       62.464979\n",
       "min        0.000000\n",
       "25%        3.560660\n",
       "50%        5.656854\n",
       "75%       11.071068\n",
       "max      851.033612\n",
       "Name: perimeter, dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file['perimeter'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file['perimeter'] = my_file['perimeter'].map({0.000000: my_file['perimeter'].mean()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file = my_file.drop('perimeter', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy</th>\n",
       "      <th>contrast</th>\n",
       "      <th>variance</th>\n",
       "      <th>inverse difference moment</th>\n",
       "      <th>sum average</th>\n",
       "      <th>sum variance</th>\n",
       "      <th>sum entropy</th>\n",
       "      <th>entropy</th>\n",
       "      <th>difference variance</th>\n",
       "      <th>difference entropy</th>\n",
       "      <th>mean_B</th>\n",
       "      <th>mean_G</th>\n",
       "      <th>mean_R</th>\n",
       "      <th>std_B</th>\n",
       "      <th>std_G</th>\n",
       "      <th>std_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.169224</td>\n",
       "      <td>0.289995</td>\n",
       "      <td>0.503613</td>\n",
       "      <td>0.328835</td>\n",
       "      <td>0.554133</td>\n",
       "      <td>0.503203</td>\n",
       "      <td>0.699561</td>\n",
       "      <td>0.680072</td>\n",
       "      <td>0.143376</td>\n",
       "      <td>0.709940</td>\n",
       "      <td>0.313805</td>\n",
       "      <td>0.528787</td>\n",
       "      <td>0.614273</td>\n",
       "      <td>0.304604</td>\n",
       "      <td>0.615009</td>\n",
       "      <td>0.737568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.816743</td>\n",
       "      <td>0.101235</td>\n",
       "      <td>0.222058</td>\n",
       "      <td>0.910721</td>\n",
       "      <td>0.092361</td>\n",
       "      <td>0.222110</td>\n",
       "      <td>0.142707</td>\n",
       "      <td>0.124576</td>\n",
       "      <td>0.695182</td>\n",
       "      <td>0.139885</td>\n",
       "      <td>0.220593</td>\n",
       "      <td>0.101461</td>\n",
       "      <td>0.053140</td>\n",
       "      <td>0.559716</td>\n",
       "      <td>0.442374</td>\n",
       "      <td>0.309818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.616307</td>\n",
       "      <td>0.174905</td>\n",
       "      <td>0.229516</td>\n",
       "      <td>0.791696</td>\n",
       "      <td>0.149270</td>\n",
       "      <td>0.229158</td>\n",
       "      <td>0.305093</td>\n",
       "      <td>0.272178</td>\n",
       "      <td>0.536824</td>\n",
       "      <td>0.286056</td>\n",
       "      <td>0.298854</td>\n",
       "      <td>0.167377</td>\n",
       "      <td>0.074775</td>\n",
       "      <td>0.539028</td>\n",
       "      <td>0.447906</td>\n",
       "      <td>0.289288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016687</td>\n",
       "      <td>0.680178</td>\n",
       "      <td>0.343683</td>\n",
       "      <td>0.133705</td>\n",
       "      <td>0.830096</td>\n",
       "      <td>0.340649</td>\n",
       "      <td>0.935801</td>\n",
       "      <td>0.905857</td>\n",
       "      <td>0.046132</td>\n",
       "      <td>0.817664</td>\n",
       "      <td>0.265694</td>\n",
       "      <td>0.874486</td>\n",
       "      <td>0.759549</td>\n",
       "      <td>0.398753</td>\n",
       "      <td>0.512621</td>\n",
       "      <td>0.594145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.144739</td>\n",
       "      <td>0.238395</td>\n",
       "      <td>0.059277</td>\n",
       "      <td>0.370087</td>\n",
       "      <td>0.252131</td>\n",
       "      <td>0.058167</td>\n",
       "      <td>0.673827</td>\n",
       "      <td>0.645537</td>\n",
       "      <td>0.162975</td>\n",
       "      <td>0.641177</td>\n",
       "      <td>0.170598</td>\n",
       "      <td>0.232265</td>\n",
       "      <td>0.307716</td>\n",
       "      <td>0.091011</td>\n",
       "      <td>0.135052</td>\n",
       "      <td>0.348236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.753275</td>\n",
       "      <td>0.026219</td>\n",
       "      <td>0.175914</td>\n",
       "      <td>0.855644</td>\n",
       "      <td>0.100871</td>\n",
       "      <td>0.176298</td>\n",
       "      <td>0.196664</td>\n",
       "      <td>0.177152</td>\n",
       "      <td>0.647691</td>\n",
       "      <td>0.198023</td>\n",
       "      <td>0.176512</td>\n",
       "      <td>0.076325</td>\n",
       "      <td>0.152918</td>\n",
       "      <td>0.394871</td>\n",
       "      <td>0.249911</td>\n",
       "      <td>0.468215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.086338</td>\n",
       "      <td>0.109834</td>\n",
       "      <td>0.002533</td>\n",
       "      <td>0.441833</td>\n",
       "      <td>0.208530</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>0.711789</td>\n",
       "      <td>0.647242</td>\n",
       "      <td>0.255335</td>\n",
       "      <td>0.552105</td>\n",
       "      <td>0.231839</td>\n",
       "      <td>0.171394</td>\n",
       "      <td>0.286421</td>\n",
       "      <td>0.087317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.297518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.719489</td>\n",
       "      <td>0.019917</td>\n",
       "      <td>0.177375</td>\n",
       "      <td>0.837457</td>\n",
       "      <td>0.111338</td>\n",
       "      <td>0.177799</td>\n",
       "      <td>0.220557</td>\n",
       "      <td>0.198897</td>\n",
       "      <td>0.622483</td>\n",
       "      <td>0.220909</td>\n",
       "      <td>0.225201</td>\n",
       "      <td>0.090681</td>\n",
       "      <td>0.143445</td>\n",
       "      <td>0.463693</td>\n",
       "      <td>0.267135</td>\n",
       "      <td>0.421028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.979866</td>\n",
       "      <td>0.065778</td>\n",
       "      <td>0.013180</td>\n",
       "      <td>0.994070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012969</td>\n",
       "      <td>0.010677</td>\n",
       "      <td>0.008506</td>\n",
       "      <td>0.847751</td>\n",
       "      <td>0.011066</td>\n",
       "      <td>0.058835</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>0.260821</td>\n",
       "      <td>0.170652</td>\n",
       "      <td>0.017506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.796203</td>\n",
       "      <td>0.177308</td>\n",
       "      <td>0.180361</td>\n",
       "      <td>0.910296</td>\n",
       "      <td>0.088612</td>\n",
       "      <td>0.179878</td>\n",
       "      <td>0.156350</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>0.687980</td>\n",
       "      <td>0.131606</td>\n",
       "      <td>0.225653</td>\n",
       "      <td>0.099282</td>\n",
       "      <td>0.044162</td>\n",
       "      <td>0.561475</td>\n",
       "      <td>0.415473</td>\n",
       "      <td>0.177397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.180932</td>\n",
       "      <td>0.239203</td>\n",
       "      <td>0.281093</td>\n",
       "      <td>0.476267</td>\n",
       "      <td>0.414113</td>\n",
       "      <td>0.280477</td>\n",
       "      <td>0.663436</td>\n",
       "      <td>0.601878</td>\n",
       "      <td>0.247823</td>\n",
       "      <td>0.536012</td>\n",
       "      <td>0.124879</td>\n",
       "      <td>0.416336</td>\n",
       "      <td>0.442787</td>\n",
       "      <td>0.188226</td>\n",
       "      <td>0.449327</td>\n",
       "      <td>0.545056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.746699</td>\n",
       "      <td>0.221874</td>\n",
       "      <td>0.172101</td>\n",
       "      <td>0.884964</td>\n",
       "      <td>0.104835</td>\n",
       "      <td>0.171341</td>\n",
       "      <td>0.186406</td>\n",
       "      <td>0.160340</td>\n",
       "      <td>0.650283</td>\n",
       "      <td>0.165443</td>\n",
       "      <td>0.211575</td>\n",
       "      <td>0.128075</td>\n",
       "      <td>0.035218</td>\n",
       "      <td>0.444714</td>\n",
       "      <td>0.439441</td>\n",
       "      <td>0.162066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.708238</td>\n",
       "      <td>0.039289</td>\n",
       "      <td>0.192864</td>\n",
       "      <td>0.832247</td>\n",
       "      <td>0.120533</td>\n",
       "      <td>0.193210</td>\n",
       "      <td>0.226917</td>\n",
       "      <td>0.204334</td>\n",
       "      <td>0.613916</td>\n",
       "      <td>0.227441</td>\n",
       "      <td>0.196033</td>\n",
       "      <td>0.095771</td>\n",
       "      <td>0.170095</td>\n",
       "      <td>0.400597</td>\n",
       "      <td>0.273870</td>\n",
       "      <td>0.480086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.759275</td>\n",
       "      <td>0.117672</td>\n",
       "      <td>0.348243</td>\n",
       "      <td>0.859624</td>\n",
       "      <td>0.151281</td>\n",
       "      <td>0.348484</td>\n",
       "      <td>0.186493</td>\n",
       "      <td>0.168041</td>\n",
       "      <td>0.682123</td>\n",
       "      <td>0.198418</td>\n",
       "      <td>0.239835</td>\n",
       "      <td>0.152197</td>\n",
       "      <td>0.131952</td>\n",
       "      <td>0.500756</td>\n",
       "      <td>0.535543</td>\n",
       "      <td>0.451087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.734341</td>\n",
       "      <td>0.212244</td>\n",
       "      <td>0.184847</td>\n",
       "      <td>0.876952</td>\n",
       "      <td>0.112303</td>\n",
       "      <td>0.184171</td>\n",
       "      <td>0.197792</td>\n",
       "      <td>0.170491</td>\n",
       "      <td>0.645881</td>\n",
       "      <td>0.175686</td>\n",
       "      <td>0.223086</td>\n",
       "      <td>0.136636</td>\n",
       "      <td>0.037988</td>\n",
       "      <td>0.459744</td>\n",
       "      <td>0.455840</td>\n",
       "      <td>0.174449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.032162</td>\n",
       "      <td>0.644137</td>\n",
       "      <td>0.395792</td>\n",
       "      <td>0.149959</td>\n",
       "      <td>0.784006</td>\n",
       "      <td>0.393083</td>\n",
       "      <td>0.905366</td>\n",
       "      <td>0.885406</td>\n",
       "      <td>0.045673</td>\n",
       "      <td>0.838216</td>\n",
       "      <td>0.267264</td>\n",
       "      <td>0.825950</td>\n",
       "      <td>0.716113</td>\n",
       "      <td>0.410896</td>\n",
       "      <td>0.566080</td>\n",
       "      <td>0.619856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.929437</td>\n",
       "      <td>0.030788</td>\n",
       "      <td>0.039176</td>\n",
       "      <td>0.961233</td>\n",
       "      <td>0.011858</td>\n",
       "      <td>0.039227</td>\n",
       "      <td>0.054511</td>\n",
       "      <td>0.049274</td>\n",
       "      <td>0.782016</td>\n",
       "      <td>0.066333</td>\n",
       "      <td>0.081997</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.026549</td>\n",
       "      <td>0.312601</td>\n",
       "      <td>0.146925</td>\n",
       "      <td>0.165443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.309006</td>\n",
       "      <td>0.181983</td>\n",
       "      <td>0.588884</td>\n",
       "      <td>0.500712</td>\n",
       "      <td>0.470738</td>\n",
       "      <td>0.589292</td>\n",
       "      <td>0.534461</td>\n",
       "      <td>0.512072</td>\n",
       "      <td>0.282558</td>\n",
       "      <td>0.563096</td>\n",
       "      <td>0.413763</td>\n",
       "      <td>0.430469</td>\n",
       "      <td>0.534928</td>\n",
       "      <td>0.399168</td>\n",
       "      <td>0.659911</td>\n",
       "      <td>0.783451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.776195</td>\n",
       "      <td>0.025340</td>\n",
       "      <td>0.168686</td>\n",
       "      <td>0.868081</td>\n",
       "      <td>0.093564</td>\n",
       "      <td>0.169059</td>\n",
       "      <td>0.178687</td>\n",
       "      <td>0.161216</td>\n",
       "      <td>0.662719</td>\n",
       "      <td>0.182666</td>\n",
       "      <td>0.167726</td>\n",
       "      <td>0.069320</td>\n",
       "      <td>0.146390</td>\n",
       "      <td>0.389611</td>\n",
       "      <td>0.240168</td>\n",
       "      <td>0.463173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.910705</td>\n",
       "      <td>0.047852</td>\n",
       "      <td>0.143099</td>\n",
       "      <td>0.963078</td>\n",
       "      <td>0.052286</td>\n",
       "      <td>0.143284</td>\n",
       "      <td>0.064152</td>\n",
       "      <td>0.054446</td>\n",
       "      <td>0.771295</td>\n",
       "      <td>0.061737</td>\n",
       "      <td>0.169317</td>\n",
       "      <td>0.058562</td>\n",
       "      <td>0.028645</td>\n",
       "      <td>0.516078</td>\n",
       "      <td>0.360929</td>\n",
       "      <td>0.163771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005193</td>\n",
       "      <td>0.024192</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.024357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.868280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011742</td>\n",
       "      <td>0.313507</td>\n",
       "      <td>0.153461</td>\n",
       "      <td>0.076231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.638123</td>\n",
       "      <td>0.147780</td>\n",
       "      <td>0.304033</td>\n",
       "      <td>0.879514</td>\n",
       "      <td>0.184535</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.270962</td>\n",
       "      <td>0.214235</td>\n",
       "      <td>0.748563</td>\n",
       "      <td>0.149985</td>\n",
       "      <td>0.398479</td>\n",
       "      <td>0.210074</td>\n",
       "      <td>0.071560</td>\n",
       "      <td>0.682240</td>\n",
       "      <td>0.573719</td>\n",
       "      <td>0.182825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.265679</td>\n",
       "      <td>0.155492</td>\n",
       "      <td>0.768694</td>\n",
       "      <td>0.525848</td>\n",
       "      <td>0.570201</td>\n",
       "      <td>0.769660</td>\n",
       "      <td>0.598892</td>\n",
       "      <td>0.547214</td>\n",
       "      <td>0.264344</td>\n",
       "      <td>0.526277</td>\n",
       "      <td>0.652788</td>\n",
       "      <td>0.494717</td>\n",
       "      <td>0.669729</td>\n",
       "      <td>0.627026</td>\n",
       "      <td>0.731178</td>\n",
       "      <td>0.923630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.701493</td>\n",
       "      <td>0.035783</td>\n",
       "      <td>0.271819</td>\n",
       "      <td>0.870198</td>\n",
       "      <td>0.136969</td>\n",
       "      <td>0.272363</td>\n",
       "      <td>0.232108</td>\n",
       "      <td>0.194935</td>\n",
       "      <td>0.624206</td>\n",
       "      <td>0.182920</td>\n",
       "      <td>0.301243</td>\n",
       "      <td>0.143018</td>\n",
       "      <td>0.089608</td>\n",
       "      <td>0.613827</td>\n",
       "      <td>0.458148</td>\n",
       "      <td>0.387999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.037521</td>\n",
       "      <td>0.410973</td>\n",
       "      <td>0.183254</td>\n",
       "      <td>0.121111</td>\n",
       "      <td>0.565109</td>\n",
       "      <td>0.181421</td>\n",
       "      <td>0.861132</td>\n",
       "      <td>0.854264</td>\n",
       "      <td>0.037339</td>\n",
       "      <td>0.834893</td>\n",
       "      <td>0.149505</td>\n",
       "      <td>0.581961</td>\n",
       "      <td>0.565702</td>\n",
       "      <td>0.134371</td>\n",
       "      <td>0.340063</td>\n",
       "      <td>0.452158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.034828</td>\n",
       "      <td>0.858426</td>\n",
       "      <td>0.423979</td>\n",
       "      <td>0.112276</td>\n",
       "      <td>0.827759</td>\n",
       "      <td>0.420090</td>\n",
       "      <td>0.891780</td>\n",
       "      <td>0.897603</td>\n",
       "      <td>0.029799</td>\n",
       "      <td>0.899544</td>\n",
       "      <td>0.316002</td>\n",
       "      <td>0.875428</td>\n",
       "      <td>0.738687</td>\n",
       "      <td>0.418568</td>\n",
       "      <td>0.599603</td>\n",
       "      <td>0.630198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.475351</td>\n",
       "      <td>0.113515</td>\n",
       "      <td>0.343857</td>\n",
       "      <td>0.629219</td>\n",
       "      <td>0.271461</td>\n",
       "      <td>0.344112</td>\n",
       "      <td>0.381336</td>\n",
       "      <td>0.372120</td>\n",
       "      <td>0.469400</td>\n",
       "      <td>0.457843</td>\n",
       "      <td>0.414242</td>\n",
       "      <td>0.259100</td>\n",
       "      <td>0.252296</td>\n",
       "      <td>0.540759</td>\n",
       "      <td>0.500993</td>\n",
       "      <td>0.459192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.582977</td>\n",
       "      <td>0.247465</td>\n",
       "      <td>0.263660</td>\n",
       "      <td>0.823804</td>\n",
       "      <td>0.173158</td>\n",
       "      <td>0.262957</td>\n",
       "      <td>0.323813</td>\n",
       "      <td>0.270001</td>\n",
       "      <td>0.550242</td>\n",
       "      <td>0.233951</td>\n",
       "      <td>0.389343</td>\n",
       "      <td>0.207296</td>\n",
       "      <td>0.041097</td>\n",
       "      <td>0.677191</td>\n",
       "      <td>0.551749</td>\n",
       "      <td>0.188445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.052330</td>\n",
       "      <td>0.463148</td>\n",
       "      <td>0.603172</td>\n",
       "      <td>0.239494</td>\n",
       "      <td>0.865652</td>\n",
       "      <td>0.601981</td>\n",
       "      <td>0.887251</td>\n",
       "      <td>0.830420</td>\n",
       "      <td>0.083958</td>\n",
       "      <td>0.725498</td>\n",
       "      <td>0.742508</td>\n",
       "      <td>0.841126</td>\n",
       "      <td>0.848570</td>\n",
       "      <td>0.533037</td>\n",
       "      <td>0.695461</td>\n",
       "      <td>0.743058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.079862</td>\n",
       "      <td>0.585364</td>\n",
       "      <td>0.747049</td>\n",
       "      <td>0.282110</td>\n",
       "      <td>0.781438</td>\n",
       "      <td>0.745472</td>\n",
       "      <td>0.830760</td>\n",
       "      <td>0.789128</td>\n",
       "      <td>0.099432</td>\n",
       "      <td>0.764286</td>\n",
       "      <td>0.632374</td>\n",
       "      <td>0.770294</td>\n",
       "      <td>0.750642</td>\n",
       "      <td>0.844418</td>\n",
       "      <td>0.764848</td>\n",
       "      <td>0.864680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.673622</td>\n",
       "      <td>0.236813</td>\n",
       "      <td>0.206139</td>\n",
       "      <td>0.811437</td>\n",
       "      <td>0.139913</td>\n",
       "      <td>0.205368</td>\n",
       "      <td>0.233830</td>\n",
       "      <td>0.216615</td>\n",
       "      <td>0.573074</td>\n",
       "      <td>0.271532</td>\n",
       "      <td>0.141284</td>\n",
       "      <td>0.169710</td>\n",
       "      <td>0.074488</td>\n",
       "      <td>0.268916</td>\n",
       "      <td>0.480453</td>\n",
       "      <td>0.260380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.880415</td>\n",
       "      <td>0.051604</td>\n",
       "      <td>0.117267</td>\n",
       "      <td>0.942785</td>\n",
       "      <td>0.054652</td>\n",
       "      <td>0.117372</td>\n",
       "      <td>0.087996</td>\n",
       "      <td>0.076518</td>\n",
       "      <td>0.742533</td>\n",
       "      <td>0.085906</td>\n",
       "      <td>0.148910</td>\n",
       "      <td>0.057173</td>\n",
       "      <td>0.045037</td>\n",
       "      <td>0.411167</td>\n",
       "      <td>0.300986</td>\n",
       "      <td>0.174222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.801684</td>\n",
       "      <td>0.024262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.915328</td>\n",
       "      <td>0.026728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132504</td>\n",
       "      <td>0.113929</td>\n",
       "      <td>0.760796</td>\n",
       "      <td>0.122401</td>\n",
       "      <td>0.086998</td>\n",
       "      <td>0.039078</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.192364</td>\n",
       "      <td>0.138401</td>\n",
       "      <td>0.026030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.811920</td>\n",
       "      <td>0.410706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.901127</td>\n",
       "      <td>0.407058</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.970119</td>\n",
       "      <td>0.728078</td>\n",
       "      <td>0.891336</td>\n",
       "      <td>0.855435</td>\n",
       "      <td>0.772312</td>\n",
       "      <td>0.459785</td>\n",
       "      <td>0.682910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.843534</td>\n",
       "      <td>0.069507</td>\n",
       "      <td>0.259898</td>\n",
       "      <td>0.921249</td>\n",
       "      <td>0.099657</td>\n",
       "      <td>0.260220</td>\n",
       "      <td>0.122099</td>\n",
       "      <td>0.107735</td>\n",
       "      <td>0.710995</td>\n",
       "      <td>0.124364</td>\n",
       "      <td>0.240255</td>\n",
       "      <td>0.108289</td>\n",
       "      <td>0.057490</td>\n",
       "      <td>0.613340</td>\n",
       "      <td>0.486935</td>\n",
       "      <td>0.315547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.140590</td>\n",
       "      <td>0.316887</td>\n",
       "      <td>0.334944</td>\n",
       "      <td>0.444251</td>\n",
       "      <td>0.499718</td>\n",
       "      <td>0.333999</td>\n",
       "      <td>0.712943</td>\n",
       "      <td>0.642178</td>\n",
       "      <td>0.214201</td>\n",
       "      <td>0.548127</td>\n",
       "      <td>0.127916</td>\n",
       "      <td>0.502639</td>\n",
       "      <td>0.532559</td>\n",
       "      <td>0.197047</td>\n",
       "      <td>0.506081</td>\n",
       "      <td>0.593324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.032007</td>\n",
       "      <td>0.147267</td>\n",
       "      <td>0.970536</td>\n",
       "      <td>0.051183</td>\n",
       "      <td>0.147553</td>\n",
       "      <td>0.064473</td>\n",
       "      <td>0.052746</td>\n",
       "      <td>0.782980</td>\n",
       "      <td>0.050377</td>\n",
       "      <td>0.165452</td>\n",
       "      <td>0.060708</td>\n",
       "      <td>0.020644</td>\n",
       "      <td>0.521208</td>\n",
       "      <td>0.386048</td>\n",
       "      <td>0.144966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.848981</td>\n",
       "      <td>0.071954</td>\n",
       "      <td>0.172494</td>\n",
       "      <td>0.923166</td>\n",
       "      <td>0.078513</td>\n",
       "      <td>0.172605</td>\n",
       "      <td>0.111210</td>\n",
       "      <td>0.097702</td>\n",
       "      <td>0.719215</td>\n",
       "      <td>0.113572</td>\n",
       "      <td>0.198191</td>\n",
       "      <td>0.069739</td>\n",
       "      <td>0.085985</td>\n",
       "      <td>0.495080</td>\n",
       "      <td>0.312069</td>\n",
       "      <td>0.325535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.954383</td>\n",
       "      <td>0.054051</td>\n",
       "      <td>0.066594</td>\n",
       "      <td>0.986426</td>\n",
       "      <td>0.021105</td>\n",
       "      <td>0.066571</td>\n",
       "      <td>0.033350</td>\n",
       "      <td>0.026036</td>\n",
       "      <td>0.817499</td>\n",
       "      <td>0.023627</td>\n",
       "      <td>0.112506</td>\n",
       "      <td>0.026828</td>\n",
       "      <td>0.009726</td>\n",
       "      <td>0.414651</td>\n",
       "      <td>0.261029</td>\n",
       "      <td>0.081890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.587120</td>\n",
       "      <td>0.191977</td>\n",
       "      <td>0.251218</td>\n",
       "      <td>0.780205</td>\n",
       "      <td>0.180097</td>\n",
       "      <td>0.250809</td>\n",
       "      <td>0.302527</td>\n",
       "      <td>0.269404</td>\n",
       "      <td>0.525626</td>\n",
       "      <td>0.294182</td>\n",
       "      <td>0.265157</td>\n",
       "      <td>0.199069</td>\n",
       "      <td>0.114448</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.470486</td>\n",
       "      <td>0.359641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.217640</td>\n",
       "      <td>0.240444</td>\n",
       "      <td>0.485385</td>\n",
       "      <td>0.472427</td>\n",
       "      <td>0.491405</td>\n",
       "      <td>0.485222</td>\n",
       "      <td>0.656693</td>\n",
       "      <td>0.601077</td>\n",
       "      <td>0.216915</td>\n",
       "      <td>0.567732</td>\n",
       "      <td>0.249824</td>\n",
       "      <td>0.529215</td>\n",
       "      <td>0.411167</td>\n",
       "      <td>0.356654</td>\n",
       "      <td>0.709945</td>\n",
       "      <td>0.542708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.260285</td>\n",
       "      <td>0.006904</td>\n",
       "      <td>0.391357</td>\n",
       "      <td>0.582404</td>\n",
       "      <td>0.386956</td>\n",
       "      <td>0.392338</td>\n",
       "      <td>0.630229</td>\n",
       "      <td>0.550682</td>\n",
       "      <td>0.364547</td>\n",
       "      <td>0.446804</td>\n",
       "      <td>0.422132</td>\n",
       "      <td>0.344042</td>\n",
       "      <td>0.448278</td>\n",
       "      <td>0.419722</td>\n",
       "      <td>0.473452</td>\n",
       "      <td>0.672721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.171980</td>\n",
       "      <td>0.197873</td>\n",
       "      <td>0.387828</td>\n",
       "      <td>0.340331</td>\n",
       "      <td>0.477394</td>\n",
       "      <td>0.387692</td>\n",
       "      <td>0.694496</td>\n",
       "      <td>0.672813</td>\n",
       "      <td>0.159429</td>\n",
       "      <td>0.697615</td>\n",
       "      <td>0.929689</td>\n",
       "      <td>0.522162</td>\n",
       "      <td>0.216727</td>\n",
       "      <td>0.777439</td>\n",
       "      <td>0.618846</td>\n",
       "      <td>0.340381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.896178</td>\n",
       "      <td>0.063057</td>\n",
       "      <td>0.135481</td>\n",
       "      <td>0.969489</td>\n",
       "      <td>0.052887</td>\n",
       "      <td>0.135560</td>\n",
       "      <td>0.076344</td>\n",
       "      <td>0.059401</td>\n",
       "      <td>0.869805</td>\n",
       "      <td>0.047101</td>\n",
       "      <td>0.147634</td>\n",
       "      <td>0.064569</td>\n",
       "      <td>0.021641</td>\n",
       "      <td>0.444405</td>\n",
       "      <td>0.372508</td>\n",
       "      <td>0.142865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.293539</td>\n",
       "      <td>0.250586</td>\n",
       "      <td>0.745285</td>\n",
       "      <td>0.589536</td>\n",
       "      <td>0.498973</td>\n",
       "      <td>0.745647</td>\n",
       "      <td>0.599466</td>\n",
       "      <td>0.531970</td>\n",
       "      <td>0.305995</td>\n",
       "      <td>0.482356</td>\n",
       "      <td>0.257551</td>\n",
       "      <td>0.484984</td>\n",
       "      <td>0.541190</td>\n",
       "      <td>0.579617</td>\n",
       "      <td>0.803037</td>\n",
       "      <td>0.856679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.031995</td>\n",
       "      <td>0.874942</td>\n",
       "      <td>0.399836</td>\n",
       "      <td>0.139135</td>\n",
       "      <td>0.804057</td>\n",
       "      <td>0.395797</td>\n",
       "      <td>0.906055</td>\n",
       "      <td>0.891244</td>\n",
       "      <td>0.041939</td>\n",
       "      <td>0.852812</td>\n",
       "      <td>0.290984</td>\n",
       "      <td>0.847244</td>\n",
       "      <td>0.730920</td>\n",
       "      <td>0.426295</td>\n",
       "      <td>0.570417</td>\n",
       "      <td>0.621260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.899593</td>\n",
       "      <td>0.053779</td>\n",
       "      <td>0.158514</td>\n",
       "      <td>0.937548</td>\n",
       "      <td>0.058574</td>\n",
       "      <td>0.158699</td>\n",
       "      <td>0.082211</td>\n",
       "      <td>0.075743</td>\n",
       "      <td>0.747268</td>\n",
       "      <td>0.098770</td>\n",
       "      <td>0.142637</td>\n",
       "      <td>0.054676</td>\n",
       "      <td>0.066041</td>\n",
       "      <td>0.420517</td>\n",
       "      <td>0.324368</td>\n",
       "      <td>0.275003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.758134</td>\n",
       "      <td>0.109442</td>\n",
       "      <td>0.189716</td>\n",
       "      <td>0.897108</td>\n",
       "      <td>0.109560</td>\n",
       "      <td>0.189649</td>\n",
       "      <td>0.172731</td>\n",
       "      <td>0.147778</td>\n",
       "      <td>0.661098</td>\n",
       "      <td>0.153561</td>\n",
       "      <td>0.233146</td>\n",
       "      <td>0.117561</td>\n",
       "      <td>0.071364</td>\n",
       "      <td>0.483006</td>\n",
       "      <td>0.396386</td>\n",
       "      <td>0.262710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.163818</td>\n",
       "      <td>0.135848</td>\n",
       "      <td>0.718995</td>\n",
       "      <td>0.542462</td>\n",
       "      <td>0.671649</td>\n",
       "      <td>0.719964</td>\n",
       "      <td>0.716340</td>\n",
       "      <td>0.624908</td>\n",
       "      <td>0.261304</td>\n",
       "      <td>0.490682</td>\n",
       "      <td>0.860006</td>\n",
       "      <td>0.623702</td>\n",
       "      <td>0.665884</td>\n",
       "      <td>0.776326</td>\n",
       "      <td>0.741387</td>\n",
       "      <td>0.779577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.038905</td>\n",
       "      <td>0.586514</td>\n",
       "      <td>0.503882</td>\n",
       "      <td>0.164647</td>\n",
       "      <td>0.816463</td>\n",
       "      <td>0.501751</td>\n",
       "      <td>0.919728</td>\n",
       "      <td>0.880194</td>\n",
       "      <td>0.051927</td>\n",
       "      <td>0.808667</td>\n",
       "      <td>0.311832</td>\n",
       "      <td>0.825653</td>\n",
       "      <td>0.818722</td>\n",
       "      <td>0.493654</td>\n",
       "      <td>0.626898</td>\n",
       "      <td>0.716824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.920701</td>\n",
       "      <td>0.040314</td>\n",
       "      <td>0.092649</td>\n",
       "      <td>0.970882</td>\n",
       "      <td>0.035811</td>\n",
       "      <td>0.092764</td>\n",
       "      <td>0.055561</td>\n",
       "      <td>0.046131</td>\n",
       "      <td>0.782385</td>\n",
       "      <td>0.050987</td>\n",
       "      <td>0.139915</td>\n",
       "      <td>0.044773</td>\n",
       "      <td>0.011418</td>\n",
       "      <td>0.448850</td>\n",
       "      <td>0.308036</td>\n",
       "      <td>0.097947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.726078</td>\n",
       "      <td>0.115909</td>\n",
       "      <td>0.300091</td>\n",
       "      <td>0.884202</td>\n",
       "      <td>0.149577</td>\n",
       "      <td>0.300234</td>\n",
       "      <td>0.202148</td>\n",
       "      <td>0.172830</td>\n",
       "      <td>0.649604</td>\n",
       "      <td>0.174849</td>\n",
       "      <td>0.322473</td>\n",
       "      <td>0.177353</td>\n",
       "      <td>0.046490</td>\n",
       "      <td>0.668801</td>\n",
       "      <td>0.601540</td>\n",
       "      <td>0.225496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.807777</td>\n",
       "      <td>0.116304</td>\n",
       "      <td>0.218959</td>\n",
       "      <td>0.917608</td>\n",
       "      <td>0.099300</td>\n",
       "      <td>0.218917</td>\n",
       "      <td>0.146716</td>\n",
       "      <td>0.124237</td>\n",
       "      <td>0.703470</td>\n",
       "      <td>0.126164</td>\n",
       "      <td>0.241203</td>\n",
       "      <td>0.119873</td>\n",
       "      <td>0.028485</td>\n",
       "      <td>0.595669</td>\n",
       "      <td>0.503300</td>\n",
       "      <td>0.167518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.749143</td>\n",
       "      <td>0.094078</td>\n",
       "      <td>0.381677</td>\n",
       "      <td>0.889109</td>\n",
       "      <td>0.162363</td>\n",
       "      <td>0.382130</td>\n",
       "      <td>0.186939</td>\n",
       "      <td>0.160144</td>\n",
       "      <td>0.671443</td>\n",
       "      <td>0.160701</td>\n",
       "      <td>0.230659</td>\n",
       "      <td>0.140920</td>\n",
       "      <td>0.199346</td>\n",
       "      <td>0.511220</td>\n",
       "      <td>0.489412</td>\n",
       "      <td>0.576189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.159620</td>\n",
       "      <td>0.318122</td>\n",
       "      <td>0.700541</td>\n",
       "      <td>0.396494</td>\n",
       "      <td>0.681425</td>\n",
       "      <td>0.700410</td>\n",
       "      <td>0.716595</td>\n",
       "      <td>0.662927</td>\n",
       "      <td>0.179710</td>\n",
       "      <td>0.615511</td>\n",
       "      <td>0.617823</td>\n",
       "      <td>0.688062</td>\n",
       "      <td>0.603715</td>\n",
       "      <td>0.690891</td>\n",
       "      <td>0.809813</td>\n",
       "      <td>0.692345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.026085</td>\n",
       "      <td>0.312549</td>\n",
       "      <td>0.024595</td>\n",
       "      <td>0.414045</td>\n",
       "      <td>0.321003</td>\n",
       "      <td>0.022976</td>\n",
       "      <td>0.828106</td>\n",
       "      <td>0.741574</td>\n",
       "      <td>0.183148</td>\n",
       "      <td>0.573303</td>\n",
       "      <td>0.382859</td>\n",
       "      <td>0.265135</td>\n",
       "      <td>0.416812</td>\n",
       "      <td>0.173793</td>\n",
       "      <td>0.031885</td>\n",
       "      <td>0.333213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.119864</td>\n",
       "      <td>0.390216</td>\n",
       "      <td>0.525686</td>\n",
       "      <td>0.407587</td>\n",
       "      <td>0.664672</td>\n",
       "      <td>0.524744</td>\n",
       "      <td>0.749218</td>\n",
       "      <td>0.676693</td>\n",
       "      <td>0.205149</td>\n",
       "      <td>0.566305</td>\n",
       "      <td>0.618787</td>\n",
       "      <td>0.681682</td>\n",
       "      <td>0.561207</td>\n",
       "      <td>0.671038</td>\n",
       "      <td>0.686257</td>\n",
       "      <td>0.585089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.267379</td>\n",
       "      <td>0.604305</td>\n",
       "      <td>0.411300</td>\n",
       "      <td>0.448197</td>\n",
       "      <td>0.412848</td>\n",
       "      <td>0.408858</td>\n",
       "      <td>0.563737</td>\n",
       "      <td>0.556675</td>\n",
       "      <td>0.214612</td>\n",
       "      <td>0.661302</td>\n",
       "      <td>0.244477</td>\n",
       "      <td>0.476542</td>\n",
       "      <td>0.266252</td>\n",
       "      <td>0.389821</td>\n",
       "      <td>0.677589</td>\n",
       "      <td>0.456193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.893015</td>\n",
       "      <td>0.105256</td>\n",
       "      <td>0.098113</td>\n",
       "      <td>0.957846</td>\n",
       "      <td>0.040973</td>\n",
       "      <td>0.097863</td>\n",
       "      <td>0.077010</td>\n",
       "      <td>0.063731</td>\n",
       "      <td>0.853903</td>\n",
       "      <td>0.068592</td>\n",
       "      <td>0.145840</td>\n",
       "      <td>0.054063</td>\n",
       "      <td>0.005795</td>\n",
       "      <td>0.464688</td>\n",
       "      <td>0.339510</td>\n",
       "      <td>0.040803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.727275</td>\n",
       "      <td>0.164323</td>\n",
       "      <td>0.273176</td>\n",
       "      <td>0.869686</td>\n",
       "      <td>0.143265</td>\n",
       "      <td>0.272977</td>\n",
       "      <td>0.204996</td>\n",
       "      <td>0.177072</td>\n",
       "      <td>0.746733</td>\n",
       "      <td>0.177171</td>\n",
       "      <td>0.218874</td>\n",
       "      <td>0.148886</td>\n",
       "      <td>0.117074</td>\n",
       "      <td>0.421086</td>\n",
       "      <td>0.477927</td>\n",
       "      <td>0.403525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       energy  contrast  variance  inverse difference moment  sum average  \\\n",
       "0    0.169224  0.289995  0.503613                   0.328835     0.554133   \n",
       "1    0.816743  0.101235  0.222058                   0.910721     0.092361   \n",
       "2    0.616307  0.174905  0.229516                   0.791696     0.149270   \n",
       "3    0.016687  0.680178  0.343683                   0.133705     0.830096   \n",
       "4    0.144739  0.238395  0.059277                   0.370087     0.252131   \n",
       "5    0.753275  0.026219  0.175914                   0.855644     0.100871   \n",
       "6    0.086338  0.109834  0.002533                   0.441833     0.208530   \n",
       "7    0.719489  0.019917  0.177375                   0.837457     0.111338   \n",
       "8    0.979866  0.065778  0.013180                   0.994070     0.000000   \n",
       "9    0.796203  0.177308  0.180361                   0.910296     0.088612   \n",
       "10   0.180932  0.239203  0.281093                   0.476267     0.414113   \n",
       "11   0.746699  0.221874  0.172101                   0.884964     0.104835   \n",
       "12   0.708238  0.039289  0.192864                   0.832247     0.120533   \n",
       "13   0.759275  0.117672  0.348243                   0.859624     0.151281   \n",
       "14   0.734341  0.212244  0.184847                   0.876952     0.112303   \n",
       "15   0.032162  0.644137  0.395792                   0.149959     0.784006   \n",
       "16   0.929437  0.030788  0.039176                   0.961233     0.011858   \n",
       "17   0.309006  0.181983  0.588884                   0.500712     0.470738   \n",
       "18   0.776195  0.025340  0.168686                   0.868081     0.093564   \n",
       "19   0.910705  0.047852  0.143099                   0.963078     0.052286   \n",
       "20   1.000000  0.005193  0.024192                   1.000000     0.000296   \n",
       "21   0.638123  0.147780  0.304033                   0.879514     0.184535   \n",
       "22   0.265679  0.155492  0.768694                   0.525848     0.570201   \n",
       "23   0.701493  0.035783  0.271819                   0.870198     0.136969   \n",
       "24   0.037521  0.410973  0.183254                   0.121111     0.565109   \n",
       "25   0.034828  0.858426  0.423979                   0.112276     0.827759   \n",
       "26   0.475351  0.113515  0.343857                   0.629219     0.271461   \n",
       "27   0.582977  0.247465  0.263660                   0.823804     0.173158   \n",
       "28   0.052330  0.463148  0.603172                   0.239494     0.865652   \n",
       "29   0.079862  0.585364  0.747049                   0.282110     0.781438   \n",
       "..        ...       ...       ...                        ...          ...   \n",
       "172  0.673622  0.236813  0.206139                   0.811437     0.139913   \n",
       "173  0.880415  0.051604  0.117267                   0.942785     0.054652   \n",
       "174  0.801684  0.024262  0.000000                   0.915328     0.026728   \n",
       "175  0.000000  0.811920  0.410706                   0.000000     0.901127   \n",
       "176  0.843534  0.069507  0.259898                   0.921249     0.099657   \n",
       "177  0.140590  0.316887  0.334944                   0.444251     0.499718   \n",
       "178  0.915000  0.032007  0.147267                   0.970536     0.051183   \n",
       "179  0.848981  0.071954  0.172494                   0.923166     0.078513   \n",
       "180  0.954383  0.054051  0.066594                   0.986426     0.021105   \n",
       "181  0.587120  0.191977  0.251218                   0.780205     0.180097   \n",
       "182  0.217640  0.240444  0.485385                   0.472427     0.491405   \n",
       "183  0.260285  0.006904  0.391357                   0.582404     0.386956   \n",
       "184  0.171980  0.197873  0.387828                   0.340331     0.477394   \n",
       "185  0.896178  0.063057  0.135481                   0.969489     0.052887   \n",
       "186  0.293539  0.250586  0.745285                   0.589536     0.498973   \n",
       "187  0.031995  0.874942  0.399836                   0.139135     0.804057   \n",
       "188  0.899593  0.053779  0.158514                   0.937548     0.058574   \n",
       "189  0.758134  0.109442  0.189716                   0.897108     0.109560   \n",
       "190  0.163818  0.135848  0.718995                   0.542462     0.671649   \n",
       "191  0.038905  0.586514  0.503882                   0.164647     0.816463   \n",
       "192  0.920701  0.040314  0.092649                   0.970882     0.035811   \n",
       "193  0.726078  0.115909  0.300091                   0.884202     0.149577   \n",
       "194  0.807777  0.116304  0.218959                   0.917608     0.099300   \n",
       "195  0.749143  0.094078  0.381677                   0.889109     0.162363   \n",
       "196  0.159620  0.318122  0.700541                   0.396494     0.681425   \n",
       "197  0.026085  0.312549  0.024595                   0.414045     0.321003   \n",
       "198  0.119864  0.390216  0.525686                   0.407587     0.664672   \n",
       "199  0.267379  0.604305  0.411300                   0.448197     0.412848   \n",
       "200  0.893015  0.105256  0.098113                   0.957846     0.040973   \n",
       "201  0.727275  0.164323  0.273176                   0.869686     0.143265   \n",
       "\n",
       "     sum variance  sum entropy   entropy  difference variance  \\\n",
       "0        0.503203     0.699561  0.680072             0.143376   \n",
       "1        0.222110     0.142707  0.124576             0.695182   \n",
       "2        0.229158     0.305093  0.272178             0.536824   \n",
       "3        0.340649     0.935801  0.905857             0.046132   \n",
       "4        0.058167     0.673827  0.645537             0.162975   \n",
       "5        0.176298     0.196664  0.177152             0.647691   \n",
       "6        0.002042     0.711789  0.647242             0.255335   \n",
       "7        0.177799     0.220557  0.198897             0.622483   \n",
       "8        0.012969     0.010677  0.008506             0.847751   \n",
       "9        0.179878     0.156350  0.132000             0.687980   \n",
       "10       0.280477     0.663436  0.601878             0.247823   \n",
       "11       0.171341     0.186406  0.160340             0.650283   \n",
       "12       0.193210     0.226917  0.204334             0.613916   \n",
       "13       0.348484     0.186493  0.168041             0.682123   \n",
       "14       0.184171     0.197792  0.170491             0.645881   \n",
       "15       0.393083     0.905366  0.885406             0.045673   \n",
       "16       0.039227     0.054511  0.049274             0.782016   \n",
       "17       0.589292     0.534461  0.512072             0.282558   \n",
       "18       0.169059     0.178687  0.161216             0.662719   \n",
       "19       0.143284     0.064152  0.054446             0.771295   \n",
       "20       0.024357     0.000000  0.000000             0.868280   \n",
       "21       0.304000     0.270962  0.214235             0.748563   \n",
       "22       0.769660     0.598892  0.547214             0.264344   \n",
       "23       0.272363     0.232108  0.194935             0.624206   \n",
       "24       0.181421     0.861132  0.854264             0.037339   \n",
       "25       0.420090     0.891780  0.897603             0.029799   \n",
       "26       0.344112     0.381336  0.372120             0.469400   \n",
       "27       0.262957     0.323813  0.270001             0.550242   \n",
       "28       0.601981     0.887251  0.830420             0.083958   \n",
       "29       0.745472     0.830760  0.789128             0.099432   \n",
       "..            ...          ...       ...                  ...   \n",
       "172      0.205368     0.233830  0.216615             0.573074   \n",
       "173      0.117372     0.087996  0.076518             0.742533   \n",
       "174      0.000000     0.132504  0.113929             0.760796   \n",
       "175      0.407058     1.000000  1.000000             0.000000   \n",
       "176      0.260220     0.122099  0.107735             0.710995   \n",
       "177      0.333999     0.712943  0.642178             0.214201   \n",
       "178      0.147553     0.064473  0.052746             0.782980   \n",
       "179      0.172605     0.111210  0.097702             0.719215   \n",
       "180      0.066571     0.033350  0.026036             0.817499   \n",
       "181      0.250809     0.302527  0.269404             0.525626   \n",
       "182      0.485222     0.656693  0.601077             0.216915   \n",
       "183      0.392338     0.630229  0.550682             0.364547   \n",
       "184      0.387692     0.694496  0.672813             0.159429   \n",
       "185      0.135560     0.076344  0.059401             0.869805   \n",
       "186      0.745647     0.599466  0.531970             0.305995   \n",
       "187      0.395797     0.906055  0.891244             0.041939   \n",
       "188      0.158699     0.082211  0.075743             0.747268   \n",
       "189      0.189649     0.172731  0.147778             0.661098   \n",
       "190      0.719964     0.716340  0.624908             0.261304   \n",
       "191      0.501751     0.919728  0.880194             0.051927   \n",
       "192      0.092764     0.055561  0.046131             0.782385   \n",
       "193      0.300234     0.202148  0.172830             0.649604   \n",
       "194      0.218917     0.146716  0.124237             0.703470   \n",
       "195      0.382130     0.186939  0.160144             0.671443   \n",
       "196      0.700410     0.716595  0.662927             0.179710   \n",
       "197      0.022976     0.828106  0.741574             0.183148   \n",
       "198      0.524744     0.749218  0.676693             0.205149   \n",
       "199      0.408858     0.563737  0.556675             0.214612   \n",
       "200      0.097863     0.077010  0.063731             0.853903   \n",
       "201      0.272977     0.204996  0.177072             0.746733   \n",
       "\n",
       "     difference entropy    mean_B    mean_G    mean_R     std_B     std_G  \\\n",
       "0              0.709940  0.313805  0.528787  0.614273  0.304604  0.615009   \n",
       "1              0.139885  0.220593  0.101461  0.053140  0.559716  0.442374   \n",
       "2              0.286056  0.298854  0.167377  0.074775  0.539028  0.447906   \n",
       "3              0.817664  0.265694  0.874486  0.759549  0.398753  0.512621   \n",
       "4              0.641177  0.170598  0.232265  0.307716  0.091011  0.135052   \n",
       "5              0.198023  0.176512  0.076325  0.152918  0.394871  0.249911   \n",
       "6              0.552105  0.231839  0.171394  0.286421  0.087317  0.000000   \n",
       "7              0.220909  0.225201  0.090681  0.143445  0.463693  0.267135   \n",
       "8              0.011066  0.058835  0.005192  0.000907  0.260821  0.170652   \n",
       "9              0.131606  0.225653  0.099282  0.044162  0.561475  0.415473   \n",
       "10             0.536012  0.124879  0.416336  0.442787  0.188226  0.449327   \n",
       "11             0.165443  0.211575  0.128075  0.035218  0.444714  0.439441   \n",
       "12             0.227441  0.196033  0.095771  0.170095  0.400597  0.273870   \n",
       "13             0.198418  0.239835  0.152197  0.131952  0.500756  0.535543   \n",
       "14             0.175686  0.223086  0.136636  0.037988  0.459744  0.455840   \n",
       "15             0.838216  0.267264  0.825950  0.716113  0.410896  0.566080   \n",
       "16             0.066333  0.081997  0.009346  0.026549  0.312601  0.146925   \n",
       "17             0.563096  0.413763  0.430469  0.534928  0.399168  0.659911   \n",
       "18             0.182666  0.167726  0.069320  0.146390  0.389611  0.240168   \n",
       "19             0.061737  0.169317  0.058562  0.028645  0.516078  0.360929   \n",
       "20             0.000000  0.069477  0.000000  0.011742  0.313507  0.153461   \n",
       "21             0.149985  0.398479  0.210074  0.071560  0.682240  0.573719   \n",
       "22             0.526277  0.652788  0.494717  0.669729  0.627026  0.731178   \n",
       "23             0.182920  0.301243  0.143018  0.089608  0.613827  0.458148   \n",
       "24             0.834893  0.149505  0.581961  0.565702  0.134371  0.340063   \n",
       "25             0.899544  0.316002  0.875428  0.738687  0.418568  0.599603   \n",
       "26             0.457843  0.414242  0.259100  0.252296  0.540759  0.500993   \n",
       "27             0.233951  0.389343  0.207296  0.041097  0.677191  0.551749   \n",
       "28             0.725498  0.742508  0.841126  0.848570  0.533037  0.695461   \n",
       "29             0.764286  0.632374  0.770294  0.750642  0.844418  0.764848   \n",
       "..                  ...       ...       ...       ...       ...       ...   \n",
       "172            0.271532  0.141284  0.169710  0.074488  0.268916  0.480453   \n",
       "173            0.085906  0.148910  0.057173  0.045037  0.411167  0.300986   \n",
       "174            0.122401  0.086998  0.039078  0.006200  0.192364  0.138401   \n",
       "175            0.970119  0.728078  0.891336  0.855435  0.772312  0.459785   \n",
       "176            0.124364  0.240255  0.108289  0.057490  0.613340  0.486935   \n",
       "177            0.548127  0.127916  0.502639  0.532559  0.197047  0.506081   \n",
       "178            0.050377  0.165452  0.060708  0.020644  0.521208  0.386048   \n",
       "179            0.113572  0.198191  0.069739  0.085985  0.495080  0.312069   \n",
       "180            0.023627  0.112506  0.026828  0.009726  0.414651  0.261029   \n",
       "181            0.294182  0.265157  0.199069  0.114448  0.417356  0.470486   \n",
       "182            0.567732  0.249824  0.529215  0.411167  0.356654  0.709945   \n",
       "183            0.446804  0.422132  0.344042  0.448278  0.419722  0.473452   \n",
       "184            0.697615  0.929689  0.522162  0.216727  0.777439  0.618846   \n",
       "185            0.047101  0.147634  0.064569  0.021641  0.444405  0.372508   \n",
       "186            0.482356  0.257551  0.484984  0.541190  0.579617  0.803037   \n",
       "187            0.852812  0.290984  0.847244  0.730920  0.426295  0.570417   \n",
       "188            0.098770  0.142637  0.054676  0.066041  0.420517  0.324368   \n",
       "189            0.153561  0.233146  0.117561  0.071364  0.483006  0.396386   \n",
       "190            0.490682  0.860006  0.623702  0.665884  0.776326  0.741387   \n",
       "191            0.808667  0.311832  0.825653  0.818722  0.493654  0.626898   \n",
       "192            0.050987  0.139915  0.044773  0.011418  0.448850  0.308036   \n",
       "193            0.174849  0.322473  0.177353  0.046490  0.668801  0.601540   \n",
       "194            0.126164  0.241203  0.119873  0.028485  0.595669  0.503300   \n",
       "195            0.160701  0.230659  0.140920  0.199346  0.511220  0.489412   \n",
       "196            0.615511  0.617823  0.688062  0.603715  0.690891  0.809813   \n",
       "197            0.573303  0.382859  0.265135  0.416812  0.173793  0.031885   \n",
       "198            0.566305  0.618787  0.681682  0.561207  0.671038  0.686257   \n",
       "199            0.661302  0.244477  0.476542  0.266252  0.389821  0.677589   \n",
       "200            0.068592  0.145840  0.054063  0.005795  0.464688  0.339510   \n",
       "201            0.177171  0.218874  0.148886  0.117074  0.421086  0.477927   \n",
       "\n",
       "        std_R  \n",
       "0    0.737568  \n",
       "1    0.309818  \n",
       "2    0.289288  \n",
       "3    0.594145  \n",
       "4    0.348236  \n",
       "5    0.468215  \n",
       "6    0.297518  \n",
       "7    0.421028  \n",
       "8    0.017506  \n",
       "9    0.177397  \n",
       "10   0.545056  \n",
       "11   0.162066  \n",
       "12   0.480086  \n",
       "13   0.451087  \n",
       "14   0.174449  \n",
       "15   0.619856  \n",
       "16   0.165443  \n",
       "17   0.783451  \n",
       "18   0.463173  \n",
       "19   0.163771  \n",
       "20   0.076231  \n",
       "21   0.182825  \n",
       "22   0.923630  \n",
       "23   0.387999  \n",
       "24   0.452158  \n",
       "25   0.630198  \n",
       "26   0.459192  \n",
       "27   0.188445  \n",
       "28   0.743058  \n",
       "29   0.864680  \n",
       "..        ...  \n",
       "172  0.260380  \n",
       "173  0.174222  \n",
       "174  0.026030  \n",
       "175  0.682910  \n",
       "176  0.315547  \n",
       "177  0.593324  \n",
       "178  0.144966  \n",
       "179  0.325535  \n",
       "180  0.081890  \n",
       "181  0.359641  \n",
       "182  0.542708  \n",
       "183  0.672721  \n",
       "184  0.340381  \n",
       "185  0.142865  \n",
       "186  0.856679  \n",
       "187  0.621260  \n",
       "188  0.275003  \n",
       "189  0.262710  \n",
       "190  0.779577  \n",
       "191  0.716824  \n",
       "192  0.097947  \n",
       "193  0.225496  \n",
       "194  0.167518  \n",
       "195  0.576189  \n",
       "196  0.692345  \n",
       "197  0.333213  \n",
       "198  0.585089  \n",
       "199  0.456193  \n",
       "200  0.040803  \n",
       "201  0.403525  \n",
       "\n",
       "[202 rows x 16 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Dataset into training and testing dataset\n",
    "\n",
    "#### 162 Tea leaves images are used as training dataset and remaining 40 tea leaf images are used for testing  (80% of dataset is used for training purpose and 20% of dataset is used for testing purpose) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = my_file[:162]\n",
    "train_label = mylabel[:162] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = my_file[162:]\n",
    "test_label = mylabel[162:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy</th>\n",
       "      <th>contrast</th>\n",
       "      <th>variance</th>\n",
       "      <th>inverse difference moment</th>\n",
       "      <th>sum average</th>\n",
       "      <th>sum variance</th>\n",
       "      <th>sum entropy</th>\n",
       "      <th>entropy</th>\n",
       "      <th>difference variance</th>\n",
       "      <th>difference entropy</th>\n",
       "      <th>mean_B</th>\n",
       "      <th>mean_G</th>\n",
       "      <th>mean_R</th>\n",
       "      <th>std_B</th>\n",
       "      <th>std_G</th>\n",
       "      <th>std_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.169224</td>\n",
       "      <td>0.289995</td>\n",
       "      <td>0.503613</td>\n",
       "      <td>0.328835</td>\n",
       "      <td>0.554133</td>\n",
       "      <td>0.503203</td>\n",
       "      <td>0.699561</td>\n",
       "      <td>0.680072</td>\n",
       "      <td>0.143376</td>\n",
       "      <td>0.709940</td>\n",
       "      <td>0.313805</td>\n",
       "      <td>0.528787</td>\n",
       "      <td>0.614273</td>\n",
       "      <td>0.304604</td>\n",
       "      <td>0.615009</td>\n",
       "      <td>0.737568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.816743</td>\n",
       "      <td>0.101235</td>\n",
       "      <td>0.222058</td>\n",
       "      <td>0.910721</td>\n",
       "      <td>0.092361</td>\n",
       "      <td>0.222110</td>\n",
       "      <td>0.142707</td>\n",
       "      <td>0.124576</td>\n",
       "      <td>0.695182</td>\n",
       "      <td>0.139885</td>\n",
       "      <td>0.220593</td>\n",
       "      <td>0.101461</td>\n",
       "      <td>0.053140</td>\n",
       "      <td>0.559716</td>\n",
       "      <td>0.442374</td>\n",
       "      <td>0.309818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.616307</td>\n",
       "      <td>0.174905</td>\n",
       "      <td>0.229516</td>\n",
       "      <td>0.791696</td>\n",
       "      <td>0.149270</td>\n",
       "      <td>0.229158</td>\n",
       "      <td>0.305093</td>\n",
       "      <td>0.272178</td>\n",
       "      <td>0.536824</td>\n",
       "      <td>0.286056</td>\n",
       "      <td>0.298854</td>\n",
       "      <td>0.167377</td>\n",
       "      <td>0.074775</td>\n",
       "      <td>0.539028</td>\n",
       "      <td>0.447906</td>\n",
       "      <td>0.289288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016687</td>\n",
       "      <td>0.680178</td>\n",
       "      <td>0.343683</td>\n",
       "      <td>0.133705</td>\n",
       "      <td>0.830096</td>\n",
       "      <td>0.340649</td>\n",
       "      <td>0.935801</td>\n",
       "      <td>0.905857</td>\n",
       "      <td>0.046132</td>\n",
       "      <td>0.817664</td>\n",
       "      <td>0.265694</td>\n",
       "      <td>0.874486</td>\n",
       "      <td>0.759549</td>\n",
       "      <td>0.398753</td>\n",
       "      <td>0.512621</td>\n",
       "      <td>0.594145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.144739</td>\n",
       "      <td>0.238395</td>\n",
       "      <td>0.059277</td>\n",
       "      <td>0.370087</td>\n",
       "      <td>0.252131</td>\n",
       "      <td>0.058167</td>\n",
       "      <td>0.673827</td>\n",
       "      <td>0.645537</td>\n",
       "      <td>0.162975</td>\n",
       "      <td>0.641177</td>\n",
       "      <td>0.170598</td>\n",
       "      <td>0.232265</td>\n",
       "      <td>0.307716</td>\n",
       "      <td>0.091011</td>\n",
       "      <td>0.135052</td>\n",
       "      <td>0.348236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.753275</td>\n",
       "      <td>0.026219</td>\n",
       "      <td>0.175914</td>\n",
       "      <td>0.855644</td>\n",
       "      <td>0.100871</td>\n",
       "      <td>0.176298</td>\n",
       "      <td>0.196664</td>\n",
       "      <td>0.177152</td>\n",
       "      <td>0.647691</td>\n",
       "      <td>0.198023</td>\n",
       "      <td>0.176512</td>\n",
       "      <td>0.076325</td>\n",
       "      <td>0.152918</td>\n",
       "      <td>0.394871</td>\n",
       "      <td>0.249911</td>\n",
       "      <td>0.468215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.086338</td>\n",
       "      <td>0.109834</td>\n",
       "      <td>0.002533</td>\n",
       "      <td>0.441833</td>\n",
       "      <td>0.208530</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>0.711789</td>\n",
       "      <td>0.647242</td>\n",
       "      <td>0.255335</td>\n",
       "      <td>0.552105</td>\n",
       "      <td>0.231839</td>\n",
       "      <td>0.171394</td>\n",
       "      <td>0.286421</td>\n",
       "      <td>0.087317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.297518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.719489</td>\n",
       "      <td>0.019917</td>\n",
       "      <td>0.177375</td>\n",
       "      <td>0.837457</td>\n",
       "      <td>0.111338</td>\n",
       "      <td>0.177799</td>\n",
       "      <td>0.220557</td>\n",
       "      <td>0.198897</td>\n",
       "      <td>0.622483</td>\n",
       "      <td>0.220909</td>\n",
       "      <td>0.225201</td>\n",
       "      <td>0.090681</td>\n",
       "      <td>0.143445</td>\n",
       "      <td>0.463693</td>\n",
       "      <td>0.267135</td>\n",
       "      <td>0.421028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.979866</td>\n",
       "      <td>0.065778</td>\n",
       "      <td>0.013180</td>\n",
       "      <td>0.994070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012969</td>\n",
       "      <td>0.010677</td>\n",
       "      <td>0.008506</td>\n",
       "      <td>0.847751</td>\n",
       "      <td>0.011066</td>\n",
       "      <td>0.058835</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>0.260821</td>\n",
       "      <td>0.170652</td>\n",
       "      <td>0.017506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.796203</td>\n",
       "      <td>0.177308</td>\n",
       "      <td>0.180361</td>\n",
       "      <td>0.910296</td>\n",
       "      <td>0.088612</td>\n",
       "      <td>0.179878</td>\n",
       "      <td>0.156350</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>0.687980</td>\n",
       "      <td>0.131606</td>\n",
       "      <td>0.225653</td>\n",
       "      <td>0.099282</td>\n",
       "      <td>0.044162</td>\n",
       "      <td>0.561475</td>\n",
       "      <td>0.415473</td>\n",
       "      <td>0.177397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.180932</td>\n",
       "      <td>0.239203</td>\n",
       "      <td>0.281093</td>\n",
       "      <td>0.476267</td>\n",
       "      <td>0.414113</td>\n",
       "      <td>0.280477</td>\n",
       "      <td>0.663436</td>\n",
       "      <td>0.601878</td>\n",
       "      <td>0.247823</td>\n",
       "      <td>0.536012</td>\n",
       "      <td>0.124879</td>\n",
       "      <td>0.416336</td>\n",
       "      <td>0.442787</td>\n",
       "      <td>0.188226</td>\n",
       "      <td>0.449327</td>\n",
       "      <td>0.545056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.746699</td>\n",
       "      <td>0.221874</td>\n",
       "      <td>0.172101</td>\n",
       "      <td>0.884964</td>\n",
       "      <td>0.104835</td>\n",
       "      <td>0.171341</td>\n",
       "      <td>0.186406</td>\n",
       "      <td>0.160340</td>\n",
       "      <td>0.650283</td>\n",
       "      <td>0.165443</td>\n",
       "      <td>0.211575</td>\n",
       "      <td>0.128075</td>\n",
       "      <td>0.035218</td>\n",
       "      <td>0.444714</td>\n",
       "      <td>0.439441</td>\n",
       "      <td>0.162066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.708238</td>\n",
       "      <td>0.039289</td>\n",
       "      <td>0.192864</td>\n",
       "      <td>0.832247</td>\n",
       "      <td>0.120533</td>\n",
       "      <td>0.193210</td>\n",
       "      <td>0.226917</td>\n",
       "      <td>0.204334</td>\n",
       "      <td>0.613916</td>\n",
       "      <td>0.227441</td>\n",
       "      <td>0.196033</td>\n",
       "      <td>0.095771</td>\n",
       "      <td>0.170095</td>\n",
       "      <td>0.400597</td>\n",
       "      <td>0.273870</td>\n",
       "      <td>0.480086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.759275</td>\n",
       "      <td>0.117672</td>\n",
       "      <td>0.348243</td>\n",
       "      <td>0.859624</td>\n",
       "      <td>0.151281</td>\n",
       "      <td>0.348484</td>\n",
       "      <td>0.186493</td>\n",
       "      <td>0.168041</td>\n",
       "      <td>0.682123</td>\n",
       "      <td>0.198418</td>\n",
       "      <td>0.239835</td>\n",
       "      <td>0.152197</td>\n",
       "      <td>0.131952</td>\n",
       "      <td>0.500756</td>\n",
       "      <td>0.535543</td>\n",
       "      <td>0.451087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.734341</td>\n",
       "      <td>0.212244</td>\n",
       "      <td>0.184847</td>\n",
       "      <td>0.876952</td>\n",
       "      <td>0.112303</td>\n",
       "      <td>0.184171</td>\n",
       "      <td>0.197792</td>\n",
       "      <td>0.170491</td>\n",
       "      <td>0.645881</td>\n",
       "      <td>0.175686</td>\n",
       "      <td>0.223086</td>\n",
       "      <td>0.136636</td>\n",
       "      <td>0.037988</td>\n",
       "      <td>0.459744</td>\n",
       "      <td>0.455840</td>\n",
       "      <td>0.174449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.032162</td>\n",
       "      <td>0.644137</td>\n",
       "      <td>0.395792</td>\n",
       "      <td>0.149959</td>\n",
       "      <td>0.784006</td>\n",
       "      <td>0.393083</td>\n",
       "      <td>0.905366</td>\n",
       "      <td>0.885406</td>\n",
       "      <td>0.045673</td>\n",
       "      <td>0.838216</td>\n",
       "      <td>0.267264</td>\n",
       "      <td>0.825950</td>\n",
       "      <td>0.716113</td>\n",
       "      <td>0.410896</td>\n",
       "      <td>0.566080</td>\n",
       "      <td>0.619856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.929437</td>\n",
       "      <td>0.030788</td>\n",
       "      <td>0.039176</td>\n",
       "      <td>0.961233</td>\n",
       "      <td>0.011858</td>\n",
       "      <td>0.039227</td>\n",
       "      <td>0.054511</td>\n",
       "      <td>0.049274</td>\n",
       "      <td>0.782016</td>\n",
       "      <td>0.066333</td>\n",
       "      <td>0.081997</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.026549</td>\n",
       "      <td>0.312601</td>\n",
       "      <td>0.146925</td>\n",
       "      <td>0.165443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.309006</td>\n",
       "      <td>0.181983</td>\n",
       "      <td>0.588884</td>\n",
       "      <td>0.500712</td>\n",
       "      <td>0.470738</td>\n",
       "      <td>0.589292</td>\n",
       "      <td>0.534461</td>\n",
       "      <td>0.512072</td>\n",
       "      <td>0.282558</td>\n",
       "      <td>0.563096</td>\n",
       "      <td>0.413763</td>\n",
       "      <td>0.430469</td>\n",
       "      <td>0.534928</td>\n",
       "      <td>0.399168</td>\n",
       "      <td>0.659911</td>\n",
       "      <td>0.783451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.776195</td>\n",
       "      <td>0.025340</td>\n",
       "      <td>0.168686</td>\n",
       "      <td>0.868081</td>\n",
       "      <td>0.093564</td>\n",
       "      <td>0.169059</td>\n",
       "      <td>0.178687</td>\n",
       "      <td>0.161216</td>\n",
       "      <td>0.662719</td>\n",
       "      <td>0.182666</td>\n",
       "      <td>0.167726</td>\n",
       "      <td>0.069320</td>\n",
       "      <td>0.146390</td>\n",
       "      <td>0.389611</td>\n",
       "      <td>0.240168</td>\n",
       "      <td>0.463173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.910705</td>\n",
       "      <td>0.047852</td>\n",
       "      <td>0.143099</td>\n",
       "      <td>0.963078</td>\n",
       "      <td>0.052286</td>\n",
       "      <td>0.143284</td>\n",
       "      <td>0.064152</td>\n",
       "      <td>0.054446</td>\n",
       "      <td>0.771295</td>\n",
       "      <td>0.061737</td>\n",
       "      <td>0.169317</td>\n",
       "      <td>0.058562</td>\n",
       "      <td>0.028645</td>\n",
       "      <td>0.516078</td>\n",
       "      <td>0.360929</td>\n",
       "      <td>0.163771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005193</td>\n",
       "      <td>0.024192</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.024357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.868280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011742</td>\n",
       "      <td>0.313507</td>\n",
       "      <td>0.153461</td>\n",
       "      <td>0.076231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.638123</td>\n",
       "      <td>0.147780</td>\n",
       "      <td>0.304033</td>\n",
       "      <td>0.879514</td>\n",
       "      <td>0.184535</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.270962</td>\n",
       "      <td>0.214235</td>\n",
       "      <td>0.748563</td>\n",
       "      <td>0.149985</td>\n",
       "      <td>0.398479</td>\n",
       "      <td>0.210074</td>\n",
       "      <td>0.071560</td>\n",
       "      <td>0.682240</td>\n",
       "      <td>0.573719</td>\n",
       "      <td>0.182825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.265679</td>\n",
       "      <td>0.155492</td>\n",
       "      <td>0.768694</td>\n",
       "      <td>0.525848</td>\n",
       "      <td>0.570201</td>\n",
       "      <td>0.769660</td>\n",
       "      <td>0.598892</td>\n",
       "      <td>0.547214</td>\n",
       "      <td>0.264344</td>\n",
       "      <td>0.526277</td>\n",
       "      <td>0.652788</td>\n",
       "      <td>0.494717</td>\n",
       "      <td>0.669729</td>\n",
       "      <td>0.627026</td>\n",
       "      <td>0.731178</td>\n",
       "      <td>0.923630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.701493</td>\n",
       "      <td>0.035783</td>\n",
       "      <td>0.271819</td>\n",
       "      <td>0.870198</td>\n",
       "      <td>0.136969</td>\n",
       "      <td>0.272363</td>\n",
       "      <td>0.232108</td>\n",
       "      <td>0.194935</td>\n",
       "      <td>0.624206</td>\n",
       "      <td>0.182920</td>\n",
       "      <td>0.301243</td>\n",
       "      <td>0.143018</td>\n",
       "      <td>0.089608</td>\n",
       "      <td>0.613827</td>\n",
       "      <td>0.458148</td>\n",
       "      <td>0.387999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.037521</td>\n",
       "      <td>0.410973</td>\n",
       "      <td>0.183254</td>\n",
       "      <td>0.121111</td>\n",
       "      <td>0.565109</td>\n",
       "      <td>0.181421</td>\n",
       "      <td>0.861132</td>\n",
       "      <td>0.854264</td>\n",
       "      <td>0.037339</td>\n",
       "      <td>0.834893</td>\n",
       "      <td>0.149505</td>\n",
       "      <td>0.581961</td>\n",
       "      <td>0.565702</td>\n",
       "      <td>0.134371</td>\n",
       "      <td>0.340063</td>\n",
       "      <td>0.452158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.034828</td>\n",
       "      <td>0.858426</td>\n",
       "      <td>0.423979</td>\n",
       "      <td>0.112276</td>\n",
       "      <td>0.827759</td>\n",
       "      <td>0.420090</td>\n",
       "      <td>0.891780</td>\n",
       "      <td>0.897603</td>\n",
       "      <td>0.029799</td>\n",
       "      <td>0.899544</td>\n",
       "      <td>0.316002</td>\n",
       "      <td>0.875428</td>\n",
       "      <td>0.738687</td>\n",
       "      <td>0.418568</td>\n",
       "      <td>0.599603</td>\n",
       "      <td>0.630198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.475351</td>\n",
       "      <td>0.113515</td>\n",
       "      <td>0.343857</td>\n",
       "      <td>0.629219</td>\n",
       "      <td>0.271461</td>\n",
       "      <td>0.344112</td>\n",
       "      <td>0.381336</td>\n",
       "      <td>0.372120</td>\n",
       "      <td>0.469400</td>\n",
       "      <td>0.457843</td>\n",
       "      <td>0.414242</td>\n",
       "      <td>0.259100</td>\n",
       "      <td>0.252296</td>\n",
       "      <td>0.540759</td>\n",
       "      <td>0.500993</td>\n",
       "      <td>0.459192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.582977</td>\n",
       "      <td>0.247465</td>\n",
       "      <td>0.263660</td>\n",
       "      <td>0.823804</td>\n",
       "      <td>0.173158</td>\n",
       "      <td>0.262957</td>\n",
       "      <td>0.323813</td>\n",
       "      <td>0.270001</td>\n",
       "      <td>0.550242</td>\n",
       "      <td>0.233951</td>\n",
       "      <td>0.389343</td>\n",
       "      <td>0.207296</td>\n",
       "      <td>0.041097</td>\n",
       "      <td>0.677191</td>\n",
       "      <td>0.551749</td>\n",
       "      <td>0.188445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.052330</td>\n",
       "      <td>0.463148</td>\n",
       "      <td>0.603172</td>\n",
       "      <td>0.239494</td>\n",
       "      <td>0.865652</td>\n",
       "      <td>0.601981</td>\n",
       "      <td>0.887251</td>\n",
       "      <td>0.830420</td>\n",
       "      <td>0.083958</td>\n",
       "      <td>0.725498</td>\n",
       "      <td>0.742508</td>\n",
       "      <td>0.841126</td>\n",
       "      <td>0.848570</td>\n",
       "      <td>0.533037</td>\n",
       "      <td>0.695461</td>\n",
       "      <td>0.743058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.079862</td>\n",
       "      <td>0.585364</td>\n",
       "      <td>0.747049</td>\n",
       "      <td>0.282110</td>\n",
       "      <td>0.781438</td>\n",
       "      <td>0.745472</td>\n",
       "      <td>0.830760</td>\n",
       "      <td>0.789128</td>\n",
       "      <td>0.099432</td>\n",
       "      <td>0.764286</td>\n",
       "      <td>0.632374</td>\n",
       "      <td>0.770294</td>\n",
       "      <td>0.750642</td>\n",
       "      <td>0.844418</td>\n",
       "      <td>0.764848</td>\n",
       "      <td>0.864680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.645853</td>\n",
       "      <td>0.135929</td>\n",
       "      <td>0.443657</td>\n",
       "      <td>0.823416</td>\n",
       "      <td>0.217616</td>\n",
       "      <td>0.444006</td>\n",
       "      <td>0.275301</td>\n",
       "      <td>0.241708</td>\n",
       "      <td>0.568529</td>\n",
       "      <td>0.250496</td>\n",
       "      <td>0.473873</td>\n",
       "      <td>0.236883</td>\n",
       "      <td>0.104340</td>\n",
       "      <td>0.838114</td>\n",
       "      <td>0.672522</td>\n",
       "      <td>0.406499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.212732</td>\n",
       "      <td>0.397300</td>\n",
       "      <td>0.447082</td>\n",
       "      <td>0.417542</td>\n",
       "      <td>0.474010</td>\n",
       "      <td>0.445922</td>\n",
       "      <td>0.659979</td>\n",
       "      <td>0.627627</td>\n",
       "      <td>0.185861</td>\n",
       "      <td>0.646859</td>\n",
       "      <td>0.247395</td>\n",
       "      <td>0.519701</td>\n",
       "      <td>0.374571</td>\n",
       "      <td>0.354900</td>\n",
       "      <td>0.684364</td>\n",
       "      <td>0.504045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.278409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.340610</td>\n",
       "      <td>0.592376</td>\n",
       "      <td>0.352626</td>\n",
       "      <td>0.341517</td>\n",
       "      <td>0.604308</td>\n",
       "      <td>0.529951</td>\n",
       "      <td>0.399729</td>\n",
       "      <td>0.440212</td>\n",
       "      <td>0.667015</td>\n",
       "      <td>0.338520</td>\n",
       "      <td>0.284144</td>\n",
       "      <td>0.703021</td>\n",
       "      <td>0.479525</td>\n",
       "      <td>0.442842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.880541</td>\n",
       "      <td>0.084340</td>\n",
       "      <td>0.076190</td>\n",
       "      <td>0.955531</td>\n",
       "      <td>0.039759</td>\n",
       "      <td>0.076012</td>\n",
       "      <td>0.085511</td>\n",
       "      <td>0.071197</td>\n",
       "      <td>0.944586</td>\n",
       "      <td>0.069753</td>\n",
       "      <td>0.136550</td>\n",
       "      <td>0.054957</td>\n",
       "      <td>0.001686</td>\n",
       "      <td>0.398962</td>\n",
       "      <td>0.311373</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.031826</td>\n",
       "      <td>0.594671</td>\n",
       "      <td>0.681899</td>\n",
       "      <td>0.296255</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.680121</td>\n",
       "      <td>0.903889</td>\n",
       "      <td>0.834994</td>\n",
       "      <td>0.108456</td>\n",
       "      <td>0.708133</td>\n",
       "      <td>0.617055</td>\n",
       "      <td>0.985698</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.877554</td>\n",
       "      <td>0.723824</td>\n",
       "      <td>0.827395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.074071</td>\n",
       "      <td>0.460207</td>\n",
       "      <td>0.444862</td>\n",
       "      <td>0.312196</td>\n",
       "      <td>0.636052</td>\n",
       "      <td>0.443332</td>\n",
       "      <td>0.846141</td>\n",
       "      <td>0.782075</td>\n",
       "      <td>0.115774</td>\n",
       "      <td>0.676443</td>\n",
       "      <td>0.010460</td>\n",
       "      <td>0.674330</td>\n",
       "      <td>0.625163</td>\n",
       "      <td>0.059598</td>\n",
       "      <td>0.646336</td>\n",
       "      <td>0.653199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.074672</td>\n",
       "      <td>0.719582</td>\n",
       "      <td>0.597443</td>\n",
       "      <td>0.241884</td>\n",
       "      <td>0.754096</td>\n",
       "      <td>0.594751</td>\n",
       "      <td>0.860951</td>\n",
       "      <td>0.818228</td>\n",
       "      <td>0.081610</td>\n",
       "      <td>0.773312</td>\n",
       "      <td>0.311437</td>\n",
       "      <td>0.756115</td>\n",
       "      <td>0.766888</td>\n",
       "      <td>0.520741</td>\n",
       "      <td>0.700660</td>\n",
       "      <td>0.771711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.861733</td>\n",
       "      <td>0.066044</td>\n",
       "      <td>0.064422</td>\n",
       "      <td>0.938579</td>\n",
       "      <td>0.039600</td>\n",
       "      <td>0.064324</td>\n",
       "      <td>0.102768</td>\n",
       "      <td>0.088436</td>\n",
       "      <td>0.758093</td>\n",
       "      <td>0.095588</td>\n",
       "      <td>0.123677</td>\n",
       "      <td>0.055475</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>0.341972</td>\n",
       "      <td>0.291142</td>\n",
       "      <td>0.021512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.242339</td>\n",
       "      <td>0.239148</td>\n",
       "      <td>0.497708</td>\n",
       "      <td>0.498061</td>\n",
       "      <td>0.479255</td>\n",
       "      <td>0.497580</td>\n",
       "      <td>0.623507</td>\n",
       "      <td>0.570164</td>\n",
       "      <td>0.235208</td>\n",
       "      <td>0.546601</td>\n",
       "      <td>0.239183</td>\n",
       "      <td>0.517943</td>\n",
       "      <td>0.398800</td>\n",
       "      <td>0.357749</td>\n",
       "      <td>0.719585</td>\n",
       "      <td>0.548627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.737837</td>\n",
       "      <td>0.123088</td>\n",
       "      <td>0.249290</td>\n",
       "      <td>0.857726</td>\n",
       "      <td>0.113028</td>\n",
       "      <td>0.249277</td>\n",
       "      <td>0.209732</td>\n",
       "      <td>0.187314</td>\n",
       "      <td>0.626262</td>\n",
       "      <td>0.213894</td>\n",
       "      <td>0.238091</td>\n",
       "      <td>0.112843</td>\n",
       "      <td>0.093472</td>\n",
       "      <td>0.549612</td>\n",
       "      <td>0.411648</td>\n",
       "      <td>0.397622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.736400</td>\n",
       "      <td>0.088800</td>\n",
       "      <td>0.366964</td>\n",
       "      <td>0.878258</td>\n",
       "      <td>0.161588</td>\n",
       "      <td>0.367415</td>\n",
       "      <td>0.201976</td>\n",
       "      <td>0.174083</td>\n",
       "      <td>0.652291</td>\n",
       "      <td>0.174873</td>\n",
       "      <td>0.285335</td>\n",
       "      <td>0.145946</td>\n",
       "      <td>0.171685</td>\n",
       "      <td>0.585209</td>\n",
       "      <td>0.493819</td>\n",
       "      <td>0.516183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.851731</td>\n",
       "      <td>0.048748</td>\n",
       "      <td>0.259864</td>\n",
       "      <td>0.925294</td>\n",
       "      <td>0.096625</td>\n",
       "      <td>0.260306</td>\n",
       "      <td>0.116619</td>\n",
       "      <td>0.102781</td>\n",
       "      <td>0.716928</td>\n",
       "      <td>0.118980</td>\n",
       "      <td>0.231058</td>\n",
       "      <td>0.104268</td>\n",
       "      <td>0.058751</td>\n",
       "      <td>0.603979</td>\n",
       "      <td>0.484588</td>\n",
       "      <td>0.318007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.284387</td>\n",
       "      <td>0.146664</td>\n",
       "      <td>0.672039</td>\n",
       "      <td>0.570640</td>\n",
       "      <td>0.514095</td>\n",
       "      <td>0.672840</td>\n",
       "      <td>0.576264</td>\n",
       "      <td>0.514959</td>\n",
       "      <td>0.313239</td>\n",
       "      <td>0.471214</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.481350</td>\n",
       "      <td>0.424212</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.735300</td>\n",
       "      <td>0.614458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.727530</td>\n",
       "      <td>0.049789</td>\n",
       "      <td>0.063248</td>\n",
       "      <td>0.848463</td>\n",
       "      <td>0.070763</td>\n",
       "      <td>0.063242</td>\n",
       "      <td>0.193881</td>\n",
       "      <td>0.176635</td>\n",
       "      <td>0.654409</td>\n",
       "      <td>0.209215</td>\n",
       "      <td>0.173089</td>\n",
       "      <td>0.086279</td>\n",
       "      <td>0.025816</td>\n",
       "      <td>0.325622</td>\n",
       "      <td>0.252005</td>\n",
       "      <td>0.088513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.794043</td>\n",
       "      <td>0.027502</td>\n",
       "      <td>0.149330</td>\n",
       "      <td>0.880099</td>\n",
       "      <td>0.082796</td>\n",
       "      <td>0.149647</td>\n",
       "      <td>0.162030</td>\n",
       "      <td>0.145990</td>\n",
       "      <td>0.682160</td>\n",
       "      <td>0.168556</td>\n",
       "      <td>0.183661</td>\n",
       "      <td>0.062259</td>\n",
       "      <td>0.122114</td>\n",
       "      <td>0.439205</td>\n",
       "      <td>0.227237</td>\n",
       "      <td>0.403000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.471033</td>\n",
       "      <td>0.240571</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.592830</td>\n",
       "      <td>0.277197</td>\n",
       "      <td>0.363198</td>\n",
       "      <td>0.389181</td>\n",
       "      <td>0.398795</td>\n",
       "      <td>0.398540</td>\n",
       "      <td>0.530844</td>\n",
       "      <td>0.363709</td>\n",
       "      <td>0.259050</td>\n",
       "      <td>0.284365</td>\n",
       "      <td>0.446762</td>\n",
       "      <td>0.503644</td>\n",
       "      <td>0.544987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.705738</td>\n",
       "      <td>0.058311</td>\n",
       "      <td>0.381418</td>\n",
       "      <td>0.856901</td>\n",
       "      <td>0.176308</td>\n",
       "      <td>0.382078</td>\n",
       "      <td>0.230541</td>\n",
       "      <td>0.200624</td>\n",
       "      <td>0.618844</td>\n",
       "      <td>0.202152</td>\n",
       "      <td>0.306789</td>\n",
       "      <td>0.160876</td>\n",
       "      <td>0.182036</td>\n",
       "      <td>0.597425</td>\n",
       "      <td>0.507315</td>\n",
       "      <td>0.525931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.280717</td>\n",
       "      <td>0.160962</td>\n",
       "      <td>0.768933</td>\n",
       "      <td>0.561061</td>\n",
       "      <td>0.557869</td>\n",
       "      <td>0.769868</td>\n",
       "      <td>0.583372</td>\n",
       "      <td>0.523030</td>\n",
       "      <td>0.292712</td>\n",
       "      <td>0.481569</td>\n",
       "      <td>0.640075</td>\n",
       "      <td>0.484277</td>\n",
       "      <td>0.654803</td>\n",
       "      <td>0.626683</td>\n",
       "      <td>0.731693</td>\n",
       "      <td>0.922313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.020219</td>\n",
       "      <td>0.554469</td>\n",
       "      <td>0.368241</td>\n",
       "      <td>0.141403</td>\n",
       "      <td>0.833108</td>\n",
       "      <td>0.365991</td>\n",
       "      <td>0.933129</td>\n",
       "      <td>0.902192</td>\n",
       "      <td>0.047187</td>\n",
       "      <td>0.812903</td>\n",
       "      <td>0.283739</td>\n",
       "      <td>0.874879</td>\n",
       "      <td>0.766307</td>\n",
       "      <td>0.431001</td>\n",
       "      <td>0.531658</td>\n",
       "      <td>0.613396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.743322</td>\n",
       "      <td>0.083516</td>\n",
       "      <td>0.375759</td>\n",
       "      <td>0.887884</td>\n",
       "      <td>0.165842</td>\n",
       "      <td>0.376260</td>\n",
       "      <td>0.191724</td>\n",
       "      <td>0.163524</td>\n",
       "      <td>0.659353</td>\n",
       "      <td>0.161803</td>\n",
       "      <td>0.389260</td>\n",
       "      <td>0.185456</td>\n",
       "      <td>0.067530</td>\n",
       "      <td>0.806767</td>\n",
       "      <td>0.646458</td>\n",
       "      <td>0.239361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.849902</td>\n",
       "      <td>0.019333</td>\n",
       "      <td>0.145730</td>\n",
       "      <td>0.949844</td>\n",
       "      <td>0.070827</td>\n",
       "      <td>0.146087</td>\n",
       "      <td>0.107178</td>\n",
       "      <td>0.087951</td>\n",
       "      <td>0.862835</td>\n",
       "      <td>0.079129</td>\n",
       "      <td>0.174678</td>\n",
       "      <td>0.089540</td>\n",
       "      <td>0.017940</td>\n",
       "      <td>0.451763</td>\n",
       "      <td>0.412236</td>\n",
       "      <td>0.115770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.397566</td>\n",
       "      <td>0.320199</td>\n",
       "      <td>0.466986</td>\n",
       "      <td>0.569552</td>\n",
       "      <td>0.348194</td>\n",
       "      <td>0.466319</td>\n",
       "      <td>0.466221</td>\n",
       "      <td>0.454695</td>\n",
       "      <td>0.355109</td>\n",
       "      <td>0.541982</td>\n",
       "      <td>0.175946</td>\n",
       "      <td>0.320325</td>\n",
       "      <td>0.429330</td>\n",
       "      <td>0.192105</td>\n",
       "      <td>0.578639</td>\n",
       "      <td>0.739005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.124393</td>\n",
       "      <td>0.248500</td>\n",
       "      <td>0.487117</td>\n",
       "      <td>0.370300</td>\n",
       "      <td>0.549832</td>\n",
       "      <td>0.486911</td>\n",
       "      <td>0.801573</td>\n",
       "      <td>0.735678</td>\n",
       "      <td>0.145483</td>\n",
       "      <td>0.644228</td>\n",
       "      <td>0.282172</td>\n",
       "      <td>0.545305</td>\n",
       "      <td>0.567497</td>\n",
       "      <td>0.433477</td>\n",
       "      <td>0.601541</td>\n",
       "      <td>0.699214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.487581</td>\n",
       "      <td>0.123430</td>\n",
       "      <td>0.352985</td>\n",
       "      <td>0.643946</td>\n",
       "      <td>0.266580</td>\n",
       "      <td>0.353203</td>\n",
       "      <td>0.371759</td>\n",
       "      <td>0.360644</td>\n",
       "      <td>0.455881</td>\n",
       "      <td>0.442211</td>\n",
       "      <td>0.355406</td>\n",
       "      <td>0.248507</td>\n",
       "      <td>0.274784</td>\n",
       "      <td>0.440869</td>\n",
       "      <td>0.493297</td>\n",
       "      <td>0.538858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.859038</td>\n",
       "      <td>0.087688</td>\n",
       "      <td>0.124883</td>\n",
       "      <td>0.934718</td>\n",
       "      <td>0.061451</td>\n",
       "      <td>0.124796</td>\n",
       "      <td>0.103159</td>\n",
       "      <td>0.089044</td>\n",
       "      <td>0.749533</td>\n",
       "      <td>0.100213</td>\n",
       "      <td>0.108491</td>\n",
       "      <td>0.074117</td>\n",
       "      <td>0.037926</td>\n",
       "      <td>0.282874</td>\n",
       "      <td>0.351699</td>\n",
       "      <td>0.183958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.842537</td>\n",
       "      <td>0.110994</td>\n",
       "      <td>0.204451</td>\n",
       "      <td>0.927244</td>\n",
       "      <td>0.086240</td>\n",
       "      <td>0.204407</td>\n",
       "      <td>0.116193</td>\n",
       "      <td>0.100923</td>\n",
       "      <td>0.717716</td>\n",
       "      <td>0.112887</td>\n",
       "      <td>0.231374</td>\n",
       "      <td>0.096031</td>\n",
       "      <td>0.042288</td>\n",
       "      <td>0.606232</td>\n",
       "      <td>0.446972</td>\n",
       "      <td>0.172812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.050335</td>\n",
       "      <td>0.567271</td>\n",
       "      <td>0.411831</td>\n",
       "      <td>0.281598</td>\n",
       "      <td>0.670655</td>\n",
       "      <td>0.409605</td>\n",
       "      <td>0.884174</td>\n",
       "      <td>0.813312</td>\n",
       "      <td>0.105402</td>\n",
       "      <td>0.674642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.714094</td>\n",
       "      <td>0.653454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.620931</td>\n",
       "      <td>0.626360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.486603</td>\n",
       "      <td>0.134009</td>\n",
       "      <td>0.340928</td>\n",
       "      <td>0.640326</td>\n",
       "      <td>0.263973</td>\n",
       "      <td>0.341058</td>\n",
       "      <td>0.371184</td>\n",
       "      <td>0.361974</td>\n",
       "      <td>0.466402</td>\n",
       "      <td>0.446690</td>\n",
       "      <td>0.406217</td>\n",
       "      <td>0.251548</td>\n",
       "      <td>0.246625</td>\n",
       "      <td>0.540365</td>\n",
       "      <td>0.497705</td>\n",
       "      <td>0.457404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.173193</td>\n",
       "      <td>0.210094</td>\n",
       "      <td>0.505773</td>\n",
       "      <td>0.336097</td>\n",
       "      <td>0.543099</td>\n",
       "      <td>0.505831</td>\n",
       "      <td>0.700749</td>\n",
       "      <td>0.679332</td>\n",
       "      <td>0.150142</td>\n",
       "      <td>0.702214</td>\n",
       "      <td>0.308823</td>\n",
       "      <td>0.517248</td>\n",
       "      <td>0.604296</td>\n",
       "      <td>0.302371</td>\n",
       "      <td>0.616105</td>\n",
       "      <td>0.740104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.494194</td>\n",
       "      <td>0.147221</td>\n",
       "      <td>0.406913</td>\n",
       "      <td>0.714284</td>\n",
       "      <td>0.248651</td>\n",
       "      <td>0.407114</td>\n",
       "      <td>0.400247</td>\n",
       "      <td>0.360798</td>\n",
       "      <td>0.444975</td>\n",
       "      <td>0.384820</td>\n",
       "      <td>0.429429</td>\n",
       "      <td>0.265146</td>\n",
       "      <td>0.155253</td>\n",
       "      <td>0.662022</td>\n",
       "      <td>0.587674</td>\n",
       "      <td>0.487641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       energy  contrast  variance  inverse difference moment  sum average  \\\n",
       "0    0.169224  0.289995  0.503613                   0.328835     0.554133   \n",
       "1    0.816743  0.101235  0.222058                   0.910721     0.092361   \n",
       "2    0.616307  0.174905  0.229516                   0.791696     0.149270   \n",
       "3    0.016687  0.680178  0.343683                   0.133705     0.830096   \n",
       "4    0.144739  0.238395  0.059277                   0.370087     0.252131   \n",
       "5    0.753275  0.026219  0.175914                   0.855644     0.100871   \n",
       "6    0.086338  0.109834  0.002533                   0.441833     0.208530   \n",
       "7    0.719489  0.019917  0.177375                   0.837457     0.111338   \n",
       "8    0.979866  0.065778  0.013180                   0.994070     0.000000   \n",
       "9    0.796203  0.177308  0.180361                   0.910296     0.088612   \n",
       "10   0.180932  0.239203  0.281093                   0.476267     0.414113   \n",
       "11   0.746699  0.221874  0.172101                   0.884964     0.104835   \n",
       "12   0.708238  0.039289  0.192864                   0.832247     0.120533   \n",
       "13   0.759275  0.117672  0.348243                   0.859624     0.151281   \n",
       "14   0.734341  0.212244  0.184847                   0.876952     0.112303   \n",
       "15   0.032162  0.644137  0.395792                   0.149959     0.784006   \n",
       "16   0.929437  0.030788  0.039176                   0.961233     0.011858   \n",
       "17   0.309006  0.181983  0.588884                   0.500712     0.470738   \n",
       "18   0.776195  0.025340  0.168686                   0.868081     0.093564   \n",
       "19   0.910705  0.047852  0.143099                   0.963078     0.052286   \n",
       "20   1.000000  0.005193  0.024192                   1.000000     0.000296   \n",
       "21   0.638123  0.147780  0.304033                   0.879514     0.184535   \n",
       "22   0.265679  0.155492  0.768694                   0.525848     0.570201   \n",
       "23   0.701493  0.035783  0.271819                   0.870198     0.136969   \n",
       "24   0.037521  0.410973  0.183254                   0.121111     0.565109   \n",
       "25   0.034828  0.858426  0.423979                   0.112276     0.827759   \n",
       "26   0.475351  0.113515  0.343857                   0.629219     0.271461   \n",
       "27   0.582977  0.247465  0.263660                   0.823804     0.173158   \n",
       "28   0.052330  0.463148  0.603172                   0.239494     0.865652   \n",
       "29   0.079862  0.585364  0.747049                   0.282110     0.781438   \n",
       "..        ...       ...       ...                        ...          ...   \n",
       "132  0.645853  0.135929  0.443657                   0.823416     0.217616   \n",
       "133  0.212732  0.397300  0.447082                   0.417542     0.474010   \n",
       "134  0.278409  0.000000  0.340610                   0.592376     0.352626   \n",
       "135  0.880541  0.084340  0.076190                   0.955531     0.039759   \n",
       "136  0.031826  0.594671  0.681899                   0.296255     1.000000   \n",
       "137  0.074071  0.460207  0.444862                   0.312196     0.636052   \n",
       "138  0.074672  0.719582  0.597443                   0.241884     0.754096   \n",
       "139  0.861733  0.066044  0.064422                   0.938579     0.039600   \n",
       "140  0.242339  0.239148  0.497708                   0.498061     0.479255   \n",
       "141  0.737837  0.123088  0.249290                   0.857726     0.113028   \n",
       "142  0.736400  0.088800  0.366964                   0.878258     0.161588   \n",
       "143  0.851731  0.048748  0.259864                   0.925294     0.096625   \n",
       "144  0.284387  0.146664  0.672039                   0.570640     0.514095   \n",
       "145  0.727530  0.049789  0.063248                   0.848463     0.070763   \n",
       "146  0.794043  0.027502  0.149330                   0.880099     0.082796   \n",
       "147  0.471033  0.240571  0.363636                   0.592830     0.277197   \n",
       "148  0.705738  0.058311  0.381418                   0.856901     0.176308   \n",
       "149  0.280717  0.160962  0.768933                   0.561061     0.557869   \n",
       "150  0.020219  0.554469  0.368241                   0.141403     0.833108   \n",
       "151  0.743322  0.083516  0.375759                   0.887884     0.165842   \n",
       "152  0.849902  0.019333  0.145730                   0.949844     0.070827   \n",
       "153  0.397566  0.320199  0.466986                   0.569552     0.348194   \n",
       "154  0.124393  0.248500  0.487117                   0.370300     0.549832   \n",
       "155  0.487581  0.123430  0.352985                   0.643946     0.266580   \n",
       "156  0.859038  0.087688  0.124883                   0.934718     0.061451   \n",
       "157  0.842537  0.110994  0.204451                   0.927244     0.086240   \n",
       "158  0.050335  0.567271  0.411831                   0.281598     0.670655   \n",
       "159  0.486603  0.134009  0.340928                   0.640326     0.263973   \n",
       "160  0.173193  0.210094  0.505773                   0.336097     0.543099   \n",
       "161  0.494194  0.147221  0.406913                   0.714284     0.248651   \n",
       "\n",
       "     sum variance  sum entropy   entropy  difference variance  \\\n",
       "0        0.503203     0.699561  0.680072             0.143376   \n",
       "1        0.222110     0.142707  0.124576             0.695182   \n",
       "2        0.229158     0.305093  0.272178             0.536824   \n",
       "3        0.340649     0.935801  0.905857             0.046132   \n",
       "4        0.058167     0.673827  0.645537             0.162975   \n",
       "5        0.176298     0.196664  0.177152             0.647691   \n",
       "6        0.002042     0.711789  0.647242             0.255335   \n",
       "7        0.177799     0.220557  0.198897             0.622483   \n",
       "8        0.012969     0.010677  0.008506             0.847751   \n",
       "9        0.179878     0.156350  0.132000             0.687980   \n",
       "10       0.280477     0.663436  0.601878             0.247823   \n",
       "11       0.171341     0.186406  0.160340             0.650283   \n",
       "12       0.193210     0.226917  0.204334             0.613916   \n",
       "13       0.348484     0.186493  0.168041             0.682123   \n",
       "14       0.184171     0.197792  0.170491             0.645881   \n",
       "15       0.393083     0.905366  0.885406             0.045673   \n",
       "16       0.039227     0.054511  0.049274             0.782016   \n",
       "17       0.589292     0.534461  0.512072             0.282558   \n",
       "18       0.169059     0.178687  0.161216             0.662719   \n",
       "19       0.143284     0.064152  0.054446             0.771295   \n",
       "20       0.024357     0.000000  0.000000             0.868280   \n",
       "21       0.304000     0.270962  0.214235             0.748563   \n",
       "22       0.769660     0.598892  0.547214             0.264344   \n",
       "23       0.272363     0.232108  0.194935             0.624206   \n",
       "24       0.181421     0.861132  0.854264             0.037339   \n",
       "25       0.420090     0.891780  0.897603             0.029799   \n",
       "26       0.344112     0.381336  0.372120             0.469400   \n",
       "27       0.262957     0.323813  0.270001             0.550242   \n",
       "28       0.601981     0.887251  0.830420             0.083958   \n",
       "29       0.745472     0.830760  0.789128             0.099432   \n",
       "..            ...          ...       ...                  ...   \n",
       "132      0.444006     0.275301  0.241708             0.568529   \n",
       "133      0.445922     0.659979  0.627627             0.185861   \n",
       "134      0.341517     0.604308  0.529951             0.399729   \n",
       "135      0.076012     0.085511  0.071197             0.944586   \n",
       "136      0.680121     0.903889  0.834994             0.108456   \n",
       "137      0.443332     0.846141  0.782075             0.115774   \n",
       "138      0.594751     0.860951  0.818228             0.081610   \n",
       "139      0.064324     0.102768  0.088436             0.758093   \n",
       "140      0.497580     0.623507  0.570164             0.235208   \n",
       "141      0.249277     0.209732  0.187314             0.626262   \n",
       "142      0.367415     0.201976  0.174083             0.652291   \n",
       "143      0.260306     0.116619  0.102781             0.716928   \n",
       "144      0.672840     0.576264  0.514959             0.313239   \n",
       "145      0.063242     0.193881  0.176635             0.654409   \n",
       "146      0.149647     0.162030  0.145990             0.682160   \n",
       "147      0.363198     0.389181  0.398795             0.398540   \n",
       "148      0.382078     0.230541  0.200624             0.618844   \n",
       "149      0.769868     0.583372  0.523030             0.292712   \n",
       "150      0.365991     0.933129  0.902192             0.047187   \n",
       "151      0.376260     0.191724  0.163524             0.659353   \n",
       "152      0.146087     0.107178  0.087951             0.862835   \n",
       "153      0.466319     0.466221  0.454695             0.355109   \n",
       "154      0.486911     0.801573  0.735678             0.145483   \n",
       "155      0.353203     0.371759  0.360644             0.455881   \n",
       "156      0.124796     0.103159  0.089044             0.749533   \n",
       "157      0.204407     0.116193  0.100923             0.717716   \n",
       "158      0.409605     0.884174  0.813312             0.105402   \n",
       "159      0.341058     0.371184  0.361974             0.466402   \n",
       "160      0.505831     0.700749  0.679332             0.150142   \n",
       "161      0.407114     0.400247  0.360798             0.444975   \n",
       "\n",
       "     difference entropy    mean_B    mean_G    mean_R     std_B     std_G  \\\n",
       "0              0.709940  0.313805  0.528787  0.614273  0.304604  0.615009   \n",
       "1              0.139885  0.220593  0.101461  0.053140  0.559716  0.442374   \n",
       "2              0.286056  0.298854  0.167377  0.074775  0.539028  0.447906   \n",
       "3              0.817664  0.265694  0.874486  0.759549  0.398753  0.512621   \n",
       "4              0.641177  0.170598  0.232265  0.307716  0.091011  0.135052   \n",
       "5              0.198023  0.176512  0.076325  0.152918  0.394871  0.249911   \n",
       "6              0.552105  0.231839  0.171394  0.286421  0.087317  0.000000   \n",
       "7              0.220909  0.225201  0.090681  0.143445  0.463693  0.267135   \n",
       "8              0.011066  0.058835  0.005192  0.000907  0.260821  0.170652   \n",
       "9              0.131606  0.225653  0.099282  0.044162  0.561475  0.415473   \n",
       "10             0.536012  0.124879  0.416336  0.442787  0.188226  0.449327   \n",
       "11             0.165443  0.211575  0.128075  0.035218  0.444714  0.439441   \n",
       "12             0.227441  0.196033  0.095771  0.170095  0.400597  0.273870   \n",
       "13             0.198418  0.239835  0.152197  0.131952  0.500756  0.535543   \n",
       "14             0.175686  0.223086  0.136636  0.037988  0.459744  0.455840   \n",
       "15             0.838216  0.267264  0.825950  0.716113  0.410896  0.566080   \n",
       "16             0.066333  0.081997  0.009346  0.026549  0.312601  0.146925   \n",
       "17             0.563096  0.413763  0.430469  0.534928  0.399168  0.659911   \n",
       "18             0.182666  0.167726  0.069320  0.146390  0.389611  0.240168   \n",
       "19             0.061737  0.169317  0.058562  0.028645  0.516078  0.360929   \n",
       "20             0.000000  0.069477  0.000000  0.011742  0.313507  0.153461   \n",
       "21             0.149985  0.398479  0.210074  0.071560  0.682240  0.573719   \n",
       "22             0.526277  0.652788  0.494717  0.669729  0.627026  0.731178   \n",
       "23             0.182920  0.301243  0.143018  0.089608  0.613827  0.458148   \n",
       "24             0.834893  0.149505  0.581961  0.565702  0.134371  0.340063   \n",
       "25             0.899544  0.316002  0.875428  0.738687  0.418568  0.599603   \n",
       "26             0.457843  0.414242  0.259100  0.252296  0.540759  0.500993   \n",
       "27             0.233951  0.389343  0.207296  0.041097  0.677191  0.551749   \n",
       "28             0.725498  0.742508  0.841126  0.848570  0.533037  0.695461   \n",
       "29             0.764286  0.632374  0.770294  0.750642  0.844418  0.764848   \n",
       "..                  ...       ...       ...       ...       ...       ...   \n",
       "132            0.250496  0.473873  0.236883  0.104340  0.838114  0.672522   \n",
       "133            0.646859  0.247395  0.519701  0.374571  0.354900  0.684364   \n",
       "134            0.440212  0.667015  0.338520  0.284144  0.703021  0.479525   \n",
       "135            0.069753  0.136550  0.054957  0.001686  0.398962  0.311373   \n",
       "136            0.708133  0.617055  0.985698  1.000000  0.877554  0.723824   \n",
       "137            0.676443  0.010460  0.674330  0.625163  0.059598  0.646336   \n",
       "138            0.773312  0.311437  0.756115  0.766888  0.520741  0.700660   \n",
       "139            0.095588  0.123677  0.055475  0.002988  0.341972  0.291142   \n",
       "140            0.546601  0.239183  0.517943  0.398800  0.357749  0.719585   \n",
       "141            0.213894  0.238091  0.112843  0.093472  0.549612  0.411648   \n",
       "142            0.174873  0.285335  0.145946  0.171685  0.585209  0.493819   \n",
       "143            0.118980  0.231058  0.104268  0.058751  0.603979  0.484588   \n",
       "144            0.471214  1.000000  0.481350  0.424212  1.000000  0.735300   \n",
       "145            0.209215  0.173089  0.086279  0.025816  0.325622  0.252005   \n",
       "146            0.168556  0.183661  0.062259  0.122114  0.439205  0.227237   \n",
       "147            0.530844  0.363709  0.259050  0.284365  0.446762  0.503644   \n",
       "148            0.202152  0.306789  0.160876  0.182036  0.597425  0.507315   \n",
       "149            0.481569  0.640075  0.484277  0.654803  0.626683  0.731693   \n",
       "150            0.812903  0.283739  0.874879  0.766307  0.431001  0.531658   \n",
       "151            0.161803  0.389260  0.185456  0.067530  0.806767  0.646458   \n",
       "152            0.079129  0.174678  0.089540  0.017940  0.451763  0.412236   \n",
       "153            0.541982  0.175946  0.320325  0.429330  0.192105  0.578639   \n",
       "154            0.644228  0.282172  0.545305  0.567497  0.433477  0.601541   \n",
       "155            0.442211  0.355406  0.248507  0.274784  0.440869  0.493297   \n",
       "156            0.100213  0.108491  0.074117  0.037926  0.282874  0.351699   \n",
       "157            0.112887  0.231374  0.096031  0.042288  0.606232  0.446972   \n",
       "158            0.674642  0.000000  0.714094  0.653454  0.000000  0.620931   \n",
       "159            0.446690  0.406217  0.251548  0.246625  0.540365  0.497705   \n",
       "160            0.702214  0.308823  0.517248  0.604296  0.302371  0.616105   \n",
       "161            0.384820  0.429429  0.265146  0.155253  0.662022  0.587674   \n",
       "\n",
       "        std_R  \n",
       "0    0.737568  \n",
       "1    0.309818  \n",
       "2    0.289288  \n",
       "3    0.594145  \n",
       "4    0.348236  \n",
       "5    0.468215  \n",
       "6    0.297518  \n",
       "7    0.421028  \n",
       "8    0.017506  \n",
       "9    0.177397  \n",
       "10   0.545056  \n",
       "11   0.162066  \n",
       "12   0.480086  \n",
       "13   0.451087  \n",
       "14   0.174449  \n",
       "15   0.619856  \n",
       "16   0.165443  \n",
       "17   0.783451  \n",
       "18   0.463173  \n",
       "19   0.163771  \n",
       "20   0.076231  \n",
       "21   0.182825  \n",
       "22   0.923630  \n",
       "23   0.387999  \n",
       "24   0.452158  \n",
       "25   0.630198  \n",
       "26   0.459192  \n",
       "27   0.188445  \n",
       "28   0.743058  \n",
       "29   0.864680  \n",
       "..        ...  \n",
       "132  0.406499  \n",
       "133  0.504045  \n",
       "134  0.442842  \n",
       "135  0.007778  \n",
       "136  0.827395  \n",
       "137  0.653199  \n",
       "138  0.771711  \n",
       "139  0.021512  \n",
       "140  0.548627  \n",
       "141  0.397622  \n",
       "142  0.516183  \n",
       "143  0.318007  \n",
       "144  0.614458  \n",
       "145  0.088513  \n",
       "146  0.403000  \n",
       "147  0.544987  \n",
       "148  0.525931  \n",
       "149  0.922313  \n",
       "150  0.613396  \n",
       "151  0.239361  \n",
       "152  0.115770  \n",
       "153  0.739005  \n",
       "154  0.699214  \n",
       "155  0.538858  \n",
       "156  0.183958  \n",
       "157  0.172812  \n",
       "158  0.626360  \n",
       "159  0.457404  \n",
       "160  0.740104  \n",
       "161  0.487641  \n",
       "\n",
       "[162 rows x 16 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      3\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      3\n",
       "5      3\n",
       "6      1\n",
       "7      3\n",
       "8      0\n",
       "9      0\n",
       "10     0\n",
       "11     0\n",
       "12     3\n",
       "13     0\n",
       "14     0\n",
       "15     0\n",
       "16     2\n",
       "17     1\n",
       "18     3\n",
       "19     0\n",
       "20     0\n",
       "21     0\n",
       "22     3\n",
       "23     0\n",
       "24     0\n",
       "25     0\n",
       "26     3\n",
       "27     0\n",
       "28     0\n",
       "29     0\n",
       "      ..\n",
       "132    0\n",
       "133    0\n",
       "134    3\n",
       "135    0\n",
       "136    0\n",
       "137    0\n",
       "138    0\n",
       "139    0\n",
       "140    0\n",
       "141    0\n",
       "142    2\n",
       "143    0\n",
       "144    3\n",
       "145    0\n",
       "146    3\n",
       "147    3\n",
       "148    2\n",
       "149    3\n",
       "150    0\n",
       "151    0\n",
       "152    0\n",
       "153    3\n",
       "154    0\n",
       "155    3\n",
       "156    0\n",
       "157    0\n",
       "158    0\n",
       "159    3\n",
       "160    3\n",
       "161    0\n",
       "Name: label, Length: 162, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy</th>\n",
       "      <th>contrast</th>\n",
       "      <th>variance</th>\n",
       "      <th>inverse difference moment</th>\n",
       "      <th>sum average</th>\n",
       "      <th>sum variance</th>\n",
       "      <th>sum entropy</th>\n",
       "      <th>entropy</th>\n",
       "      <th>difference variance</th>\n",
       "      <th>difference entropy</th>\n",
       "      <th>mean_B</th>\n",
       "      <th>mean_G</th>\n",
       "      <th>mean_R</th>\n",
       "      <th>std_B</th>\n",
       "      <th>std_G</th>\n",
       "      <th>std_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.912701</td>\n",
       "      <td>0.103995</td>\n",
       "      <td>0.057363</td>\n",
       "      <td>0.973406</td>\n",
       "      <td>0.026295</td>\n",
       "      <td>0.057030</td>\n",
       "      <td>0.060228</td>\n",
       "      <td>0.048115</td>\n",
       "      <td>0.987541</td>\n",
       "      <td>0.040413</td>\n",
       "      <td>0.111921</td>\n",
       "      <td>0.038536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.365689</td>\n",
       "      <td>0.274969</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.802899</td>\n",
       "      <td>0.131688</td>\n",
       "      <td>0.176016</td>\n",
       "      <td>0.897297</td>\n",
       "      <td>0.083034</td>\n",
       "      <td>0.175788</td>\n",
       "      <td>0.151498</td>\n",
       "      <td>0.134484</td>\n",
       "      <td>0.679371</td>\n",
       "      <td>0.157074</td>\n",
       "      <td>0.146306</td>\n",
       "      <td>0.093407</td>\n",
       "      <td>0.057747</td>\n",
       "      <td>0.366779</td>\n",
       "      <td>0.386870</td>\n",
       "      <td>0.294857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.654991</td>\n",
       "      <td>0.023718</td>\n",
       "      <td>0.268112</td>\n",
       "      <td>0.869235</td>\n",
       "      <td>0.167608</td>\n",
       "      <td>0.268718</td>\n",
       "      <td>0.252792</td>\n",
       "      <td>0.209413</td>\n",
       "      <td>0.614776</td>\n",
       "      <td>0.177381</td>\n",
       "      <td>0.323161</td>\n",
       "      <td>0.202048</td>\n",
       "      <td>0.050047</td>\n",
       "      <td>0.568116</td>\n",
       "      <td>0.568696</td>\n",
       "      <td>0.211591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.844038</td>\n",
       "      <td>0.050417</td>\n",
       "      <td>0.205173</td>\n",
       "      <td>0.962903</td>\n",
       "      <td>0.089557</td>\n",
       "      <td>0.205483</td>\n",
       "      <td>0.101417</td>\n",
       "      <td>0.076707</td>\n",
       "      <td>0.754815</td>\n",
       "      <td>0.055386</td>\n",
       "      <td>0.230158</td>\n",
       "      <td>0.110132</td>\n",
       "      <td>0.020558</td>\n",
       "      <td>0.574570</td>\n",
       "      <td>0.489568</td>\n",
       "      <td>0.154522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.037351</td>\n",
       "      <td>0.704891</td>\n",
       "      <td>0.516688</td>\n",
       "      <td>0.168996</td>\n",
       "      <td>0.830211</td>\n",
       "      <td>0.513899</td>\n",
       "      <td>0.925518</td>\n",
       "      <td>0.883008</td>\n",
       "      <td>0.053791</td>\n",
       "      <td>0.806301</td>\n",
       "      <td>0.340693</td>\n",
       "      <td>0.834916</td>\n",
       "      <td>0.837268</td>\n",
       "      <td>0.529395</td>\n",
       "      <td>0.631379</td>\n",
       "      <td>0.728693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.009876</td>\n",
       "      <td>0.422267</td>\n",
       "      <td>0.353680</td>\n",
       "      <td>0.220852</td>\n",
       "      <td>0.934069</td>\n",
       "      <td>0.352165</td>\n",
       "      <td>0.945251</td>\n",
       "      <td>0.855314</td>\n",
       "      <td>0.097865</td>\n",
       "      <td>0.627474</td>\n",
       "      <td>0.447481</td>\n",
       "      <td>0.972793</td>\n",
       "      <td>0.842667</td>\n",
       "      <td>0.621903</td>\n",
       "      <td>0.510829</td>\n",
       "      <td>0.576742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.507251</td>\n",
       "      <td>0.153106</td>\n",
       "      <td>0.355712</td>\n",
       "      <td>0.656894</td>\n",
       "      <td>0.262457</td>\n",
       "      <td>0.355764</td>\n",
       "      <td>0.351175</td>\n",
       "      <td>0.342577</td>\n",
       "      <td>0.472403</td>\n",
       "      <td>0.427251</td>\n",
       "      <td>0.341421</td>\n",
       "      <td>0.244177</td>\n",
       "      <td>0.274670</td>\n",
       "      <td>0.435213</td>\n",
       "      <td>0.495676</td>\n",
       "      <td>0.540223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.715721</td>\n",
       "      <td>0.074629</td>\n",
       "      <td>0.287857</td>\n",
       "      <td>0.865516</td>\n",
       "      <td>0.145956</td>\n",
       "      <td>0.288212</td>\n",
       "      <td>0.218153</td>\n",
       "      <td>0.188595</td>\n",
       "      <td>0.626046</td>\n",
       "      <td>0.193984</td>\n",
       "      <td>0.350272</td>\n",
       "      <td>0.162270</td>\n",
       "      <td>0.063109</td>\n",
       "      <td>0.710056</td>\n",
       "      <td>0.531423</td>\n",
       "      <td>0.248220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.328106</td>\n",
       "      <td>0.049275</td>\n",
       "      <td>0.409954</td>\n",
       "      <td>0.619402</td>\n",
       "      <td>0.367306</td>\n",
       "      <td>0.410731</td>\n",
       "      <td>0.548129</td>\n",
       "      <td>0.485241</td>\n",
       "      <td>0.409449</td>\n",
       "      <td>0.428987</td>\n",
       "      <td>0.398853</td>\n",
       "      <td>0.325164</td>\n",
       "      <td>0.430801</td>\n",
       "      <td>0.428924</td>\n",
       "      <td>0.489261</td>\n",
       "      <td>0.685704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.971210</td>\n",
       "      <td>0.022061</td>\n",
       "      <td>0.130377</td>\n",
       "      <td>0.994994</td>\n",
       "      <td>0.033170</td>\n",
       "      <td>0.130683</td>\n",
       "      <td>0.021014</td>\n",
       "      <td>0.015535</td>\n",
       "      <td>0.821306</td>\n",
       "      <td>0.011573</td>\n",
       "      <td>0.125511</td>\n",
       "      <td>0.038168</td>\n",
       "      <td>0.021424</td>\n",
       "      <td>0.476160</td>\n",
       "      <td>0.352179</td>\n",
       "      <td>0.169903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.673622</td>\n",
       "      <td>0.236813</td>\n",
       "      <td>0.206139</td>\n",
       "      <td>0.811437</td>\n",
       "      <td>0.139913</td>\n",
       "      <td>0.205368</td>\n",
       "      <td>0.233830</td>\n",
       "      <td>0.216615</td>\n",
       "      <td>0.573074</td>\n",
       "      <td>0.271532</td>\n",
       "      <td>0.141284</td>\n",
       "      <td>0.169710</td>\n",
       "      <td>0.074488</td>\n",
       "      <td>0.268916</td>\n",
       "      <td>0.480453</td>\n",
       "      <td>0.260380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.880415</td>\n",
       "      <td>0.051604</td>\n",
       "      <td>0.117267</td>\n",
       "      <td>0.942785</td>\n",
       "      <td>0.054652</td>\n",
       "      <td>0.117372</td>\n",
       "      <td>0.087996</td>\n",
       "      <td>0.076518</td>\n",
       "      <td>0.742533</td>\n",
       "      <td>0.085906</td>\n",
       "      <td>0.148910</td>\n",
       "      <td>0.057173</td>\n",
       "      <td>0.045037</td>\n",
       "      <td>0.411167</td>\n",
       "      <td>0.300986</td>\n",
       "      <td>0.174222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.801684</td>\n",
       "      <td>0.024262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.915328</td>\n",
       "      <td>0.026728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132504</td>\n",
       "      <td>0.113929</td>\n",
       "      <td>0.760796</td>\n",
       "      <td>0.122401</td>\n",
       "      <td>0.086998</td>\n",
       "      <td>0.039078</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.192364</td>\n",
       "      <td>0.138401</td>\n",
       "      <td>0.026030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.811920</td>\n",
       "      <td>0.410706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.901127</td>\n",
       "      <td>0.407058</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.970119</td>\n",
       "      <td>0.728078</td>\n",
       "      <td>0.891336</td>\n",
       "      <td>0.855435</td>\n",
       "      <td>0.772312</td>\n",
       "      <td>0.459785</td>\n",
       "      <td>0.682910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.843534</td>\n",
       "      <td>0.069507</td>\n",
       "      <td>0.259898</td>\n",
       "      <td>0.921249</td>\n",
       "      <td>0.099657</td>\n",
       "      <td>0.260220</td>\n",
       "      <td>0.122099</td>\n",
       "      <td>0.107735</td>\n",
       "      <td>0.710995</td>\n",
       "      <td>0.124364</td>\n",
       "      <td>0.240255</td>\n",
       "      <td>0.108289</td>\n",
       "      <td>0.057490</td>\n",
       "      <td>0.613340</td>\n",
       "      <td>0.486935</td>\n",
       "      <td>0.315547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.140590</td>\n",
       "      <td>0.316887</td>\n",
       "      <td>0.334944</td>\n",
       "      <td>0.444251</td>\n",
       "      <td>0.499718</td>\n",
       "      <td>0.333999</td>\n",
       "      <td>0.712943</td>\n",
       "      <td>0.642178</td>\n",
       "      <td>0.214201</td>\n",
       "      <td>0.548127</td>\n",
       "      <td>0.127916</td>\n",
       "      <td>0.502639</td>\n",
       "      <td>0.532559</td>\n",
       "      <td>0.197047</td>\n",
       "      <td>0.506081</td>\n",
       "      <td>0.593324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.032007</td>\n",
       "      <td>0.147267</td>\n",
       "      <td>0.970536</td>\n",
       "      <td>0.051183</td>\n",
       "      <td>0.147553</td>\n",
       "      <td>0.064473</td>\n",
       "      <td>0.052746</td>\n",
       "      <td>0.782980</td>\n",
       "      <td>0.050377</td>\n",
       "      <td>0.165452</td>\n",
       "      <td>0.060708</td>\n",
       "      <td>0.020644</td>\n",
       "      <td>0.521208</td>\n",
       "      <td>0.386048</td>\n",
       "      <td>0.144966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.848981</td>\n",
       "      <td>0.071954</td>\n",
       "      <td>0.172494</td>\n",
       "      <td>0.923166</td>\n",
       "      <td>0.078513</td>\n",
       "      <td>0.172605</td>\n",
       "      <td>0.111210</td>\n",
       "      <td>0.097702</td>\n",
       "      <td>0.719215</td>\n",
       "      <td>0.113572</td>\n",
       "      <td>0.198191</td>\n",
       "      <td>0.069739</td>\n",
       "      <td>0.085985</td>\n",
       "      <td>0.495080</td>\n",
       "      <td>0.312069</td>\n",
       "      <td>0.325535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.954383</td>\n",
       "      <td>0.054051</td>\n",
       "      <td>0.066594</td>\n",
       "      <td>0.986426</td>\n",
       "      <td>0.021105</td>\n",
       "      <td>0.066571</td>\n",
       "      <td>0.033350</td>\n",
       "      <td>0.026036</td>\n",
       "      <td>0.817499</td>\n",
       "      <td>0.023627</td>\n",
       "      <td>0.112506</td>\n",
       "      <td>0.026828</td>\n",
       "      <td>0.009726</td>\n",
       "      <td>0.414651</td>\n",
       "      <td>0.261029</td>\n",
       "      <td>0.081890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.587120</td>\n",
       "      <td>0.191977</td>\n",
       "      <td>0.251218</td>\n",
       "      <td>0.780205</td>\n",
       "      <td>0.180097</td>\n",
       "      <td>0.250809</td>\n",
       "      <td>0.302527</td>\n",
       "      <td>0.269404</td>\n",
       "      <td>0.525626</td>\n",
       "      <td>0.294182</td>\n",
       "      <td>0.265157</td>\n",
       "      <td>0.199069</td>\n",
       "      <td>0.114448</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.470486</td>\n",
       "      <td>0.359641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.217640</td>\n",
       "      <td>0.240444</td>\n",
       "      <td>0.485385</td>\n",
       "      <td>0.472427</td>\n",
       "      <td>0.491405</td>\n",
       "      <td>0.485222</td>\n",
       "      <td>0.656693</td>\n",
       "      <td>0.601077</td>\n",
       "      <td>0.216915</td>\n",
       "      <td>0.567732</td>\n",
       "      <td>0.249824</td>\n",
       "      <td>0.529215</td>\n",
       "      <td>0.411167</td>\n",
       "      <td>0.356654</td>\n",
       "      <td>0.709945</td>\n",
       "      <td>0.542708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.260285</td>\n",
       "      <td>0.006904</td>\n",
       "      <td>0.391357</td>\n",
       "      <td>0.582404</td>\n",
       "      <td>0.386956</td>\n",
       "      <td>0.392338</td>\n",
       "      <td>0.630229</td>\n",
       "      <td>0.550682</td>\n",
       "      <td>0.364547</td>\n",
       "      <td>0.446804</td>\n",
       "      <td>0.422132</td>\n",
       "      <td>0.344042</td>\n",
       "      <td>0.448278</td>\n",
       "      <td>0.419722</td>\n",
       "      <td>0.473452</td>\n",
       "      <td>0.672721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.171980</td>\n",
       "      <td>0.197873</td>\n",
       "      <td>0.387828</td>\n",
       "      <td>0.340331</td>\n",
       "      <td>0.477394</td>\n",
       "      <td>0.387692</td>\n",
       "      <td>0.694496</td>\n",
       "      <td>0.672813</td>\n",
       "      <td>0.159429</td>\n",
       "      <td>0.697615</td>\n",
       "      <td>0.929689</td>\n",
       "      <td>0.522162</td>\n",
       "      <td>0.216727</td>\n",
       "      <td>0.777439</td>\n",
       "      <td>0.618846</td>\n",
       "      <td>0.340381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.896178</td>\n",
       "      <td>0.063057</td>\n",
       "      <td>0.135481</td>\n",
       "      <td>0.969489</td>\n",
       "      <td>0.052887</td>\n",
       "      <td>0.135560</td>\n",
       "      <td>0.076344</td>\n",
       "      <td>0.059401</td>\n",
       "      <td>0.869805</td>\n",
       "      <td>0.047101</td>\n",
       "      <td>0.147634</td>\n",
       "      <td>0.064569</td>\n",
       "      <td>0.021641</td>\n",
       "      <td>0.444405</td>\n",
       "      <td>0.372508</td>\n",
       "      <td>0.142865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.293539</td>\n",
       "      <td>0.250586</td>\n",
       "      <td>0.745285</td>\n",
       "      <td>0.589536</td>\n",
       "      <td>0.498973</td>\n",
       "      <td>0.745647</td>\n",
       "      <td>0.599466</td>\n",
       "      <td>0.531970</td>\n",
       "      <td>0.305995</td>\n",
       "      <td>0.482356</td>\n",
       "      <td>0.257551</td>\n",
       "      <td>0.484984</td>\n",
       "      <td>0.541190</td>\n",
       "      <td>0.579617</td>\n",
       "      <td>0.803037</td>\n",
       "      <td>0.856679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.031995</td>\n",
       "      <td>0.874942</td>\n",
       "      <td>0.399836</td>\n",
       "      <td>0.139135</td>\n",
       "      <td>0.804057</td>\n",
       "      <td>0.395797</td>\n",
       "      <td>0.906055</td>\n",
       "      <td>0.891244</td>\n",
       "      <td>0.041939</td>\n",
       "      <td>0.852812</td>\n",
       "      <td>0.290984</td>\n",
       "      <td>0.847244</td>\n",
       "      <td>0.730920</td>\n",
       "      <td>0.426295</td>\n",
       "      <td>0.570417</td>\n",
       "      <td>0.621260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.899593</td>\n",
       "      <td>0.053779</td>\n",
       "      <td>0.158514</td>\n",
       "      <td>0.937548</td>\n",
       "      <td>0.058574</td>\n",
       "      <td>0.158699</td>\n",
       "      <td>0.082211</td>\n",
       "      <td>0.075743</td>\n",
       "      <td>0.747268</td>\n",
       "      <td>0.098770</td>\n",
       "      <td>0.142637</td>\n",
       "      <td>0.054676</td>\n",
       "      <td>0.066041</td>\n",
       "      <td>0.420517</td>\n",
       "      <td>0.324368</td>\n",
       "      <td>0.275003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.758134</td>\n",
       "      <td>0.109442</td>\n",
       "      <td>0.189716</td>\n",
       "      <td>0.897108</td>\n",
       "      <td>0.109560</td>\n",
       "      <td>0.189649</td>\n",
       "      <td>0.172731</td>\n",
       "      <td>0.147778</td>\n",
       "      <td>0.661098</td>\n",
       "      <td>0.153561</td>\n",
       "      <td>0.233146</td>\n",
       "      <td>0.117561</td>\n",
       "      <td>0.071364</td>\n",
       "      <td>0.483006</td>\n",
       "      <td>0.396386</td>\n",
       "      <td>0.262710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.163818</td>\n",
       "      <td>0.135848</td>\n",
       "      <td>0.718995</td>\n",
       "      <td>0.542462</td>\n",
       "      <td>0.671649</td>\n",
       "      <td>0.719964</td>\n",
       "      <td>0.716340</td>\n",
       "      <td>0.624908</td>\n",
       "      <td>0.261304</td>\n",
       "      <td>0.490682</td>\n",
       "      <td>0.860006</td>\n",
       "      <td>0.623702</td>\n",
       "      <td>0.665884</td>\n",
       "      <td>0.776326</td>\n",
       "      <td>0.741387</td>\n",
       "      <td>0.779577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.038905</td>\n",
       "      <td>0.586514</td>\n",
       "      <td>0.503882</td>\n",
       "      <td>0.164647</td>\n",
       "      <td>0.816463</td>\n",
       "      <td>0.501751</td>\n",
       "      <td>0.919728</td>\n",
       "      <td>0.880194</td>\n",
       "      <td>0.051927</td>\n",
       "      <td>0.808667</td>\n",
       "      <td>0.311832</td>\n",
       "      <td>0.825653</td>\n",
       "      <td>0.818722</td>\n",
       "      <td>0.493654</td>\n",
       "      <td>0.626898</td>\n",
       "      <td>0.716824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.920701</td>\n",
       "      <td>0.040314</td>\n",
       "      <td>0.092649</td>\n",
       "      <td>0.970882</td>\n",
       "      <td>0.035811</td>\n",
       "      <td>0.092764</td>\n",
       "      <td>0.055561</td>\n",
       "      <td>0.046131</td>\n",
       "      <td>0.782385</td>\n",
       "      <td>0.050987</td>\n",
       "      <td>0.139915</td>\n",
       "      <td>0.044773</td>\n",
       "      <td>0.011418</td>\n",
       "      <td>0.448850</td>\n",
       "      <td>0.308036</td>\n",
       "      <td>0.097947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.726078</td>\n",
       "      <td>0.115909</td>\n",
       "      <td>0.300091</td>\n",
       "      <td>0.884202</td>\n",
       "      <td>0.149577</td>\n",
       "      <td>0.300234</td>\n",
       "      <td>0.202148</td>\n",
       "      <td>0.172830</td>\n",
       "      <td>0.649604</td>\n",
       "      <td>0.174849</td>\n",
       "      <td>0.322473</td>\n",
       "      <td>0.177353</td>\n",
       "      <td>0.046490</td>\n",
       "      <td>0.668801</td>\n",
       "      <td>0.601540</td>\n",
       "      <td>0.225496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.807777</td>\n",
       "      <td>0.116304</td>\n",
       "      <td>0.218959</td>\n",
       "      <td>0.917608</td>\n",
       "      <td>0.099300</td>\n",
       "      <td>0.218917</td>\n",
       "      <td>0.146716</td>\n",
       "      <td>0.124237</td>\n",
       "      <td>0.703470</td>\n",
       "      <td>0.126164</td>\n",
       "      <td>0.241203</td>\n",
       "      <td>0.119873</td>\n",
       "      <td>0.028485</td>\n",
       "      <td>0.595669</td>\n",
       "      <td>0.503300</td>\n",
       "      <td>0.167518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.749143</td>\n",
       "      <td>0.094078</td>\n",
       "      <td>0.381677</td>\n",
       "      <td>0.889109</td>\n",
       "      <td>0.162363</td>\n",
       "      <td>0.382130</td>\n",
       "      <td>0.186939</td>\n",
       "      <td>0.160144</td>\n",
       "      <td>0.671443</td>\n",
       "      <td>0.160701</td>\n",
       "      <td>0.230659</td>\n",
       "      <td>0.140920</td>\n",
       "      <td>0.199346</td>\n",
       "      <td>0.511220</td>\n",
       "      <td>0.489412</td>\n",
       "      <td>0.576189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.159620</td>\n",
       "      <td>0.318122</td>\n",
       "      <td>0.700541</td>\n",
       "      <td>0.396494</td>\n",
       "      <td>0.681425</td>\n",
       "      <td>0.700410</td>\n",
       "      <td>0.716595</td>\n",
       "      <td>0.662927</td>\n",
       "      <td>0.179710</td>\n",
       "      <td>0.615511</td>\n",
       "      <td>0.617823</td>\n",
       "      <td>0.688062</td>\n",
       "      <td>0.603715</td>\n",
       "      <td>0.690891</td>\n",
       "      <td>0.809813</td>\n",
       "      <td>0.692345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.026085</td>\n",
       "      <td>0.312549</td>\n",
       "      <td>0.024595</td>\n",
       "      <td>0.414045</td>\n",
       "      <td>0.321003</td>\n",
       "      <td>0.022976</td>\n",
       "      <td>0.828106</td>\n",
       "      <td>0.741574</td>\n",
       "      <td>0.183148</td>\n",
       "      <td>0.573303</td>\n",
       "      <td>0.382859</td>\n",
       "      <td>0.265135</td>\n",
       "      <td>0.416812</td>\n",
       "      <td>0.173793</td>\n",
       "      <td>0.031885</td>\n",
       "      <td>0.333213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.119864</td>\n",
       "      <td>0.390216</td>\n",
       "      <td>0.525686</td>\n",
       "      <td>0.407587</td>\n",
       "      <td>0.664672</td>\n",
       "      <td>0.524744</td>\n",
       "      <td>0.749218</td>\n",
       "      <td>0.676693</td>\n",
       "      <td>0.205149</td>\n",
       "      <td>0.566305</td>\n",
       "      <td>0.618787</td>\n",
       "      <td>0.681682</td>\n",
       "      <td>0.561207</td>\n",
       "      <td>0.671038</td>\n",
       "      <td>0.686257</td>\n",
       "      <td>0.585089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.267379</td>\n",
       "      <td>0.604305</td>\n",
       "      <td>0.411300</td>\n",
       "      <td>0.448197</td>\n",
       "      <td>0.412848</td>\n",
       "      <td>0.408858</td>\n",
       "      <td>0.563737</td>\n",
       "      <td>0.556675</td>\n",
       "      <td>0.214612</td>\n",
       "      <td>0.661302</td>\n",
       "      <td>0.244477</td>\n",
       "      <td>0.476542</td>\n",
       "      <td>0.266252</td>\n",
       "      <td>0.389821</td>\n",
       "      <td>0.677589</td>\n",
       "      <td>0.456193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.893015</td>\n",
       "      <td>0.105256</td>\n",
       "      <td>0.098113</td>\n",
       "      <td>0.957846</td>\n",
       "      <td>0.040973</td>\n",
       "      <td>0.097863</td>\n",
       "      <td>0.077010</td>\n",
       "      <td>0.063731</td>\n",
       "      <td>0.853903</td>\n",
       "      <td>0.068592</td>\n",
       "      <td>0.145840</td>\n",
       "      <td>0.054063</td>\n",
       "      <td>0.005795</td>\n",
       "      <td>0.464688</td>\n",
       "      <td>0.339510</td>\n",
       "      <td>0.040803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.727275</td>\n",
       "      <td>0.164323</td>\n",
       "      <td>0.273176</td>\n",
       "      <td>0.869686</td>\n",
       "      <td>0.143265</td>\n",
       "      <td>0.272977</td>\n",
       "      <td>0.204996</td>\n",
       "      <td>0.177072</td>\n",
       "      <td>0.746733</td>\n",
       "      <td>0.177171</td>\n",
       "      <td>0.218874</td>\n",
       "      <td>0.148886</td>\n",
       "      <td>0.117074</td>\n",
       "      <td>0.421086</td>\n",
       "      <td>0.477927</td>\n",
       "      <td>0.403525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       energy  contrast  variance  inverse difference moment  sum average  \\\n",
       "162  0.912701  0.103995  0.057363                   0.973406     0.026295   \n",
       "163  0.802899  0.131688  0.176016                   0.897297     0.083034   \n",
       "164  0.654991  0.023718  0.268112                   0.869235     0.167608   \n",
       "165  0.844038  0.050417  0.205173                   0.962903     0.089557   \n",
       "166  0.037351  0.704891  0.516688                   0.168996     0.830211   \n",
       "167  0.009876  0.422267  0.353680                   0.220852     0.934069   \n",
       "168  0.507251  0.153106  0.355712                   0.656894     0.262457   \n",
       "169  0.715721  0.074629  0.287857                   0.865516     0.145956   \n",
       "170  0.328106  0.049275  0.409954                   0.619402     0.367306   \n",
       "171  0.971210  0.022061  0.130377                   0.994994     0.033170   \n",
       "172  0.673622  0.236813  0.206139                   0.811437     0.139913   \n",
       "173  0.880415  0.051604  0.117267                   0.942785     0.054652   \n",
       "174  0.801684  0.024262  0.000000                   0.915328     0.026728   \n",
       "175  0.000000  0.811920  0.410706                   0.000000     0.901127   \n",
       "176  0.843534  0.069507  0.259898                   0.921249     0.099657   \n",
       "177  0.140590  0.316887  0.334944                   0.444251     0.499718   \n",
       "178  0.915000  0.032007  0.147267                   0.970536     0.051183   \n",
       "179  0.848981  0.071954  0.172494                   0.923166     0.078513   \n",
       "180  0.954383  0.054051  0.066594                   0.986426     0.021105   \n",
       "181  0.587120  0.191977  0.251218                   0.780205     0.180097   \n",
       "182  0.217640  0.240444  0.485385                   0.472427     0.491405   \n",
       "183  0.260285  0.006904  0.391357                   0.582404     0.386956   \n",
       "184  0.171980  0.197873  0.387828                   0.340331     0.477394   \n",
       "185  0.896178  0.063057  0.135481                   0.969489     0.052887   \n",
       "186  0.293539  0.250586  0.745285                   0.589536     0.498973   \n",
       "187  0.031995  0.874942  0.399836                   0.139135     0.804057   \n",
       "188  0.899593  0.053779  0.158514                   0.937548     0.058574   \n",
       "189  0.758134  0.109442  0.189716                   0.897108     0.109560   \n",
       "190  0.163818  0.135848  0.718995                   0.542462     0.671649   \n",
       "191  0.038905  0.586514  0.503882                   0.164647     0.816463   \n",
       "192  0.920701  0.040314  0.092649                   0.970882     0.035811   \n",
       "193  0.726078  0.115909  0.300091                   0.884202     0.149577   \n",
       "194  0.807777  0.116304  0.218959                   0.917608     0.099300   \n",
       "195  0.749143  0.094078  0.381677                   0.889109     0.162363   \n",
       "196  0.159620  0.318122  0.700541                   0.396494     0.681425   \n",
       "197  0.026085  0.312549  0.024595                   0.414045     0.321003   \n",
       "198  0.119864  0.390216  0.525686                   0.407587     0.664672   \n",
       "199  0.267379  0.604305  0.411300                   0.448197     0.412848   \n",
       "200  0.893015  0.105256  0.098113                   0.957846     0.040973   \n",
       "201  0.727275  0.164323  0.273176                   0.869686     0.143265   \n",
       "\n",
       "     sum variance  sum entropy   entropy  difference variance  \\\n",
       "162      0.057030     0.060228  0.048115             0.987541   \n",
       "163      0.175788     0.151498  0.134484             0.679371   \n",
       "164      0.268718     0.252792  0.209413             0.614776   \n",
       "165      0.205483     0.101417  0.076707             0.754815   \n",
       "166      0.513899     0.925518  0.883008             0.053791   \n",
       "167      0.352165     0.945251  0.855314             0.097865   \n",
       "168      0.355764     0.351175  0.342577             0.472403   \n",
       "169      0.288212     0.218153  0.188595             0.626046   \n",
       "170      0.410731     0.548129  0.485241             0.409449   \n",
       "171      0.130683     0.021014  0.015535             0.821306   \n",
       "172      0.205368     0.233830  0.216615             0.573074   \n",
       "173      0.117372     0.087996  0.076518             0.742533   \n",
       "174      0.000000     0.132504  0.113929             0.760796   \n",
       "175      0.407058     1.000000  1.000000             0.000000   \n",
       "176      0.260220     0.122099  0.107735             0.710995   \n",
       "177      0.333999     0.712943  0.642178             0.214201   \n",
       "178      0.147553     0.064473  0.052746             0.782980   \n",
       "179      0.172605     0.111210  0.097702             0.719215   \n",
       "180      0.066571     0.033350  0.026036             0.817499   \n",
       "181      0.250809     0.302527  0.269404             0.525626   \n",
       "182      0.485222     0.656693  0.601077             0.216915   \n",
       "183      0.392338     0.630229  0.550682             0.364547   \n",
       "184      0.387692     0.694496  0.672813             0.159429   \n",
       "185      0.135560     0.076344  0.059401             0.869805   \n",
       "186      0.745647     0.599466  0.531970             0.305995   \n",
       "187      0.395797     0.906055  0.891244             0.041939   \n",
       "188      0.158699     0.082211  0.075743             0.747268   \n",
       "189      0.189649     0.172731  0.147778             0.661098   \n",
       "190      0.719964     0.716340  0.624908             0.261304   \n",
       "191      0.501751     0.919728  0.880194             0.051927   \n",
       "192      0.092764     0.055561  0.046131             0.782385   \n",
       "193      0.300234     0.202148  0.172830             0.649604   \n",
       "194      0.218917     0.146716  0.124237             0.703470   \n",
       "195      0.382130     0.186939  0.160144             0.671443   \n",
       "196      0.700410     0.716595  0.662927             0.179710   \n",
       "197      0.022976     0.828106  0.741574             0.183148   \n",
       "198      0.524744     0.749218  0.676693             0.205149   \n",
       "199      0.408858     0.563737  0.556675             0.214612   \n",
       "200      0.097863     0.077010  0.063731             0.853903   \n",
       "201      0.272977     0.204996  0.177072             0.746733   \n",
       "\n",
       "     difference entropy    mean_B    mean_G    mean_R     std_B     std_G  \\\n",
       "162            0.040413  0.111921  0.038536  0.000000  0.365689  0.274969   \n",
       "163            0.157074  0.146306  0.093407  0.057747  0.366779  0.386870   \n",
       "164            0.177381  0.323161  0.202048  0.050047  0.568116  0.568696   \n",
       "165            0.055386  0.230158  0.110132  0.020558  0.574570  0.489568   \n",
       "166            0.806301  0.340693  0.834916  0.837268  0.529395  0.631379   \n",
       "167            0.627474  0.447481  0.972793  0.842667  0.621903  0.510829   \n",
       "168            0.427251  0.341421  0.244177  0.274670  0.435213  0.495676   \n",
       "169            0.193984  0.350272  0.162270  0.063109  0.710056  0.531423   \n",
       "170            0.428987  0.398853  0.325164  0.430801  0.428924  0.489261   \n",
       "171            0.011573  0.125511  0.038168  0.021424  0.476160  0.352179   \n",
       "172            0.271532  0.141284  0.169710  0.074488  0.268916  0.480453   \n",
       "173            0.085906  0.148910  0.057173  0.045037  0.411167  0.300986   \n",
       "174            0.122401  0.086998  0.039078  0.006200  0.192364  0.138401   \n",
       "175            0.970119  0.728078  0.891336  0.855435  0.772312  0.459785   \n",
       "176            0.124364  0.240255  0.108289  0.057490  0.613340  0.486935   \n",
       "177            0.548127  0.127916  0.502639  0.532559  0.197047  0.506081   \n",
       "178            0.050377  0.165452  0.060708  0.020644  0.521208  0.386048   \n",
       "179            0.113572  0.198191  0.069739  0.085985  0.495080  0.312069   \n",
       "180            0.023627  0.112506  0.026828  0.009726  0.414651  0.261029   \n",
       "181            0.294182  0.265157  0.199069  0.114448  0.417356  0.470486   \n",
       "182            0.567732  0.249824  0.529215  0.411167  0.356654  0.709945   \n",
       "183            0.446804  0.422132  0.344042  0.448278  0.419722  0.473452   \n",
       "184            0.697615  0.929689  0.522162  0.216727  0.777439  0.618846   \n",
       "185            0.047101  0.147634  0.064569  0.021641  0.444405  0.372508   \n",
       "186            0.482356  0.257551  0.484984  0.541190  0.579617  0.803037   \n",
       "187            0.852812  0.290984  0.847244  0.730920  0.426295  0.570417   \n",
       "188            0.098770  0.142637  0.054676  0.066041  0.420517  0.324368   \n",
       "189            0.153561  0.233146  0.117561  0.071364  0.483006  0.396386   \n",
       "190            0.490682  0.860006  0.623702  0.665884  0.776326  0.741387   \n",
       "191            0.808667  0.311832  0.825653  0.818722  0.493654  0.626898   \n",
       "192            0.050987  0.139915  0.044773  0.011418  0.448850  0.308036   \n",
       "193            0.174849  0.322473  0.177353  0.046490  0.668801  0.601540   \n",
       "194            0.126164  0.241203  0.119873  0.028485  0.595669  0.503300   \n",
       "195            0.160701  0.230659  0.140920  0.199346  0.511220  0.489412   \n",
       "196            0.615511  0.617823  0.688062  0.603715  0.690891  0.809813   \n",
       "197            0.573303  0.382859  0.265135  0.416812  0.173793  0.031885   \n",
       "198            0.566305  0.618787  0.681682  0.561207  0.671038  0.686257   \n",
       "199            0.661302  0.244477  0.476542  0.266252  0.389821  0.677589   \n",
       "200            0.068592  0.145840  0.054063  0.005795  0.464688  0.339510   \n",
       "201            0.177171  0.218874  0.148886  0.117074  0.421086  0.477927   \n",
       "\n",
       "        std_R  \n",
       "162  0.000000  \n",
       "163  0.294857  \n",
       "164  0.211591  \n",
       "165  0.154522  \n",
       "166  0.728693  \n",
       "167  0.576742  \n",
       "168  0.540223  \n",
       "169  0.248220  \n",
       "170  0.685704  \n",
       "171  0.169903  \n",
       "172  0.260380  \n",
       "173  0.174222  \n",
       "174  0.026030  \n",
       "175  0.682910  \n",
       "176  0.315547  \n",
       "177  0.593324  \n",
       "178  0.144966  \n",
       "179  0.325535  \n",
       "180  0.081890  \n",
       "181  0.359641  \n",
       "182  0.542708  \n",
       "183  0.672721  \n",
       "184  0.340381  \n",
       "185  0.142865  \n",
       "186  0.856679  \n",
       "187  0.621260  \n",
       "188  0.275003  \n",
       "189  0.262710  \n",
       "190  0.779577  \n",
       "191  0.716824  \n",
       "192  0.097947  \n",
       "193  0.225496  \n",
       "194  0.167518  \n",
       "195  0.576189  \n",
       "196  0.692345  \n",
       "197  0.333213  \n",
       "198  0.585089  \n",
       "199  0.456193  \n",
       "200  0.040803  \n",
       "201  0.403525  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162    0\n",
       "163    0\n",
       "164    0\n",
       "165    0\n",
       "166    0\n",
       "167    0\n",
       "168    3\n",
       "169    0\n",
       "170    3\n",
       "171    0\n",
       "172    0\n",
       "173    0\n",
       "174    0\n",
       "175    0\n",
       "176    0\n",
       "177    0\n",
       "178    0\n",
       "179    0\n",
       "180    0\n",
       "181    0\n",
       "182    0\n",
       "183    3\n",
       "184    3\n",
       "185    0\n",
       "186    0\n",
       "187    0\n",
       "188    0\n",
       "189    0\n",
       "190    2\n",
       "191    0\n",
       "192    0\n",
       "193    0\n",
       "194    0\n",
       "195    2\n",
       "196    0\n",
       "197    1\n",
       "198    0\n",
       "199    0\n",
       "200    0\n",
       "201    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Step is the model Selection\n",
    "\n",
    "#### Training \n",
    "\n",
    "#### Evaluation\n",
    "\n",
    "#### Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "####  Support Vector machine works well for multiclass classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing of the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of the trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 82.50\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Hyper-Parameter Tuning\n",
    "\n",
    "#### Regularization parameter C - high C value implies strict classification.\n",
    "\n",
    "#### Gamma parameter - high gamma parameter value implies only nearby points (support vector) are considered for classification.\n",
    "\n",
    "#### Kernel - Radial Basis Kernel(rbf) , linear kernel are popular choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel = 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 90.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel = 'linear',C=10,gamma = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1, kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 95.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel = 'linear',C=10,gamma = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=2, kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 95.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel = 'linear',C=10,gamma = 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.02, kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 95.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel = 'linear',C=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 97.50\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel = 'rbf',C=10,gamma=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 97.50\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel = 'rbf',C=100,gamma=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 97.50\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel = 'rbf',C=100,gamma=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=2, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 95.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel = 'rbf',C=100,gamma=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 95.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel = 'rbf',C=1,gamma=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 82.50\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel = 'rbf', C=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.0001, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.825"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(test_sample,test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 82.50\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier\n",
    "\n",
    "#### case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 87.50\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tree.DecisionTreeClassifier(criterion = 'entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 92.50\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### case 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tree.DecisionTreeClassifier(min_samples_split = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 90.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### case 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tree.DecisionTreeClassifier(criterion = 'entropy', min_samples_split = 79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=79,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 90.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-NN Classifier\n",
    "\n",
    "#### case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors = 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 97.50\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 97.50\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### case 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors = 5,algorithm = 'kd_tree') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 97.50\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### case 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors = 5,algorithm = 'ball_tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 97.50\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### case 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors = 6,algorithm = 'brute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=6, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 95.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier\n",
    "\n",
    "#### case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 95.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=5, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 92.50\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### case 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators = 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=70, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 97.50\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### case 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(criterion = 'entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 92.50\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### case 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators = 30, criterion = 'entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 95.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### case 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators = 100,criterion = 'entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 95.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier\n",
    "\n",
    "#### case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = tree.DecisionTreeClassifier(criterion = 'gini', max_depth = 1)\n",
    "adabst = AdaBoostClassifier(base_estimator = dtree, n_estimators = 5000, learning_rate = 0.05, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=0.05, n_estimators=5000, random_state=42)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adabst.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = adabst.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 92.50\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = tree.DecisionTreeClassifier(criterion = 'gini')\n",
    "adabst = AdaBoostClassifier(base_estimator = dtree, n_estimators = 5000, learning_rate = 0.05, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=0.05, n_estimators=5000, random_state=42)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adabst.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = adabst.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 85.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### case 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = tree.DecisionTreeClassifier(min_samples_split = 10)\n",
    "adabst = AdaBoostClassifier(base_estimator = dtree, n_estimators = 1000, learning_rate = 0.05, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=10,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=0.05, n_estimators=1000, random_state=42)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adabst.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = adabst.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 92.50\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### case 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = tree.DecisionTreeClassifier(min_samples_split = 10)\n",
    "adabst = AdaBoostClassifier(base_estimator = dtree, n_estimators = 5000, learning_rate = 0.01, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=10,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=0.01, n_estimators=5000, random_state=42)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adabst.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = adabst.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 95.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### case 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = tree.DecisionTreeClassifier(min_samples_split = 10)\n",
    "adabst = AdaBoostClassifier(base_estimator = dtree, n_estimators = 5000, learning_rate = 0.005, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=10,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=0.005, n_estimators=5000, random_state=42)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adabst.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = adabst.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 95.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation for model selection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [] \n",
    "value = [] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-fold Cross-validation for SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel = 'linear',C=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mylabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model,my_file,mylabel,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9047619 , 0.97619048, 0.95121951, 0.97435897, 1.        ])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8779786cf8>]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(5),scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9613061735012955"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append('SVM')\n",
    "value.append(scores.mean()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-fold Cross-validation for Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model,my_file,mylabel,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88095238, 0.97619048, 0.90243902, 0.84615385, 0.92105263])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8779714cf8>]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(5),scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9053576718531791"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append('Decision Tree')\n",
    "value.append(scores.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SVM', 'Decision Tree']"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[96.13061735012955, 90.53576718531791]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-fold Cross-validation for Naive-Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model,my_file,mylabel,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57142857, 0.47619048, 0.56097561, 0.38461538, 0.47368421])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8779694cf8>]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(5),scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4933788505033691"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append('Naive-Bayes')\n",
    "value.append(scores.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['SVM', 'Decision Tree', 'Naive-Bayes'],\n",
       " [96.13061735012955, 90.53576718531791, 49.33788505033691])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models,value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-fold Cross-validation for k-nearest neighbour classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors = 5,algorithm = 'auto') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model,my_file,mylabel,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85714286, 0.88095238, 0.87804878, 0.87179487, 0.97368421])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f87795fbcc0>]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(5),scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.892324620180846"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append('K-NN')\n",
    "value.append(scores.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['SVM', 'Decision Tree', 'Naive-Bayes', 'K-NN'],\n",
       " [96.13061735012955, 90.53576718531791, 49.33788505033691, 89.2324620180846])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models,value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### K-fold Cross-validation for Random Forset Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators = 100,criterion = 'entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model,my_file,mylabel,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9047619 , 0.95238095, 0.95121951, 0.8974359 , 1.        ])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f87795e2358>]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(5),scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9411596533547752"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append('Random Forest')\n",
    "value.append(scores.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['SVM', 'Decision Tree', 'Naive-Bayes', 'K-NN', 'Random Forest'],\n",
       " [96.13061735012955,\n",
       "  90.53576718531791,\n",
       "  49.33788505033691,\n",
       "  89.2324620180846,\n",
       "  94.11596533547753])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models,value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-fold Cross-validation for AdaBoost Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = tree.DecisionTreeClassifier(min_samples_split = 10)\n",
    "adabst = AdaBoostClassifier(base_estimator = dtree, n_estimators = 5000, learning_rate = 0.005, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(adabst,my_file,mylabel,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92857143, 0.92857143, 0.92682927, 0.87179487, 0.97368421])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8779543860>]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(5),scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9258902415513456"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append('AdaBoost')\n",
    "value.append(scores.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['SVM', 'Decision Tree', 'Naive-Bayes', 'K-NN', 'Random Forest', 'AdaBoost'],\n",
       " [96.13061735012955,\n",
       "  90.53576718531791,\n",
       "  49.33788505033691,\n",
       "  89.2324620180846,\n",
       "  94.11596533547753,\n",
       "  92.58902415513455])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models,value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of diiferent classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SVM', 'Decision Tree', 'Naive-Bayes', 'K-NN', 'Random Forest', 'AdaBoost']"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[96.13061735012955,\n",
       " 90.53576718531791,\n",
       " 49.33788505033691,\n",
       " 89.2324620180846,\n",
       " 94.11596533547753,\n",
       " 92.58902415513455]"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, list)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(models),type(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = np.asarray(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_label = np.arange(len(models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Average accuracy chart of different classification models')"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_label,value)\n",
    "plt.xticks(x_label,models)\n",
    "plt.xlabel('Classification Models')\n",
    "plt.ylabel('Accuracy-score')\n",
    "plt.title('Average accuracy chart of different classification models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Average accuracy chart of different classification models')"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(x_label,value,align = 'center', alpha = 0.5)\n",
    "plt.xticks(x_label,models)\n",
    "plt.xlabel('Classification Models')\n",
    "plt.ylabel('Accuracy-score')\n",
    "plt.title('Average accuracy chart of different classification models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Average accuracy chart of different classification models')"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_label,value)\n",
    "plt.xticks(x_label,models)\n",
    "plt.xlabel('Classification Models')\n",
    "plt.ylabel('Accuracy-score')\n",
    "plt.title('Average accuracy chart of different classification models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training And Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy</th>\n",
       "      <th>contrast</th>\n",
       "      <th>variance</th>\n",
       "      <th>inverse difference moment</th>\n",
       "      <th>sum average</th>\n",
       "      <th>sum variance</th>\n",
       "      <th>sum entropy</th>\n",
       "      <th>entropy</th>\n",
       "      <th>difference variance</th>\n",
       "      <th>difference entropy</th>\n",
       "      <th>mean_B</th>\n",
       "      <th>mean_G</th>\n",
       "      <th>mean_R</th>\n",
       "      <th>std_B</th>\n",
       "      <th>std_G</th>\n",
       "      <th>std_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.169224</td>\n",
       "      <td>0.289995</td>\n",
       "      <td>0.503613</td>\n",
       "      <td>0.328835</td>\n",
       "      <td>0.554133</td>\n",
       "      <td>0.503203</td>\n",
       "      <td>0.699561</td>\n",
       "      <td>0.680072</td>\n",
       "      <td>0.143376</td>\n",
       "      <td>0.709940</td>\n",
       "      <td>0.313805</td>\n",
       "      <td>0.528787</td>\n",
       "      <td>0.614273</td>\n",
       "      <td>0.304604</td>\n",
       "      <td>0.615009</td>\n",
       "      <td>0.737568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.816743</td>\n",
       "      <td>0.101235</td>\n",
       "      <td>0.222058</td>\n",
       "      <td>0.910721</td>\n",
       "      <td>0.092361</td>\n",
       "      <td>0.222110</td>\n",
       "      <td>0.142707</td>\n",
       "      <td>0.124576</td>\n",
       "      <td>0.695182</td>\n",
       "      <td>0.139885</td>\n",
       "      <td>0.220593</td>\n",
       "      <td>0.101461</td>\n",
       "      <td>0.053140</td>\n",
       "      <td>0.559716</td>\n",
       "      <td>0.442374</td>\n",
       "      <td>0.309818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.616307</td>\n",
       "      <td>0.174905</td>\n",
       "      <td>0.229516</td>\n",
       "      <td>0.791696</td>\n",
       "      <td>0.149270</td>\n",
       "      <td>0.229158</td>\n",
       "      <td>0.305093</td>\n",
       "      <td>0.272178</td>\n",
       "      <td>0.536824</td>\n",
       "      <td>0.286056</td>\n",
       "      <td>0.298854</td>\n",
       "      <td>0.167377</td>\n",
       "      <td>0.074775</td>\n",
       "      <td>0.539028</td>\n",
       "      <td>0.447906</td>\n",
       "      <td>0.289288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016687</td>\n",
       "      <td>0.680178</td>\n",
       "      <td>0.343683</td>\n",
       "      <td>0.133705</td>\n",
       "      <td>0.830096</td>\n",
       "      <td>0.340649</td>\n",
       "      <td>0.935801</td>\n",
       "      <td>0.905857</td>\n",
       "      <td>0.046132</td>\n",
       "      <td>0.817664</td>\n",
       "      <td>0.265694</td>\n",
       "      <td>0.874486</td>\n",
       "      <td>0.759549</td>\n",
       "      <td>0.398753</td>\n",
       "      <td>0.512621</td>\n",
       "      <td>0.594145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.144739</td>\n",
       "      <td>0.238395</td>\n",
       "      <td>0.059277</td>\n",
       "      <td>0.370087</td>\n",
       "      <td>0.252131</td>\n",
       "      <td>0.058167</td>\n",
       "      <td>0.673827</td>\n",
       "      <td>0.645537</td>\n",
       "      <td>0.162975</td>\n",
       "      <td>0.641177</td>\n",
       "      <td>0.170598</td>\n",
       "      <td>0.232265</td>\n",
       "      <td>0.307716</td>\n",
       "      <td>0.091011</td>\n",
       "      <td>0.135052</td>\n",
       "      <td>0.348236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.753275</td>\n",
       "      <td>0.026219</td>\n",
       "      <td>0.175914</td>\n",
       "      <td>0.855644</td>\n",
       "      <td>0.100871</td>\n",
       "      <td>0.176298</td>\n",
       "      <td>0.196664</td>\n",
       "      <td>0.177152</td>\n",
       "      <td>0.647691</td>\n",
       "      <td>0.198023</td>\n",
       "      <td>0.176512</td>\n",
       "      <td>0.076325</td>\n",
       "      <td>0.152918</td>\n",
       "      <td>0.394871</td>\n",
       "      <td>0.249911</td>\n",
       "      <td>0.468215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.086338</td>\n",
       "      <td>0.109834</td>\n",
       "      <td>0.002533</td>\n",
       "      <td>0.441833</td>\n",
       "      <td>0.208530</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>0.711789</td>\n",
       "      <td>0.647242</td>\n",
       "      <td>0.255335</td>\n",
       "      <td>0.552105</td>\n",
       "      <td>0.231839</td>\n",
       "      <td>0.171394</td>\n",
       "      <td>0.286421</td>\n",
       "      <td>0.087317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.297518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.719489</td>\n",
       "      <td>0.019917</td>\n",
       "      <td>0.177375</td>\n",
       "      <td>0.837457</td>\n",
       "      <td>0.111338</td>\n",
       "      <td>0.177799</td>\n",
       "      <td>0.220557</td>\n",
       "      <td>0.198897</td>\n",
       "      <td>0.622483</td>\n",
       "      <td>0.220909</td>\n",
       "      <td>0.225201</td>\n",
       "      <td>0.090681</td>\n",
       "      <td>0.143445</td>\n",
       "      <td>0.463693</td>\n",
       "      <td>0.267135</td>\n",
       "      <td>0.421028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.979866</td>\n",
       "      <td>0.065778</td>\n",
       "      <td>0.013180</td>\n",
       "      <td>0.994070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012969</td>\n",
       "      <td>0.010677</td>\n",
       "      <td>0.008506</td>\n",
       "      <td>0.847751</td>\n",
       "      <td>0.011066</td>\n",
       "      <td>0.058835</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>0.260821</td>\n",
       "      <td>0.170652</td>\n",
       "      <td>0.017506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.796203</td>\n",
       "      <td>0.177308</td>\n",
       "      <td>0.180361</td>\n",
       "      <td>0.910296</td>\n",
       "      <td>0.088612</td>\n",
       "      <td>0.179878</td>\n",
       "      <td>0.156350</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>0.687980</td>\n",
       "      <td>0.131606</td>\n",
       "      <td>0.225653</td>\n",
       "      <td>0.099282</td>\n",
       "      <td>0.044162</td>\n",
       "      <td>0.561475</td>\n",
       "      <td>0.415473</td>\n",
       "      <td>0.177397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.180932</td>\n",
       "      <td>0.239203</td>\n",
       "      <td>0.281093</td>\n",
       "      <td>0.476267</td>\n",
       "      <td>0.414113</td>\n",
       "      <td>0.280477</td>\n",
       "      <td>0.663436</td>\n",
       "      <td>0.601878</td>\n",
       "      <td>0.247823</td>\n",
       "      <td>0.536012</td>\n",
       "      <td>0.124879</td>\n",
       "      <td>0.416336</td>\n",
       "      <td>0.442787</td>\n",
       "      <td>0.188226</td>\n",
       "      <td>0.449327</td>\n",
       "      <td>0.545056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.746699</td>\n",
       "      <td>0.221874</td>\n",
       "      <td>0.172101</td>\n",
       "      <td>0.884964</td>\n",
       "      <td>0.104835</td>\n",
       "      <td>0.171341</td>\n",
       "      <td>0.186406</td>\n",
       "      <td>0.160340</td>\n",
       "      <td>0.650283</td>\n",
       "      <td>0.165443</td>\n",
       "      <td>0.211575</td>\n",
       "      <td>0.128075</td>\n",
       "      <td>0.035218</td>\n",
       "      <td>0.444714</td>\n",
       "      <td>0.439441</td>\n",
       "      <td>0.162066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.708238</td>\n",
       "      <td>0.039289</td>\n",
       "      <td>0.192864</td>\n",
       "      <td>0.832247</td>\n",
       "      <td>0.120533</td>\n",
       "      <td>0.193210</td>\n",
       "      <td>0.226917</td>\n",
       "      <td>0.204334</td>\n",
       "      <td>0.613916</td>\n",
       "      <td>0.227441</td>\n",
       "      <td>0.196033</td>\n",
       "      <td>0.095771</td>\n",
       "      <td>0.170095</td>\n",
       "      <td>0.400597</td>\n",
       "      <td>0.273870</td>\n",
       "      <td>0.480086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.759275</td>\n",
       "      <td>0.117672</td>\n",
       "      <td>0.348243</td>\n",
       "      <td>0.859624</td>\n",
       "      <td>0.151281</td>\n",
       "      <td>0.348484</td>\n",
       "      <td>0.186493</td>\n",
       "      <td>0.168041</td>\n",
       "      <td>0.682123</td>\n",
       "      <td>0.198418</td>\n",
       "      <td>0.239835</td>\n",
       "      <td>0.152197</td>\n",
       "      <td>0.131952</td>\n",
       "      <td>0.500756</td>\n",
       "      <td>0.535543</td>\n",
       "      <td>0.451087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.734341</td>\n",
       "      <td>0.212244</td>\n",
       "      <td>0.184847</td>\n",
       "      <td>0.876952</td>\n",
       "      <td>0.112303</td>\n",
       "      <td>0.184171</td>\n",
       "      <td>0.197792</td>\n",
       "      <td>0.170491</td>\n",
       "      <td>0.645881</td>\n",
       "      <td>0.175686</td>\n",
       "      <td>0.223086</td>\n",
       "      <td>0.136636</td>\n",
       "      <td>0.037988</td>\n",
       "      <td>0.459744</td>\n",
       "      <td>0.455840</td>\n",
       "      <td>0.174449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.032162</td>\n",
       "      <td>0.644137</td>\n",
       "      <td>0.395792</td>\n",
       "      <td>0.149959</td>\n",
       "      <td>0.784006</td>\n",
       "      <td>0.393083</td>\n",
       "      <td>0.905366</td>\n",
       "      <td>0.885406</td>\n",
       "      <td>0.045673</td>\n",
       "      <td>0.838216</td>\n",
       "      <td>0.267264</td>\n",
       "      <td>0.825950</td>\n",
       "      <td>0.716113</td>\n",
       "      <td>0.410896</td>\n",
       "      <td>0.566080</td>\n",
       "      <td>0.619856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.929437</td>\n",
       "      <td>0.030788</td>\n",
       "      <td>0.039176</td>\n",
       "      <td>0.961233</td>\n",
       "      <td>0.011858</td>\n",
       "      <td>0.039227</td>\n",
       "      <td>0.054511</td>\n",
       "      <td>0.049274</td>\n",
       "      <td>0.782016</td>\n",
       "      <td>0.066333</td>\n",
       "      <td>0.081997</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.026549</td>\n",
       "      <td>0.312601</td>\n",
       "      <td>0.146925</td>\n",
       "      <td>0.165443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.309006</td>\n",
       "      <td>0.181983</td>\n",
       "      <td>0.588884</td>\n",
       "      <td>0.500712</td>\n",
       "      <td>0.470738</td>\n",
       "      <td>0.589292</td>\n",
       "      <td>0.534461</td>\n",
       "      <td>0.512072</td>\n",
       "      <td>0.282558</td>\n",
       "      <td>0.563096</td>\n",
       "      <td>0.413763</td>\n",
       "      <td>0.430469</td>\n",
       "      <td>0.534928</td>\n",
       "      <td>0.399168</td>\n",
       "      <td>0.659911</td>\n",
       "      <td>0.783451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.776195</td>\n",
       "      <td>0.025340</td>\n",
       "      <td>0.168686</td>\n",
       "      <td>0.868081</td>\n",
       "      <td>0.093564</td>\n",
       "      <td>0.169059</td>\n",
       "      <td>0.178687</td>\n",
       "      <td>0.161216</td>\n",
       "      <td>0.662719</td>\n",
       "      <td>0.182666</td>\n",
       "      <td>0.167726</td>\n",
       "      <td>0.069320</td>\n",
       "      <td>0.146390</td>\n",
       "      <td>0.389611</td>\n",
       "      <td>0.240168</td>\n",
       "      <td>0.463173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.910705</td>\n",
       "      <td>0.047852</td>\n",
       "      <td>0.143099</td>\n",
       "      <td>0.963078</td>\n",
       "      <td>0.052286</td>\n",
       "      <td>0.143284</td>\n",
       "      <td>0.064152</td>\n",
       "      <td>0.054446</td>\n",
       "      <td>0.771295</td>\n",
       "      <td>0.061737</td>\n",
       "      <td>0.169317</td>\n",
       "      <td>0.058562</td>\n",
       "      <td>0.028645</td>\n",
       "      <td>0.516078</td>\n",
       "      <td>0.360929</td>\n",
       "      <td>0.163771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005193</td>\n",
       "      <td>0.024192</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.024357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.868280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011742</td>\n",
       "      <td>0.313507</td>\n",
       "      <td>0.153461</td>\n",
       "      <td>0.076231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.638123</td>\n",
       "      <td>0.147780</td>\n",
       "      <td>0.304033</td>\n",
       "      <td>0.879514</td>\n",
       "      <td>0.184535</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.270962</td>\n",
       "      <td>0.214235</td>\n",
       "      <td>0.748563</td>\n",
       "      <td>0.149985</td>\n",
       "      <td>0.398479</td>\n",
       "      <td>0.210074</td>\n",
       "      <td>0.071560</td>\n",
       "      <td>0.682240</td>\n",
       "      <td>0.573719</td>\n",
       "      <td>0.182825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.265679</td>\n",
       "      <td>0.155492</td>\n",
       "      <td>0.768694</td>\n",
       "      <td>0.525848</td>\n",
       "      <td>0.570201</td>\n",
       "      <td>0.769660</td>\n",
       "      <td>0.598892</td>\n",
       "      <td>0.547214</td>\n",
       "      <td>0.264344</td>\n",
       "      <td>0.526277</td>\n",
       "      <td>0.652788</td>\n",
       "      <td>0.494717</td>\n",
       "      <td>0.669729</td>\n",
       "      <td>0.627026</td>\n",
       "      <td>0.731178</td>\n",
       "      <td>0.923630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.701493</td>\n",
       "      <td>0.035783</td>\n",
       "      <td>0.271819</td>\n",
       "      <td>0.870198</td>\n",
       "      <td>0.136969</td>\n",
       "      <td>0.272363</td>\n",
       "      <td>0.232108</td>\n",
       "      <td>0.194935</td>\n",
       "      <td>0.624206</td>\n",
       "      <td>0.182920</td>\n",
       "      <td>0.301243</td>\n",
       "      <td>0.143018</td>\n",
       "      <td>0.089608</td>\n",
       "      <td>0.613827</td>\n",
       "      <td>0.458148</td>\n",
       "      <td>0.387999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.037521</td>\n",
       "      <td>0.410973</td>\n",
       "      <td>0.183254</td>\n",
       "      <td>0.121111</td>\n",
       "      <td>0.565109</td>\n",
       "      <td>0.181421</td>\n",
       "      <td>0.861132</td>\n",
       "      <td>0.854264</td>\n",
       "      <td>0.037339</td>\n",
       "      <td>0.834893</td>\n",
       "      <td>0.149505</td>\n",
       "      <td>0.581961</td>\n",
       "      <td>0.565702</td>\n",
       "      <td>0.134371</td>\n",
       "      <td>0.340063</td>\n",
       "      <td>0.452158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.034828</td>\n",
       "      <td>0.858426</td>\n",
       "      <td>0.423979</td>\n",
       "      <td>0.112276</td>\n",
       "      <td>0.827759</td>\n",
       "      <td>0.420090</td>\n",
       "      <td>0.891780</td>\n",
       "      <td>0.897603</td>\n",
       "      <td>0.029799</td>\n",
       "      <td>0.899544</td>\n",
       "      <td>0.316002</td>\n",
       "      <td>0.875428</td>\n",
       "      <td>0.738687</td>\n",
       "      <td>0.418568</td>\n",
       "      <td>0.599603</td>\n",
       "      <td>0.630198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.475351</td>\n",
       "      <td>0.113515</td>\n",
       "      <td>0.343857</td>\n",
       "      <td>0.629219</td>\n",
       "      <td>0.271461</td>\n",
       "      <td>0.344112</td>\n",
       "      <td>0.381336</td>\n",
       "      <td>0.372120</td>\n",
       "      <td>0.469400</td>\n",
       "      <td>0.457843</td>\n",
       "      <td>0.414242</td>\n",
       "      <td>0.259100</td>\n",
       "      <td>0.252296</td>\n",
       "      <td>0.540759</td>\n",
       "      <td>0.500993</td>\n",
       "      <td>0.459192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.582977</td>\n",
       "      <td>0.247465</td>\n",
       "      <td>0.263660</td>\n",
       "      <td>0.823804</td>\n",
       "      <td>0.173158</td>\n",
       "      <td>0.262957</td>\n",
       "      <td>0.323813</td>\n",
       "      <td>0.270001</td>\n",
       "      <td>0.550242</td>\n",
       "      <td>0.233951</td>\n",
       "      <td>0.389343</td>\n",
       "      <td>0.207296</td>\n",
       "      <td>0.041097</td>\n",
       "      <td>0.677191</td>\n",
       "      <td>0.551749</td>\n",
       "      <td>0.188445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.052330</td>\n",
       "      <td>0.463148</td>\n",
       "      <td>0.603172</td>\n",
       "      <td>0.239494</td>\n",
       "      <td>0.865652</td>\n",
       "      <td>0.601981</td>\n",
       "      <td>0.887251</td>\n",
       "      <td>0.830420</td>\n",
       "      <td>0.083958</td>\n",
       "      <td>0.725498</td>\n",
       "      <td>0.742508</td>\n",
       "      <td>0.841126</td>\n",
       "      <td>0.848570</td>\n",
       "      <td>0.533037</td>\n",
       "      <td>0.695461</td>\n",
       "      <td>0.743058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.079862</td>\n",
       "      <td>0.585364</td>\n",
       "      <td>0.747049</td>\n",
       "      <td>0.282110</td>\n",
       "      <td>0.781438</td>\n",
       "      <td>0.745472</td>\n",
       "      <td>0.830760</td>\n",
       "      <td>0.789128</td>\n",
       "      <td>0.099432</td>\n",
       "      <td>0.764286</td>\n",
       "      <td>0.632374</td>\n",
       "      <td>0.770294</td>\n",
       "      <td>0.750642</td>\n",
       "      <td>0.844418</td>\n",
       "      <td>0.764848</td>\n",
       "      <td>0.864680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.645853</td>\n",
       "      <td>0.135929</td>\n",
       "      <td>0.443657</td>\n",
       "      <td>0.823416</td>\n",
       "      <td>0.217616</td>\n",
       "      <td>0.444006</td>\n",
       "      <td>0.275301</td>\n",
       "      <td>0.241708</td>\n",
       "      <td>0.568529</td>\n",
       "      <td>0.250496</td>\n",
       "      <td>0.473873</td>\n",
       "      <td>0.236883</td>\n",
       "      <td>0.104340</td>\n",
       "      <td>0.838114</td>\n",
       "      <td>0.672522</td>\n",
       "      <td>0.406499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.212732</td>\n",
       "      <td>0.397300</td>\n",
       "      <td>0.447082</td>\n",
       "      <td>0.417542</td>\n",
       "      <td>0.474010</td>\n",
       "      <td>0.445922</td>\n",
       "      <td>0.659979</td>\n",
       "      <td>0.627627</td>\n",
       "      <td>0.185861</td>\n",
       "      <td>0.646859</td>\n",
       "      <td>0.247395</td>\n",
       "      <td>0.519701</td>\n",
       "      <td>0.374571</td>\n",
       "      <td>0.354900</td>\n",
       "      <td>0.684364</td>\n",
       "      <td>0.504045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.278409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.340610</td>\n",
       "      <td>0.592376</td>\n",
       "      <td>0.352626</td>\n",
       "      <td>0.341517</td>\n",
       "      <td>0.604308</td>\n",
       "      <td>0.529951</td>\n",
       "      <td>0.399729</td>\n",
       "      <td>0.440212</td>\n",
       "      <td>0.667015</td>\n",
       "      <td>0.338520</td>\n",
       "      <td>0.284144</td>\n",
       "      <td>0.703021</td>\n",
       "      <td>0.479525</td>\n",
       "      <td>0.442842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.880541</td>\n",
       "      <td>0.084340</td>\n",
       "      <td>0.076190</td>\n",
       "      <td>0.955531</td>\n",
       "      <td>0.039759</td>\n",
       "      <td>0.076012</td>\n",
       "      <td>0.085511</td>\n",
       "      <td>0.071197</td>\n",
       "      <td>0.944586</td>\n",
       "      <td>0.069753</td>\n",
       "      <td>0.136550</td>\n",
       "      <td>0.054957</td>\n",
       "      <td>0.001686</td>\n",
       "      <td>0.398962</td>\n",
       "      <td>0.311373</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.031826</td>\n",
       "      <td>0.594671</td>\n",
       "      <td>0.681899</td>\n",
       "      <td>0.296255</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.680121</td>\n",
       "      <td>0.903889</td>\n",
       "      <td>0.834994</td>\n",
       "      <td>0.108456</td>\n",
       "      <td>0.708133</td>\n",
       "      <td>0.617055</td>\n",
       "      <td>0.985698</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.877554</td>\n",
       "      <td>0.723824</td>\n",
       "      <td>0.827395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.074071</td>\n",
       "      <td>0.460207</td>\n",
       "      <td>0.444862</td>\n",
       "      <td>0.312196</td>\n",
       "      <td>0.636052</td>\n",
       "      <td>0.443332</td>\n",
       "      <td>0.846141</td>\n",
       "      <td>0.782075</td>\n",
       "      <td>0.115774</td>\n",
       "      <td>0.676443</td>\n",
       "      <td>0.010460</td>\n",
       "      <td>0.674330</td>\n",
       "      <td>0.625163</td>\n",
       "      <td>0.059598</td>\n",
       "      <td>0.646336</td>\n",
       "      <td>0.653199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.074672</td>\n",
       "      <td>0.719582</td>\n",
       "      <td>0.597443</td>\n",
       "      <td>0.241884</td>\n",
       "      <td>0.754096</td>\n",
       "      <td>0.594751</td>\n",
       "      <td>0.860951</td>\n",
       "      <td>0.818228</td>\n",
       "      <td>0.081610</td>\n",
       "      <td>0.773312</td>\n",
       "      <td>0.311437</td>\n",
       "      <td>0.756115</td>\n",
       "      <td>0.766888</td>\n",
       "      <td>0.520741</td>\n",
       "      <td>0.700660</td>\n",
       "      <td>0.771711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.861733</td>\n",
       "      <td>0.066044</td>\n",
       "      <td>0.064422</td>\n",
       "      <td>0.938579</td>\n",
       "      <td>0.039600</td>\n",
       "      <td>0.064324</td>\n",
       "      <td>0.102768</td>\n",
       "      <td>0.088436</td>\n",
       "      <td>0.758093</td>\n",
       "      <td>0.095588</td>\n",
       "      <td>0.123677</td>\n",
       "      <td>0.055475</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>0.341972</td>\n",
       "      <td>0.291142</td>\n",
       "      <td>0.021512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.242339</td>\n",
       "      <td>0.239148</td>\n",
       "      <td>0.497708</td>\n",
       "      <td>0.498061</td>\n",
       "      <td>0.479255</td>\n",
       "      <td>0.497580</td>\n",
       "      <td>0.623507</td>\n",
       "      <td>0.570164</td>\n",
       "      <td>0.235208</td>\n",
       "      <td>0.546601</td>\n",
       "      <td>0.239183</td>\n",
       "      <td>0.517943</td>\n",
       "      <td>0.398800</td>\n",
       "      <td>0.357749</td>\n",
       "      <td>0.719585</td>\n",
       "      <td>0.548627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.737837</td>\n",
       "      <td>0.123088</td>\n",
       "      <td>0.249290</td>\n",
       "      <td>0.857726</td>\n",
       "      <td>0.113028</td>\n",
       "      <td>0.249277</td>\n",
       "      <td>0.209732</td>\n",
       "      <td>0.187314</td>\n",
       "      <td>0.626262</td>\n",
       "      <td>0.213894</td>\n",
       "      <td>0.238091</td>\n",
       "      <td>0.112843</td>\n",
       "      <td>0.093472</td>\n",
       "      <td>0.549612</td>\n",
       "      <td>0.411648</td>\n",
       "      <td>0.397622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.736400</td>\n",
       "      <td>0.088800</td>\n",
       "      <td>0.366964</td>\n",
       "      <td>0.878258</td>\n",
       "      <td>0.161588</td>\n",
       "      <td>0.367415</td>\n",
       "      <td>0.201976</td>\n",
       "      <td>0.174083</td>\n",
       "      <td>0.652291</td>\n",
       "      <td>0.174873</td>\n",
       "      <td>0.285335</td>\n",
       "      <td>0.145946</td>\n",
       "      <td>0.171685</td>\n",
       "      <td>0.585209</td>\n",
       "      <td>0.493819</td>\n",
       "      <td>0.516183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.851731</td>\n",
       "      <td>0.048748</td>\n",
       "      <td>0.259864</td>\n",
       "      <td>0.925294</td>\n",
       "      <td>0.096625</td>\n",
       "      <td>0.260306</td>\n",
       "      <td>0.116619</td>\n",
       "      <td>0.102781</td>\n",
       "      <td>0.716928</td>\n",
       "      <td>0.118980</td>\n",
       "      <td>0.231058</td>\n",
       "      <td>0.104268</td>\n",
       "      <td>0.058751</td>\n",
       "      <td>0.603979</td>\n",
       "      <td>0.484588</td>\n",
       "      <td>0.318007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.284387</td>\n",
       "      <td>0.146664</td>\n",
       "      <td>0.672039</td>\n",
       "      <td>0.570640</td>\n",
       "      <td>0.514095</td>\n",
       "      <td>0.672840</td>\n",
       "      <td>0.576264</td>\n",
       "      <td>0.514959</td>\n",
       "      <td>0.313239</td>\n",
       "      <td>0.471214</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.481350</td>\n",
       "      <td>0.424212</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.735300</td>\n",
       "      <td>0.614458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.727530</td>\n",
       "      <td>0.049789</td>\n",
       "      <td>0.063248</td>\n",
       "      <td>0.848463</td>\n",
       "      <td>0.070763</td>\n",
       "      <td>0.063242</td>\n",
       "      <td>0.193881</td>\n",
       "      <td>0.176635</td>\n",
       "      <td>0.654409</td>\n",
       "      <td>0.209215</td>\n",
       "      <td>0.173089</td>\n",
       "      <td>0.086279</td>\n",
       "      <td>0.025816</td>\n",
       "      <td>0.325622</td>\n",
       "      <td>0.252005</td>\n",
       "      <td>0.088513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.794043</td>\n",
       "      <td>0.027502</td>\n",
       "      <td>0.149330</td>\n",
       "      <td>0.880099</td>\n",
       "      <td>0.082796</td>\n",
       "      <td>0.149647</td>\n",
       "      <td>0.162030</td>\n",
       "      <td>0.145990</td>\n",
       "      <td>0.682160</td>\n",
       "      <td>0.168556</td>\n",
       "      <td>0.183661</td>\n",
       "      <td>0.062259</td>\n",
       "      <td>0.122114</td>\n",
       "      <td>0.439205</td>\n",
       "      <td>0.227237</td>\n",
       "      <td>0.403000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.471033</td>\n",
       "      <td>0.240571</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.592830</td>\n",
       "      <td>0.277197</td>\n",
       "      <td>0.363198</td>\n",
       "      <td>0.389181</td>\n",
       "      <td>0.398795</td>\n",
       "      <td>0.398540</td>\n",
       "      <td>0.530844</td>\n",
       "      <td>0.363709</td>\n",
       "      <td>0.259050</td>\n",
       "      <td>0.284365</td>\n",
       "      <td>0.446762</td>\n",
       "      <td>0.503644</td>\n",
       "      <td>0.544987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.705738</td>\n",
       "      <td>0.058311</td>\n",
       "      <td>0.381418</td>\n",
       "      <td>0.856901</td>\n",
       "      <td>0.176308</td>\n",
       "      <td>0.382078</td>\n",
       "      <td>0.230541</td>\n",
       "      <td>0.200624</td>\n",
       "      <td>0.618844</td>\n",
       "      <td>0.202152</td>\n",
       "      <td>0.306789</td>\n",
       "      <td>0.160876</td>\n",
       "      <td>0.182036</td>\n",
       "      <td>0.597425</td>\n",
       "      <td>0.507315</td>\n",
       "      <td>0.525931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.280717</td>\n",
       "      <td>0.160962</td>\n",
       "      <td>0.768933</td>\n",
       "      <td>0.561061</td>\n",
       "      <td>0.557869</td>\n",
       "      <td>0.769868</td>\n",
       "      <td>0.583372</td>\n",
       "      <td>0.523030</td>\n",
       "      <td>0.292712</td>\n",
       "      <td>0.481569</td>\n",
       "      <td>0.640075</td>\n",
       "      <td>0.484277</td>\n",
       "      <td>0.654803</td>\n",
       "      <td>0.626683</td>\n",
       "      <td>0.731693</td>\n",
       "      <td>0.922313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.020219</td>\n",
       "      <td>0.554469</td>\n",
       "      <td>0.368241</td>\n",
       "      <td>0.141403</td>\n",
       "      <td>0.833108</td>\n",
       "      <td>0.365991</td>\n",
       "      <td>0.933129</td>\n",
       "      <td>0.902192</td>\n",
       "      <td>0.047187</td>\n",
       "      <td>0.812903</td>\n",
       "      <td>0.283739</td>\n",
       "      <td>0.874879</td>\n",
       "      <td>0.766307</td>\n",
       "      <td>0.431001</td>\n",
       "      <td>0.531658</td>\n",
       "      <td>0.613396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.743322</td>\n",
       "      <td>0.083516</td>\n",
       "      <td>0.375759</td>\n",
       "      <td>0.887884</td>\n",
       "      <td>0.165842</td>\n",
       "      <td>0.376260</td>\n",
       "      <td>0.191724</td>\n",
       "      <td>0.163524</td>\n",
       "      <td>0.659353</td>\n",
       "      <td>0.161803</td>\n",
       "      <td>0.389260</td>\n",
       "      <td>0.185456</td>\n",
       "      <td>0.067530</td>\n",
       "      <td>0.806767</td>\n",
       "      <td>0.646458</td>\n",
       "      <td>0.239361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.849902</td>\n",
       "      <td>0.019333</td>\n",
       "      <td>0.145730</td>\n",
       "      <td>0.949844</td>\n",
       "      <td>0.070827</td>\n",
       "      <td>0.146087</td>\n",
       "      <td>0.107178</td>\n",
       "      <td>0.087951</td>\n",
       "      <td>0.862835</td>\n",
       "      <td>0.079129</td>\n",
       "      <td>0.174678</td>\n",
       "      <td>0.089540</td>\n",
       "      <td>0.017940</td>\n",
       "      <td>0.451763</td>\n",
       "      <td>0.412236</td>\n",
       "      <td>0.115770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.397566</td>\n",
       "      <td>0.320199</td>\n",
       "      <td>0.466986</td>\n",
       "      <td>0.569552</td>\n",
       "      <td>0.348194</td>\n",
       "      <td>0.466319</td>\n",
       "      <td>0.466221</td>\n",
       "      <td>0.454695</td>\n",
       "      <td>0.355109</td>\n",
       "      <td>0.541982</td>\n",
       "      <td>0.175946</td>\n",
       "      <td>0.320325</td>\n",
       "      <td>0.429330</td>\n",
       "      <td>0.192105</td>\n",
       "      <td>0.578639</td>\n",
       "      <td>0.739005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.124393</td>\n",
       "      <td>0.248500</td>\n",
       "      <td>0.487117</td>\n",
       "      <td>0.370300</td>\n",
       "      <td>0.549832</td>\n",
       "      <td>0.486911</td>\n",
       "      <td>0.801573</td>\n",
       "      <td>0.735678</td>\n",
       "      <td>0.145483</td>\n",
       "      <td>0.644228</td>\n",
       "      <td>0.282172</td>\n",
       "      <td>0.545305</td>\n",
       "      <td>0.567497</td>\n",
       "      <td>0.433477</td>\n",
       "      <td>0.601541</td>\n",
       "      <td>0.699214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.487581</td>\n",
       "      <td>0.123430</td>\n",
       "      <td>0.352985</td>\n",
       "      <td>0.643946</td>\n",
       "      <td>0.266580</td>\n",
       "      <td>0.353203</td>\n",
       "      <td>0.371759</td>\n",
       "      <td>0.360644</td>\n",
       "      <td>0.455881</td>\n",
       "      <td>0.442211</td>\n",
       "      <td>0.355406</td>\n",
       "      <td>0.248507</td>\n",
       "      <td>0.274784</td>\n",
       "      <td>0.440869</td>\n",
       "      <td>0.493297</td>\n",
       "      <td>0.538858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.859038</td>\n",
       "      <td>0.087688</td>\n",
       "      <td>0.124883</td>\n",
       "      <td>0.934718</td>\n",
       "      <td>0.061451</td>\n",
       "      <td>0.124796</td>\n",
       "      <td>0.103159</td>\n",
       "      <td>0.089044</td>\n",
       "      <td>0.749533</td>\n",
       "      <td>0.100213</td>\n",
       "      <td>0.108491</td>\n",
       "      <td>0.074117</td>\n",
       "      <td>0.037926</td>\n",
       "      <td>0.282874</td>\n",
       "      <td>0.351699</td>\n",
       "      <td>0.183958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.842537</td>\n",
       "      <td>0.110994</td>\n",
       "      <td>0.204451</td>\n",
       "      <td>0.927244</td>\n",
       "      <td>0.086240</td>\n",
       "      <td>0.204407</td>\n",
       "      <td>0.116193</td>\n",
       "      <td>0.100923</td>\n",
       "      <td>0.717716</td>\n",
       "      <td>0.112887</td>\n",
       "      <td>0.231374</td>\n",
       "      <td>0.096031</td>\n",
       "      <td>0.042288</td>\n",
       "      <td>0.606232</td>\n",
       "      <td>0.446972</td>\n",
       "      <td>0.172812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.050335</td>\n",
       "      <td>0.567271</td>\n",
       "      <td>0.411831</td>\n",
       "      <td>0.281598</td>\n",
       "      <td>0.670655</td>\n",
       "      <td>0.409605</td>\n",
       "      <td>0.884174</td>\n",
       "      <td>0.813312</td>\n",
       "      <td>0.105402</td>\n",
       "      <td>0.674642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.714094</td>\n",
       "      <td>0.653454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.620931</td>\n",
       "      <td>0.626360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.486603</td>\n",
       "      <td>0.134009</td>\n",
       "      <td>0.340928</td>\n",
       "      <td>0.640326</td>\n",
       "      <td>0.263973</td>\n",
       "      <td>0.341058</td>\n",
       "      <td>0.371184</td>\n",
       "      <td>0.361974</td>\n",
       "      <td>0.466402</td>\n",
       "      <td>0.446690</td>\n",
       "      <td>0.406217</td>\n",
       "      <td>0.251548</td>\n",
       "      <td>0.246625</td>\n",
       "      <td>0.540365</td>\n",
       "      <td>0.497705</td>\n",
       "      <td>0.457404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.173193</td>\n",
       "      <td>0.210094</td>\n",
       "      <td>0.505773</td>\n",
       "      <td>0.336097</td>\n",
       "      <td>0.543099</td>\n",
       "      <td>0.505831</td>\n",
       "      <td>0.700749</td>\n",
       "      <td>0.679332</td>\n",
       "      <td>0.150142</td>\n",
       "      <td>0.702214</td>\n",
       "      <td>0.308823</td>\n",
       "      <td>0.517248</td>\n",
       "      <td>0.604296</td>\n",
       "      <td>0.302371</td>\n",
       "      <td>0.616105</td>\n",
       "      <td>0.740104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.494194</td>\n",
       "      <td>0.147221</td>\n",
       "      <td>0.406913</td>\n",
       "      <td>0.714284</td>\n",
       "      <td>0.248651</td>\n",
       "      <td>0.407114</td>\n",
       "      <td>0.400247</td>\n",
       "      <td>0.360798</td>\n",
       "      <td>0.444975</td>\n",
       "      <td>0.384820</td>\n",
       "      <td>0.429429</td>\n",
       "      <td>0.265146</td>\n",
       "      <td>0.155253</td>\n",
       "      <td>0.662022</td>\n",
       "      <td>0.587674</td>\n",
       "      <td>0.487641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       energy  contrast  variance  inverse difference moment  sum average  \\\n",
       "0    0.169224  0.289995  0.503613                   0.328835     0.554133   \n",
       "1    0.816743  0.101235  0.222058                   0.910721     0.092361   \n",
       "2    0.616307  0.174905  0.229516                   0.791696     0.149270   \n",
       "3    0.016687  0.680178  0.343683                   0.133705     0.830096   \n",
       "4    0.144739  0.238395  0.059277                   0.370087     0.252131   \n",
       "5    0.753275  0.026219  0.175914                   0.855644     0.100871   \n",
       "6    0.086338  0.109834  0.002533                   0.441833     0.208530   \n",
       "7    0.719489  0.019917  0.177375                   0.837457     0.111338   \n",
       "8    0.979866  0.065778  0.013180                   0.994070     0.000000   \n",
       "9    0.796203  0.177308  0.180361                   0.910296     0.088612   \n",
       "10   0.180932  0.239203  0.281093                   0.476267     0.414113   \n",
       "11   0.746699  0.221874  0.172101                   0.884964     0.104835   \n",
       "12   0.708238  0.039289  0.192864                   0.832247     0.120533   \n",
       "13   0.759275  0.117672  0.348243                   0.859624     0.151281   \n",
       "14   0.734341  0.212244  0.184847                   0.876952     0.112303   \n",
       "15   0.032162  0.644137  0.395792                   0.149959     0.784006   \n",
       "16   0.929437  0.030788  0.039176                   0.961233     0.011858   \n",
       "17   0.309006  0.181983  0.588884                   0.500712     0.470738   \n",
       "18   0.776195  0.025340  0.168686                   0.868081     0.093564   \n",
       "19   0.910705  0.047852  0.143099                   0.963078     0.052286   \n",
       "20   1.000000  0.005193  0.024192                   1.000000     0.000296   \n",
       "21   0.638123  0.147780  0.304033                   0.879514     0.184535   \n",
       "22   0.265679  0.155492  0.768694                   0.525848     0.570201   \n",
       "23   0.701493  0.035783  0.271819                   0.870198     0.136969   \n",
       "24   0.037521  0.410973  0.183254                   0.121111     0.565109   \n",
       "25   0.034828  0.858426  0.423979                   0.112276     0.827759   \n",
       "26   0.475351  0.113515  0.343857                   0.629219     0.271461   \n",
       "27   0.582977  0.247465  0.263660                   0.823804     0.173158   \n",
       "28   0.052330  0.463148  0.603172                   0.239494     0.865652   \n",
       "29   0.079862  0.585364  0.747049                   0.282110     0.781438   \n",
       "..        ...       ...       ...                        ...          ...   \n",
       "132  0.645853  0.135929  0.443657                   0.823416     0.217616   \n",
       "133  0.212732  0.397300  0.447082                   0.417542     0.474010   \n",
       "134  0.278409  0.000000  0.340610                   0.592376     0.352626   \n",
       "135  0.880541  0.084340  0.076190                   0.955531     0.039759   \n",
       "136  0.031826  0.594671  0.681899                   0.296255     1.000000   \n",
       "137  0.074071  0.460207  0.444862                   0.312196     0.636052   \n",
       "138  0.074672  0.719582  0.597443                   0.241884     0.754096   \n",
       "139  0.861733  0.066044  0.064422                   0.938579     0.039600   \n",
       "140  0.242339  0.239148  0.497708                   0.498061     0.479255   \n",
       "141  0.737837  0.123088  0.249290                   0.857726     0.113028   \n",
       "142  0.736400  0.088800  0.366964                   0.878258     0.161588   \n",
       "143  0.851731  0.048748  0.259864                   0.925294     0.096625   \n",
       "144  0.284387  0.146664  0.672039                   0.570640     0.514095   \n",
       "145  0.727530  0.049789  0.063248                   0.848463     0.070763   \n",
       "146  0.794043  0.027502  0.149330                   0.880099     0.082796   \n",
       "147  0.471033  0.240571  0.363636                   0.592830     0.277197   \n",
       "148  0.705738  0.058311  0.381418                   0.856901     0.176308   \n",
       "149  0.280717  0.160962  0.768933                   0.561061     0.557869   \n",
       "150  0.020219  0.554469  0.368241                   0.141403     0.833108   \n",
       "151  0.743322  0.083516  0.375759                   0.887884     0.165842   \n",
       "152  0.849902  0.019333  0.145730                   0.949844     0.070827   \n",
       "153  0.397566  0.320199  0.466986                   0.569552     0.348194   \n",
       "154  0.124393  0.248500  0.487117                   0.370300     0.549832   \n",
       "155  0.487581  0.123430  0.352985                   0.643946     0.266580   \n",
       "156  0.859038  0.087688  0.124883                   0.934718     0.061451   \n",
       "157  0.842537  0.110994  0.204451                   0.927244     0.086240   \n",
       "158  0.050335  0.567271  0.411831                   0.281598     0.670655   \n",
       "159  0.486603  0.134009  0.340928                   0.640326     0.263973   \n",
       "160  0.173193  0.210094  0.505773                   0.336097     0.543099   \n",
       "161  0.494194  0.147221  0.406913                   0.714284     0.248651   \n",
       "\n",
       "     sum variance  sum entropy   entropy  difference variance  \\\n",
       "0        0.503203     0.699561  0.680072             0.143376   \n",
       "1        0.222110     0.142707  0.124576             0.695182   \n",
       "2        0.229158     0.305093  0.272178             0.536824   \n",
       "3        0.340649     0.935801  0.905857             0.046132   \n",
       "4        0.058167     0.673827  0.645537             0.162975   \n",
       "5        0.176298     0.196664  0.177152             0.647691   \n",
       "6        0.002042     0.711789  0.647242             0.255335   \n",
       "7        0.177799     0.220557  0.198897             0.622483   \n",
       "8        0.012969     0.010677  0.008506             0.847751   \n",
       "9        0.179878     0.156350  0.132000             0.687980   \n",
       "10       0.280477     0.663436  0.601878             0.247823   \n",
       "11       0.171341     0.186406  0.160340             0.650283   \n",
       "12       0.193210     0.226917  0.204334             0.613916   \n",
       "13       0.348484     0.186493  0.168041             0.682123   \n",
       "14       0.184171     0.197792  0.170491             0.645881   \n",
       "15       0.393083     0.905366  0.885406             0.045673   \n",
       "16       0.039227     0.054511  0.049274             0.782016   \n",
       "17       0.589292     0.534461  0.512072             0.282558   \n",
       "18       0.169059     0.178687  0.161216             0.662719   \n",
       "19       0.143284     0.064152  0.054446             0.771295   \n",
       "20       0.024357     0.000000  0.000000             0.868280   \n",
       "21       0.304000     0.270962  0.214235             0.748563   \n",
       "22       0.769660     0.598892  0.547214             0.264344   \n",
       "23       0.272363     0.232108  0.194935             0.624206   \n",
       "24       0.181421     0.861132  0.854264             0.037339   \n",
       "25       0.420090     0.891780  0.897603             0.029799   \n",
       "26       0.344112     0.381336  0.372120             0.469400   \n",
       "27       0.262957     0.323813  0.270001             0.550242   \n",
       "28       0.601981     0.887251  0.830420             0.083958   \n",
       "29       0.745472     0.830760  0.789128             0.099432   \n",
       "..            ...          ...       ...                  ...   \n",
       "132      0.444006     0.275301  0.241708             0.568529   \n",
       "133      0.445922     0.659979  0.627627             0.185861   \n",
       "134      0.341517     0.604308  0.529951             0.399729   \n",
       "135      0.076012     0.085511  0.071197             0.944586   \n",
       "136      0.680121     0.903889  0.834994             0.108456   \n",
       "137      0.443332     0.846141  0.782075             0.115774   \n",
       "138      0.594751     0.860951  0.818228             0.081610   \n",
       "139      0.064324     0.102768  0.088436             0.758093   \n",
       "140      0.497580     0.623507  0.570164             0.235208   \n",
       "141      0.249277     0.209732  0.187314             0.626262   \n",
       "142      0.367415     0.201976  0.174083             0.652291   \n",
       "143      0.260306     0.116619  0.102781             0.716928   \n",
       "144      0.672840     0.576264  0.514959             0.313239   \n",
       "145      0.063242     0.193881  0.176635             0.654409   \n",
       "146      0.149647     0.162030  0.145990             0.682160   \n",
       "147      0.363198     0.389181  0.398795             0.398540   \n",
       "148      0.382078     0.230541  0.200624             0.618844   \n",
       "149      0.769868     0.583372  0.523030             0.292712   \n",
       "150      0.365991     0.933129  0.902192             0.047187   \n",
       "151      0.376260     0.191724  0.163524             0.659353   \n",
       "152      0.146087     0.107178  0.087951             0.862835   \n",
       "153      0.466319     0.466221  0.454695             0.355109   \n",
       "154      0.486911     0.801573  0.735678             0.145483   \n",
       "155      0.353203     0.371759  0.360644             0.455881   \n",
       "156      0.124796     0.103159  0.089044             0.749533   \n",
       "157      0.204407     0.116193  0.100923             0.717716   \n",
       "158      0.409605     0.884174  0.813312             0.105402   \n",
       "159      0.341058     0.371184  0.361974             0.466402   \n",
       "160      0.505831     0.700749  0.679332             0.150142   \n",
       "161      0.407114     0.400247  0.360798             0.444975   \n",
       "\n",
       "     difference entropy    mean_B    mean_G    mean_R     std_B     std_G  \\\n",
       "0              0.709940  0.313805  0.528787  0.614273  0.304604  0.615009   \n",
       "1              0.139885  0.220593  0.101461  0.053140  0.559716  0.442374   \n",
       "2              0.286056  0.298854  0.167377  0.074775  0.539028  0.447906   \n",
       "3              0.817664  0.265694  0.874486  0.759549  0.398753  0.512621   \n",
       "4              0.641177  0.170598  0.232265  0.307716  0.091011  0.135052   \n",
       "5              0.198023  0.176512  0.076325  0.152918  0.394871  0.249911   \n",
       "6              0.552105  0.231839  0.171394  0.286421  0.087317  0.000000   \n",
       "7              0.220909  0.225201  0.090681  0.143445  0.463693  0.267135   \n",
       "8              0.011066  0.058835  0.005192  0.000907  0.260821  0.170652   \n",
       "9              0.131606  0.225653  0.099282  0.044162  0.561475  0.415473   \n",
       "10             0.536012  0.124879  0.416336  0.442787  0.188226  0.449327   \n",
       "11             0.165443  0.211575  0.128075  0.035218  0.444714  0.439441   \n",
       "12             0.227441  0.196033  0.095771  0.170095  0.400597  0.273870   \n",
       "13             0.198418  0.239835  0.152197  0.131952  0.500756  0.535543   \n",
       "14             0.175686  0.223086  0.136636  0.037988  0.459744  0.455840   \n",
       "15             0.838216  0.267264  0.825950  0.716113  0.410896  0.566080   \n",
       "16             0.066333  0.081997  0.009346  0.026549  0.312601  0.146925   \n",
       "17             0.563096  0.413763  0.430469  0.534928  0.399168  0.659911   \n",
       "18             0.182666  0.167726  0.069320  0.146390  0.389611  0.240168   \n",
       "19             0.061737  0.169317  0.058562  0.028645  0.516078  0.360929   \n",
       "20             0.000000  0.069477  0.000000  0.011742  0.313507  0.153461   \n",
       "21             0.149985  0.398479  0.210074  0.071560  0.682240  0.573719   \n",
       "22             0.526277  0.652788  0.494717  0.669729  0.627026  0.731178   \n",
       "23             0.182920  0.301243  0.143018  0.089608  0.613827  0.458148   \n",
       "24             0.834893  0.149505  0.581961  0.565702  0.134371  0.340063   \n",
       "25             0.899544  0.316002  0.875428  0.738687  0.418568  0.599603   \n",
       "26             0.457843  0.414242  0.259100  0.252296  0.540759  0.500993   \n",
       "27             0.233951  0.389343  0.207296  0.041097  0.677191  0.551749   \n",
       "28             0.725498  0.742508  0.841126  0.848570  0.533037  0.695461   \n",
       "29             0.764286  0.632374  0.770294  0.750642  0.844418  0.764848   \n",
       "..                  ...       ...       ...       ...       ...       ...   \n",
       "132            0.250496  0.473873  0.236883  0.104340  0.838114  0.672522   \n",
       "133            0.646859  0.247395  0.519701  0.374571  0.354900  0.684364   \n",
       "134            0.440212  0.667015  0.338520  0.284144  0.703021  0.479525   \n",
       "135            0.069753  0.136550  0.054957  0.001686  0.398962  0.311373   \n",
       "136            0.708133  0.617055  0.985698  1.000000  0.877554  0.723824   \n",
       "137            0.676443  0.010460  0.674330  0.625163  0.059598  0.646336   \n",
       "138            0.773312  0.311437  0.756115  0.766888  0.520741  0.700660   \n",
       "139            0.095588  0.123677  0.055475  0.002988  0.341972  0.291142   \n",
       "140            0.546601  0.239183  0.517943  0.398800  0.357749  0.719585   \n",
       "141            0.213894  0.238091  0.112843  0.093472  0.549612  0.411648   \n",
       "142            0.174873  0.285335  0.145946  0.171685  0.585209  0.493819   \n",
       "143            0.118980  0.231058  0.104268  0.058751  0.603979  0.484588   \n",
       "144            0.471214  1.000000  0.481350  0.424212  1.000000  0.735300   \n",
       "145            0.209215  0.173089  0.086279  0.025816  0.325622  0.252005   \n",
       "146            0.168556  0.183661  0.062259  0.122114  0.439205  0.227237   \n",
       "147            0.530844  0.363709  0.259050  0.284365  0.446762  0.503644   \n",
       "148            0.202152  0.306789  0.160876  0.182036  0.597425  0.507315   \n",
       "149            0.481569  0.640075  0.484277  0.654803  0.626683  0.731693   \n",
       "150            0.812903  0.283739  0.874879  0.766307  0.431001  0.531658   \n",
       "151            0.161803  0.389260  0.185456  0.067530  0.806767  0.646458   \n",
       "152            0.079129  0.174678  0.089540  0.017940  0.451763  0.412236   \n",
       "153            0.541982  0.175946  0.320325  0.429330  0.192105  0.578639   \n",
       "154            0.644228  0.282172  0.545305  0.567497  0.433477  0.601541   \n",
       "155            0.442211  0.355406  0.248507  0.274784  0.440869  0.493297   \n",
       "156            0.100213  0.108491  0.074117  0.037926  0.282874  0.351699   \n",
       "157            0.112887  0.231374  0.096031  0.042288  0.606232  0.446972   \n",
       "158            0.674642  0.000000  0.714094  0.653454  0.000000  0.620931   \n",
       "159            0.446690  0.406217  0.251548  0.246625  0.540365  0.497705   \n",
       "160            0.702214  0.308823  0.517248  0.604296  0.302371  0.616105   \n",
       "161            0.384820  0.429429  0.265146  0.155253  0.662022  0.587674   \n",
       "\n",
       "        std_R  \n",
       "0    0.737568  \n",
       "1    0.309818  \n",
       "2    0.289288  \n",
       "3    0.594145  \n",
       "4    0.348236  \n",
       "5    0.468215  \n",
       "6    0.297518  \n",
       "7    0.421028  \n",
       "8    0.017506  \n",
       "9    0.177397  \n",
       "10   0.545056  \n",
       "11   0.162066  \n",
       "12   0.480086  \n",
       "13   0.451087  \n",
       "14   0.174449  \n",
       "15   0.619856  \n",
       "16   0.165443  \n",
       "17   0.783451  \n",
       "18   0.463173  \n",
       "19   0.163771  \n",
       "20   0.076231  \n",
       "21   0.182825  \n",
       "22   0.923630  \n",
       "23   0.387999  \n",
       "24   0.452158  \n",
       "25   0.630198  \n",
       "26   0.459192  \n",
       "27   0.188445  \n",
       "28   0.743058  \n",
       "29   0.864680  \n",
       "..        ...  \n",
       "132  0.406499  \n",
       "133  0.504045  \n",
       "134  0.442842  \n",
       "135  0.007778  \n",
       "136  0.827395  \n",
       "137  0.653199  \n",
       "138  0.771711  \n",
       "139  0.021512  \n",
       "140  0.548627  \n",
       "141  0.397622  \n",
       "142  0.516183  \n",
       "143  0.318007  \n",
       "144  0.614458  \n",
       "145  0.088513  \n",
       "146  0.403000  \n",
       "147  0.544987  \n",
       "148  0.525931  \n",
       "149  0.922313  \n",
       "150  0.613396  \n",
       "151  0.239361  \n",
       "152  0.115770  \n",
       "153  0.739005  \n",
       "154  0.699214  \n",
       "155  0.538858  \n",
       "156  0.183958  \n",
       "157  0.172812  \n",
       "158  0.626360  \n",
       "159  0.457404  \n",
       "160  0.740104  \n",
       "161  0.487641  \n",
       "\n",
       "[162 rows x 16 columns]"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      3\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      3\n",
       "5      3\n",
       "6      1\n",
       "7      3\n",
       "8      0\n",
       "9      0\n",
       "10     0\n",
       "11     0\n",
       "12     3\n",
       "13     0\n",
       "14     0\n",
       "15     0\n",
       "16     2\n",
       "17     1\n",
       "18     3\n",
       "19     0\n",
       "20     0\n",
       "21     0\n",
       "22     3\n",
       "23     0\n",
       "24     0\n",
       "25     0\n",
       "26     3\n",
       "27     0\n",
       "28     0\n",
       "29     0\n",
       "      ..\n",
       "132    0\n",
       "133    0\n",
       "134    3\n",
       "135    0\n",
       "136    0\n",
       "137    0\n",
       "138    0\n",
       "139    0\n",
       "140    0\n",
       "141    0\n",
       "142    2\n",
       "143    0\n",
       "144    3\n",
       "145    0\n",
       "146    3\n",
       "147    3\n",
       "148    2\n",
       "149    3\n",
       "150    0\n",
       "151    0\n",
       "152    0\n",
       "153    3\n",
       "154    0\n",
       "155    3\n",
       "156    0\n",
       "157    0\n",
       "158    0\n",
       "159    3\n",
       "160    3\n",
       "161    0\n",
       "Name: label, Length: 162, dtype: int64"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy</th>\n",
       "      <th>contrast</th>\n",
       "      <th>variance</th>\n",
       "      <th>inverse difference moment</th>\n",
       "      <th>sum average</th>\n",
       "      <th>sum variance</th>\n",
       "      <th>sum entropy</th>\n",
       "      <th>entropy</th>\n",
       "      <th>difference variance</th>\n",
       "      <th>difference entropy</th>\n",
       "      <th>mean_B</th>\n",
       "      <th>mean_G</th>\n",
       "      <th>mean_R</th>\n",
       "      <th>std_B</th>\n",
       "      <th>std_G</th>\n",
       "      <th>std_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.912701</td>\n",
       "      <td>0.103995</td>\n",
       "      <td>0.057363</td>\n",
       "      <td>0.973406</td>\n",
       "      <td>0.026295</td>\n",
       "      <td>0.057030</td>\n",
       "      <td>0.060228</td>\n",
       "      <td>0.048115</td>\n",
       "      <td>0.987541</td>\n",
       "      <td>0.040413</td>\n",
       "      <td>0.111921</td>\n",
       "      <td>0.038536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.365689</td>\n",
       "      <td>0.274969</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.802899</td>\n",
       "      <td>0.131688</td>\n",
       "      <td>0.176016</td>\n",
       "      <td>0.897297</td>\n",
       "      <td>0.083034</td>\n",
       "      <td>0.175788</td>\n",
       "      <td>0.151498</td>\n",
       "      <td>0.134484</td>\n",
       "      <td>0.679371</td>\n",
       "      <td>0.157074</td>\n",
       "      <td>0.146306</td>\n",
       "      <td>0.093407</td>\n",
       "      <td>0.057747</td>\n",
       "      <td>0.366779</td>\n",
       "      <td>0.386870</td>\n",
       "      <td>0.294857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.654991</td>\n",
       "      <td>0.023718</td>\n",
       "      <td>0.268112</td>\n",
       "      <td>0.869235</td>\n",
       "      <td>0.167608</td>\n",
       "      <td>0.268718</td>\n",
       "      <td>0.252792</td>\n",
       "      <td>0.209413</td>\n",
       "      <td>0.614776</td>\n",
       "      <td>0.177381</td>\n",
       "      <td>0.323161</td>\n",
       "      <td>0.202048</td>\n",
       "      <td>0.050047</td>\n",
       "      <td>0.568116</td>\n",
       "      <td>0.568696</td>\n",
       "      <td>0.211591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.844038</td>\n",
       "      <td>0.050417</td>\n",
       "      <td>0.205173</td>\n",
       "      <td>0.962903</td>\n",
       "      <td>0.089557</td>\n",
       "      <td>0.205483</td>\n",
       "      <td>0.101417</td>\n",
       "      <td>0.076707</td>\n",
       "      <td>0.754815</td>\n",
       "      <td>0.055386</td>\n",
       "      <td>0.230158</td>\n",
       "      <td>0.110132</td>\n",
       "      <td>0.020558</td>\n",
       "      <td>0.574570</td>\n",
       "      <td>0.489568</td>\n",
       "      <td>0.154522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.037351</td>\n",
       "      <td>0.704891</td>\n",
       "      <td>0.516688</td>\n",
       "      <td>0.168996</td>\n",
       "      <td>0.830211</td>\n",
       "      <td>0.513899</td>\n",
       "      <td>0.925518</td>\n",
       "      <td>0.883008</td>\n",
       "      <td>0.053791</td>\n",
       "      <td>0.806301</td>\n",
       "      <td>0.340693</td>\n",
       "      <td>0.834916</td>\n",
       "      <td>0.837268</td>\n",
       "      <td>0.529395</td>\n",
       "      <td>0.631379</td>\n",
       "      <td>0.728693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.009876</td>\n",
       "      <td>0.422267</td>\n",
       "      <td>0.353680</td>\n",
       "      <td>0.220852</td>\n",
       "      <td>0.934069</td>\n",
       "      <td>0.352165</td>\n",
       "      <td>0.945251</td>\n",
       "      <td>0.855314</td>\n",
       "      <td>0.097865</td>\n",
       "      <td>0.627474</td>\n",
       "      <td>0.447481</td>\n",
       "      <td>0.972793</td>\n",
       "      <td>0.842667</td>\n",
       "      <td>0.621903</td>\n",
       "      <td>0.510829</td>\n",
       "      <td>0.576742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.507251</td>\n",
       "      <td>0.153106</td>\n",
       "      <td>0.355712</td>\n",
       "      <td>0.656894</td>\n",
       "      <td>0.262457</td>\n",
       "      <td>0.355764</td>\n",
       "      <td>0.351175</td>\n",
       "      <td>0.342577</td>\n",
       "      <td>0.472403</td>\n",
       "      <td>0.427251</td>\n",
       "      <td>0.341421</td>\n",
       "      <td>0.244177</td>\n",
       "      <td>0.274670</td>\n",
       "      <td>0.435213</td>\n",
       "      <td>0.495676</td>\n",
       "      <td>0.540223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.715721</td>\n",
       "      <td>0.074629</td>\n",
       "      <td>0.287857</td>\n",
       "      <td>0.865516</td>\n",
       "      <td>0.145956</td>\n",
       "      <td>0.288212</td>\n",
       "      <td>0.218153</td>\n",
       "      <td>0.188595</td>\n",
       "      <td>0.626046</td>\n",
       "      <td>0.193984</td>\n",
       "      <td>0.350272</td>\n",
       "      <td>0.162270</td>\n",
       "      <td>0.063109</td>\n",
       "      <td>0.710056</td>\n",
       "      <td>0.531423</td>\n",
       "      <td>0.248220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.328106</td>\n",
       "      <td>0.049275</td>\n",
       "      <td>0.409954</td>\n",
       "      <td>0.619402</td>\n",
       "      <td>0.367306</td>\n",
       "      <td>0.410731</td>\n",
       "      <td>0.548129</td>\n",
       "      <td>0.485241</td>\n",
       "      <td>0.409449</td>\n",
       "      <td>0.428987</td>\n",
       "      <td>0.398853</td>\n",
       "      <td>0.325164</td>\n",
       "      <td>0.430801</td>\n",
       "      <td>0.428924</td>\n",
       "      <td>0.489261</td>\n",
       "      <td>0.685704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.971210</td>\n",
       "      <td>0.022061</td>\n",
       "      <td>0.130377</td>\n",
       "      <td>0.994994</td>\n",
       "      <td>0.033170</td>\n",
       "      <td>0.130683</td>\n",
       "      <td>0.021014</td>\n",
       "      <td>0.015535</td>\n",
       "      <td>0.821306</td>\n",
       "      <td>0.011573</td>\n",
       "      <td>0.125511</td>\n",
       "      <td>0.038168</td>\n",
       "      <td>0.021424</td>\n",
       "      <td>0.476160</td>\n",
       "      <td>0.352179</td>\n",
       "      <td>0.169903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.673622</td>\n",
       "      <td>0.236813</td>\n",
       "      <td>0.206139</td>\n",
       "      <td>0.811437</td>\n",
       "      <td>0.139913</td>\n",
       "      <td>0.205368</td>\n",
       "      <td>0.233830</td>\n",
       "      <td>0.216615</td>\n",
       "      <td>0.573074</td>\n",
       "      <td>0.271532</td>\n",
       "      <td>0.141284</td>\n",
       "      <td>0.169710</td>\n",
       "      <td>0.074488</td>\n",
       "      <td>0.268916</td>\n",
       "      <td>0.480453</td>\n",
       "      <td>0.260380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.880415</td>\n",
       "      <td>0.051604</td>\n",
       "      <td>0.117267</td>\n",
       "      <td>0.942785</td>\n",
       "      <td>0.054652</td>\n",
       "      <td>0.117372</td>\n",
       "      <td>0.087996</td>\n",
       "      <td>0.076518</td>\n",
       "      <td>0.742533</td>\n",
       "      <td>0.085906</td>\n",
       "      <td>0.148910</td>\n",
       "      <td>0.057173</td>\n",
       "      <td>0.045037</td>\n",
       "      <td>0.411167</td>\n",
       "      <td>0.300986</td>\n",
       "      <td>0.174222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.801684</td>\n",
       "      <td>0.024262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.915328</td>\n",
       "      <td>0.026728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132504</td>\n",
       "      <td>0.113929</td>\n",
       "      <td>0.760796</td>\n",
       "      <td>0.122401</td>\n",
       "      <td>0.086998</td>\n",
       "      <td>0.039078</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.192364</td>\n",
       "      <td>0.138401</td>\n",
       "      <td>0.026030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.811920</td>\n",
       "      <td>0.410706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.901127</td>\n",
       "      <td>0.407058</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.970119</td>\n",
       "      <td>0.728078</td>\n",
       "      <td>0.891336</td>\n",
       "      <td>0.855435</td>\n",
       "      <td>0.772312</td>\n",
       "      <td>0.459785</td>\n",
       "      <td>0.682910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.843534</td>\n",
       "      <td>0.069507</td>\n",
       "      <td>0.259898</td>\n",
       "      <td>0.921249</td>\n",
       "      <td>0.099657</td>\n",
       "      <td>0.260220</td>\n",
       "      <td>0.122099</td>\n",
       "      <td>0.107735</td>\n",
       "      <td>0.710995</td>\n",
       "      <td>0.124364</td>\n",
       "      <td>0.240255</td>\n",
       "      <td>0.108289</td>\n",
       "      <td>0.057490</td>\n",
       "      <td>0.613340</td>\n",
       "      <td>0.486935</td>\n",
       "      <td>0.315547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.140590</td>\n",
       "      <td>0.316887</td>\n",
       "      <td>0.334944</td>\n",
       "      <td>0.444251</td>\n",
       "      <td>0.499718</td>\n",
       "      <td>0.333999</td>\n",
       "      <td>0.712943</td>\n",
       "      <td>0.642178</td>\n",
       "      <td>0.214201</td>\n",
       "      <td>0.548127</td>\n",
       "      <td>0.127916</td>\n",
       "      <td>0.502639</td>\n",
       "      <td>0.532559</td>\n",
       "      <td>0.197047</td>\n",
       "      <td>0.506081</td>\n",
       "      <td>0.593324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.032007</td>\n",
       "      <td>0.147267</td>\n",
       "      <td>0.970536</td>\n",
       "      <td>0.051183</td>\n",
       "      <td>0.147553</td>\n",
       "      <td>0.064473</td>\n",
       "      <td>0.052746</td>\n",
       "      <td>0.782980</td>\n",
       "      <td>0.050377</td>\n",
       "      <td>0.165452</td>\n",
       "      <td>0.060708</td>\n",
       "      <td>0.020644</td>\n",
       "      <td>0.521208</td>\n",
       "      <td>0.386048</td>\n",
       "      <td>0.144966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.848981</td>\n",
       "      <td>0.071954</td>\n",
       "      <td>0.172494</td>\n",
       "      <td>0.923166</td>\n",
       "      <td>0.078513</td>\n",
       "      <td>0.172605</td>\n",
       "      <td>0.111210</td>\n",
       "      <td>0.097702</td>\n",
       "      <td>0.719215</td>\n",
       "      <td>0.113572</td>\n",
       "      <td>0.198191</td>\n",
       "      <td>0.069739</td>\n",
       "      <td>0.085985</td>\n",
       "      <td>0.495080</td>\n",
       "      <td>0.312069</td>\n",
       "      <td>0.325535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.954383</td>\n",
       "      <td>0.054051</td>\n",
       "      <td>0.066594</td>\n",
       "      <td>0.986426</td>\n",
       "      <td>0.021105</td>\n",
       "      <td>0.066571</td>\n",
       "      <td>0.033350</td>\n",
       "      <td>0.026036</td>\n",
       "      <td>0.817499</td>\n",
       "      <td>0.023627</td>\n",
       "      <td>0.112506</td>\n",
       "      <td>0.026828</td>\n",
       "      <td>0.009726</td>\n",
       "      <td>0.414651</td>\n",
       "      <td>0.261029</td>\n",
       "      <td>0.081890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.587120</td>\n",
       "      <td>0.191977</td>\n",
       "      <td>0.251218</td>\n",
       "      <td>0.780205</td>\n",
       "      <td>0.180097</td>\n",
       "      <td>0.250809</td>\n",
       "      <td>0.302527</td>\n",
       "      <td>0.269404</td>\n",
       "      <td>0.525626</td>\n",
       "      <td>0.294182</td>\n",
       "      <td>0.265157</td>\n",
       "      <td>0.199069</td>\n",
       "      <td>0.114448</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.470486</td>\n",
       "      <td>0.359641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.217640</td>\n",
       "      <td>0.240444</td>\n",
       "      <td>0.485385</td>\n",
       "      <td>0.472427</td>\n",
       "      <td>0.491405</td>\n",
       "      <td>0.485222</td>\n",
       "      <td>0.656693</td>\n",
       "      <td>0.601077</td>\n",
       "      <td>0.216915</td>\n",
       "      <td>0.567732</td>\n",
       "      <td>0.249824</td>\n",
       "      <td>0.529215</td>\n",
       "      <td>0.411167</td>\n",
       "      <td>0.356654</td>\n",
       "      <td>0.709945</td>\n",
       "      <td>0.542708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.260285</td>\n",
       "      <td>0.006904</td>\n",
       "      <td>0.391357</td>\n",
       "      <td>0.582404</td>\n",
       "      <td>0.386956</td>\n",
       "      <td>0.392338</td>\n",
       "      <td>0.630229</td>\n",
       "      <td>0.550682</td>\n",
       "      <td>0.364547</td>\n",
       "      <td>0.446804</td>\n",
       "      <td>0.422132</td>\n",
       "      <td>0.344042</td>\n",
       "      <td>0.448278</td>\n",
       "      <td>0.419722</td>\n",
       "      <td>0.473452</td>\n",
       "      <td>0.672721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.171980</td>\n",
       "      <td>0.197873</td>\n",
       "      <td>0.387828</td>\n",
       "      <td>0.340331</td>\n",
       "      <td>0.477394</td>\n",
       "      <td>0.387692</td>\n",
       "      <td>0.694496</td>\n",
       "      <td>0.672813</td>\n",
       "      <td>0.159429</td>\n",
       "      <td>0.697615</td>\n",
       "      <td>0.929689</td>\n",
       "      <td>0.522162</td>\n",
       "      <td>0.216727</td>\n",
       "      <td>0.777439</td>\n",
       "      <td>0.618846</td>\n",
       "      <td>0.340381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.896178</td>\n",
       "      <td>0.063057</td>\n",
       "      <td>0.135481</td>\n",
       "      <td>0.969489</td>\n",
       "      <td>0.052887</td>\n",
       "      <td>0.135560</td>\n",
       "      <td>0.076344</td>\n",
       "      <td>0.059401</td>\n",
       "      <td>0.869805</td>\n",
       "      <td>0.047101</td>\n",
       "      <td>0.147634</td>\n",
       "      <td>0.064569</td>\n",
       "      <td>0.021641</td>\n",
       "      <td>0.444405</td>\n",
       "      <td>0.372508</td>\n",
       "      <td>0.142865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.293539</td>\n",
       "      <td>0.250586</td>\n",
       "      <td>0.745285</td>\n",
       "      <td>0.589536</td>\n",
       "      <td>0.498973</td>\n",
       "      <td>0.745647</td>\n",
       "      <td>0.599466</td>\n",
       "      <td>0.531970</td>\n",
       "      <td>0.305995</td>\n",
       "      <td>0.482356</td>\n",
       "      <td>0.257551</td>\n",
       "      <td>0.484984</td>\n",
       "      <td>0.541190</td>\n",
       "      <td>0.579617</td>\n",
       "      <td>0.803037</td>\n",
       "      <td>0.856679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.031995</td>\n",
       "      <td>0.874942</td>\n",
       "      <td>0.399836</td>\n",
       "      <td>0.139135</td>\n",
       "      <td>0.804057</td>\n",
       "      <td>0.395797</td>\n",
       "      <td>0.906055</td>\n",
       "      <td>0.891244</td>\n",
       "      <td>0.041939</td>\n",
       "      <td>0.852812</td>\n",
       "      <td>0.290984</td>\n",
       "      <td>0.847244</td>\n",
       "      <td>0.730920</td>\n",
       "      <td>0.426295</td>\n",
       "      <td>0.570417</td>\n",
       "      <td>0.621260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.899593</td>\n",
       "      <td>0.053779</td>\n",
       "      <td>0.158514</td>\n",
       "      <td>0.937548</td>\n",
       "      <td>0.058574</td>\n",
       "      <td>0.158699</td>\n",
       "      <td>0.082211</td>\n",
       "      <td>0.075743</td>\n",
       "      <td>0.747268</td>\n",
       "      <td>0.098770</td>\n",
       "      <td>0.142637</td>\n",
       "      <td>0.054676</td>\n",
       "      <td>0.066041</td>\n",
       "      <td>0.420517</td>\n",
       "      <td>0.324368</td>\n",
       "      <td>0.275003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.758134</td>\n",
       "      <td>0.109442</td>\n",
       "      <td>0.189716</td>\n",
       "      <td>0.897108</td>\n",
       "      <td>0.109560</td>\n",
       "      <td>0.189649</td>\n",
       "      <td>0.172731</td>\n",
       "      <td>0.147778</td>\n",
       "      <td>0.661098</td>\n",
       "      <td>0.153561</td>\n",
       "      <td>0.233146</td>\n",
       "      <td>0.117561</td>\n",
       "      <td>0.071364</td>\n",
       "      <td>0.483006</td>\n",
       "      <td>0.396386</td>\n",
       "      <td>0.262710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.163818</td>\n",
       "      <td>0.135848</td>\n",
       "      <td>0.718995</td>\n",
       "      <td>0.542462</td>\n",
       "      <td>0.671649</td>\n",
       "      <td>0.719964</td>\n",
       "      <td>0.716340</td>\n",
       "      <td>0.624908</td>\n",
       "      <td>0.261304</td>\n",
       "      <td>0.490682</td>\n",
       "      <td>0.860006</td>\n",
       "      <td>0.623702</td>\n",
       "      <td>0.665884</td>\n",
       "      <td>0.776326</td>\n",
       "      <td>0.741387</td>\n",
       "      <td>0.779577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.038905</td>\n",
       "      <td>0.586514</td>\n",
       "      <td>0.503882</td>\n",
       "      <td>0.164647</td>\n",
       "      <td>0.816463</td>\n",
       "      <td>0.501751</td>\n",
       "      <td>0.919728</td>\n",
       "      <td>0.880194</td>\n",
       "      <td>0.051927</td>\n",
       "      <td>0.808667</td>\n",
       "      <td>0.311832</td>\n",
       "      <td>0.825653</td>\n",
       "      <td>0.818722</td>\n",
       "      <td>0.493654</td>\n",
       "      <td>0.626898</td>\n",
       "      <td>0.716824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.920701</td>\n",
       "      <td>0.040314</td>\n",
       "      <td>0.092649</td>\n",
       "      <td>0.970882</td>\n",
       "      <td>0.035811</td>\n",
       "      <td>0.092764</td>\n",
       "      <td>0.055561</td>\n",
       "      <td>0.046131</td>\n",
       "      <td>0.782385</td>\n",
       "      <td>0.050987</td>\n",
       "      <td>0.139915</td>\n",
       "      <td>0.044773</td>\n",
       "      <td>0.011418</td>\n",
       "      <td>0.448850</td>\n",
       "      <td>0.308036</td>\n",
       "      <td>0.097947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.726078</td>\n",
       "      <td>0.115909</td>\n",
       "      <td>0.300091</td>\n",
       "      <td>0.884202</td>\n",
       "      <td>0.149577</td>\n",
       "      <td>0.300234</td>\n",
       "      <td>0.202148</td>\n",
       "      <td>0.172830</td>\n",
       "      <td>0.649604</td>\n",
       "      <td>0.174849</td>\n",
       "      <td>0.322473</td>\n",
       "      <td>0.177353</td>\n",
       "      <td>0.046490</td>\n",
       "      <td>0.668801</td>\n",
       "      <td>0.601540</td>\n",
       "      <td>0.225496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.807777</td>\n",
       "      <td>0.116304</td>\n",
       "      <td>0.218959</td>\n",
       "      <td>0.917608</td>\n",
       "      <td>0.099300</td>\n",
       "      <td>0.218917</td>\n",
       "      <td>0.146716</td>\n",
       "      <td>0.124237</td>\n",
       "      <td>0.703470</td>\n",
       "      <td>0.126164</td>\n",
       "      <td>0.241203</td>\n",
       "      <td>0.119873</td>\n",
       "      <td>0.028485</td>\n",
       "      <td>0.595669</td>\n",
       "      <td>0.503300</td>\n",
       "      <td>0.167518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.749143</td>\n",
       "      <td>0.094078</td>\n",
       "      <td>0.381677</td>\n",
       "      <td>0.889109</td>\n",
       "      <td>0.162363</td>\n",
       "      <td>0.382130</td>\n",
       "      <td>0.186939</td>\n",
       "      <td>0.160144</td>\n",
       "      <td>0.671443</td>\n",
       "      <td>0.160701</td>\n",
       "      <td>0.230659</td>\n",
       "      <td>0.140920</td>\n",
       "      <td>0.199346</td>\n",
       "      <td>0.511220</td>\n",
       "      <td>0.489412</td>\n",
       "      <td>0.576189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.159620</td>\n",
       "      <td>0.318122</td>\n",
       "      <td>0.700541</td>\n",
       "      <td>0.396494</td>\n",
       "      <td>0.681425</td>\n",
       "      <td>0.700410</td>\n",
       "      <td>0.716595</td>\n",
       "      <td>0.662927</td>\n",
       "      <td>0.179710</td>\n",
       "      <td>0.615511</td>\n",
       "      <td>0.617823</td>\n",
       "      <td>0.688062</td>\n",
       "      <td>0.603715</td>\n",
       "      <td>0.690891</td>\n",
       "      <td>0.809813</td>\n",
       "      <td>0.692345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.026085</td>\n",
       "      <td>0.312549</td>\n",
       "      <td>0.024595</td>\n",
       "      <td>0.414045</td>\n",
       "      <td>0.321003</td>\n",
       "      <td>0.022976</td>\n",
       "      <td>0.828106</td>\n",
       "      <td>0.741574</td>\n",
       "      <td>0.183148</td>\n",
       "      <td>0.573303</td>\n",
       "      <td>0.382859</td>\n",
       "      <td>0.265135</td>\n",
       "      <td>0.416812</td>\n",
       "      <td>0.173793</td>\n",
       "      <td>0.031885</td>\n",
       "      <td>0.333213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.119864</td>\n",
       "      <td>0.390216</td>\n",
       "      <td>0.525686</td>\n",
       "      <td>0.407587</td>\n",
       "      <td>0.664672</td>\n",
       "      <td>0.524744</td>\n",
       "      <td>0.749218</td>\n",
       "      <td>0.676693</td>\n",
       "      <td>0.205149</td>\n",
       "      <td>0.566305</td>\n",
       "      <td>0.618787</td>\n",
       "      <td>0.681682</td>\n",
       "      <td>0.561207</td>\n",
       "      <td>0.671038</td>\n",
       "      <td>0.686257</td>\n",
       "      <td>0.585089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.267379</td>\n",
       "      <td>0.604305</td>\n",
       "      <td>0.411300</td>\n",
       "      <td>0.448197</td>\n",
       "      <td>0.412848</td>\n",
       "      <td>0.408858</td>\n",
       "      <td>0.563737</td>\n",
       "      <td>0.556675</td>\n",
       "      <td>0.214612</td>\n",
       "      <td>0.661302</td>\n",
       "      <td>0.244477</td>\n",
       "      <td>0.476542</td>\n",
       "      <td>0.266252</td>\n",
       "      <td>0.389821</td>\n",
       "      <td>0.677589</td>\n",
       "      <td>0.456193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.893015</td>\n",
       "      <td>0.105256</td>\n",
       "      <td>0.098113</td>\n",
       "      <td>0.957846</td>\n",
       "      <td>0.040973</td>\n",
       "      <td>0.097863</td>\n",
       "      <td>0.077010</td>\n",
       "      <td>0.063731</td>\n",
       "      <td>0.853903</td>\n",
       "      <td>0.068592</td>\n",
       "      <td>0.145840</td>\n",
       "      <td>0.054063</td>\n",
       "      <td>0.005795</td>\n",
       "      <td>0.464688</td>\n",
       "      <td>0.339510</td>\n",
       "      <td>0.040803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.727275</td>\n",
       "      <td>0.164323</td>\n",
       "      <td>0.273176</td>\n",
       "      <td>0.869686</td>\n",
       "      <td>0.143265</td>\n",
       "      <td>0.272977</td>\n",
       "      <td>0.204996</td>\n",
       "      <td>0.177072</td>\n",
       "      <td>0.746733</td>\n",
       "      <td>0.177171</td>\n",
       "      <td>0.218874</td>\n",
       "      <td>0.148886</td>\n",
       "      <td>0.117074</td>\n",
       "      <td>0.421086</td>\n",
       "      <td>0.477927</td>\n",
       "      <td>0.403525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       energy  contrast  variance  inverse difference moment  sum average  \\\n",
       "162  0.912701  0.103995  0.057363                   0.973406     0.026295   \n",
       "163  0.802899  0.131688  0.176016                   0.897297     0.083034   \n",
       "164  0.654991  0.023718  0.268112                   0.869235     0.167608   \n",
       "165  0.844038  0.050417  0.205173                   0.962903     0.089557   \n",
       "166  0.037351  0.704891  0.516688                   0.168996     0.830211   \n",
       "167  0.009876  0.422267  0.353680                   0.220852     0.934069   \n",
       "168  0.507251  0.153106  0.355712                   0.656894     0.262457   \n",
       "169  0.715721  0.074629  0.287857                   0.865516     0.145956   \n",
       "170  0.328106  0.049275  0.409954                   0.619402     0.367306   \n",
       "171  0.971210  0.022061  0.130377                   0.994994     0.033170   \n",
       "172  0.673622  0.236813  0.206139                   0.811437     0.139913   \n",
       "173  0.880415  0.051604  0.117267                   0.942785     0.054652   \n",
       "174  0.801684  0.024262  0.000000                   0.915328     0.026728   \n",
       "175  0.000000  0.811920  0.410706                   0.000000     0.901127   \n",
       "176  0.843534  0.069507  0.259898                   0.921249     0.099657   \n",
       "177  0.140590  0.316887  0.334944                   0.444251     0.499718   \n",
       "178  0.915000  0.032007  0.147267                   0.970536     0.051183   \n",
       "179  0.848981  0.071954  0.172494                   0.923166     0.078513   \n",
       "180  0.954383  0.054051  0.066594                   0.986426     0.021105   \n",
       "181  0.587120  0.191977  0.251218                   0.780205     0.180097   \n",
       "182  0.217640  0.240444  0.485385                   0.472427     0.491405   \n",
       "183  0.260285  0.006904  0.391357                   0.582404     0.386956   \n",
       "184  0.171980  0.197873  0.387828                   0.340331     0.477394   \n",
       "185  0.896178  0.063057  0.135481                   0.969489     0.052887   \n",
       "186  0.293539  0.250586  0.745285                   0.589536     0.498973   \n",
       "187  0.031995  0.874942  0.399836                   0.139135     0.804057   \n",
       "188  0.899593  0.053779  0.158514                   0.937548     0.058574   \n",
       "189  0.758134  0.109442  0.189716                   0.897108     0.109560   \n",
       "190  0.163818  0.135848  0.718995                   0.542462     0.671649   \n",
       "191  0.038905  0.586514  0.503882                   0.164647     0.816463   \n",
       "192  0.920701  0.040314  0.092649                   0.970882     0.035811   \n",
       "193  0.726078  0.115909  0.300091                   0.884202     0.149577   \n",
       "194  0.807777  0.116304  0.218959                   0.917608     0.099300   \n",
       "195  0.749143  0.094078  0.381677                   0.889109     0.162363   \n",
       "196  0.159620  0.318122  0.700541                   0.396494     0.681425   \n",
       "197  0.026085  0.312549  0.024595                   0.414045     0.321003   \n",
       "198  0.119864  0.390216  0.525686                   0.407587     0.664672   \n",
       "199  0.267379  0.604305  0.411300                   0.448197     0.412848   \n",
       "200  0.893015  0.105256  0.098113                   0.957846     0.040973   \n",
       "201  0.727275  0.164323  0.273176                   0.869686     0.143265   \n",
       "\n",
       "     sum variance  sum entropy   entropy  difference variance  \\\n",
       "162      0.057030     0.060228  0.048115             0.987541   \n",
       "163      0.175788     0.151498  0.134484             0.679371   \n",
       "164      0.268718     0.252792  0.209413             0.614776   \n",
       "165      0.205483     0.101417  0.076707             0.754815   \n",
       "166      0.513899     0.925518  0.883008             0.053791   \n",
       "167      0.352165     0.945251  0.855314             0.097865   \n",
       "168      0.355764     0.351175  0.342577             0.472403   \n",
       "169      0.288212     0.218153  0.188595             0.626046   \n",
       "170      0.410731     0.548129  0.485241             0.409449   \n",
       "171      0.130683     0.021014  0.015535             0.821306   \n",
       "172      0.205368     0.233830  0.216615             0.573074   \n",
       "173      0.117372     0.087996  0.076518             0.742533   \n",
       "174      0.000000     0.132504  0.113929             0.760796   \n",
       "175      0.407058     1.000000  1.000000             0.000000   \n",
       "176      0.260220     0.122099  0.107735             0.710995   \n",
       "177      0.333999     0.712943  0.642178             0.214201   \n",
       "178      0.147553     0.064473  0.052746             0.782980   \n",
       "179      0.172605     0.111210  0.097702             0.719215   \n",
       "180      0.066571     0.033350  0.026036             0.817499   \n",
       "181      0.250809     0.302527  0.269404             0.525626   \n",
       "182      0.485222     0.656693  0.601077             0.216915   \n",
       "183      0.392338     0.630229  0.550682             0.364547   \n",
       "184      0.387692     0.694496  0.672813             0.159429   \n",
       "185      0.135560     0.076344  0.059401             0.869805   \n",
       "186      0.745647     0.599466  0.531970             0.305995   \n",
       "187      0.395797     0.906055  0.891244             0.041939   \n",
       "188      0.158699     0.082211  0.075743             0.747268   \n",
       "189      0.189649     0.172731  0.147778             0.661098   \n",
       "190      0.719964     0.716340  0.624908             0.261304   \n",
       "191      0.501751     0.919728  0.880194             0.051927   \n",
       "192      0.092764     0.055561  0.046131             0.782385   \n",
       "193      0.300234     0.202148  0.172830             0.649604   \n",
       "194      0.218917     0.146716  0.124237             0.703470   \n",
       "195      0.382130     0.186939  0.160144             0.671443   \n",
       "196      0.700410     0.716595  0.662927             0.179710   \n",
       "197      0.022976     0.828106  0.741574             0.183148   \n",
       "198      0.524744     0.749218  0.676693             0.205149   \n",
       "199      0.408858     0.563737  0.556675             0.214612   \n",
       "200      0.097863     0.077010  0.063731             0.853903   \n",
       "201      0.272977     0.204996  0.177072             0.746733   \n",
       "\n",
       "     difference entropy    mean_B    mean_G    mean_R     std_B     std_G  \\\n",
       "162            0.040413  0.111921  0.038536  0.000000  0.365689  0.274969   \n",
       "163            0.157074  0.146306  0.093407  0.057747  0.366779  0.386870   \n",
       "164            0.177381  0.323161  0.202048  0.050047  0.568116  0.568696   \n",
       "165            0.055386  0.230158  0.110132  0.020558  0.574570  0.489568   \n",
       "166            0.806301  0.340693  0.834916  0.837268  0.529395  0.631379   \n",
       "167            0.627474  0.447481  0.972793  0.842667  0.621903  0.510829   \n",
       "168            0.427251  0.341421  0.244177  0.274670  0.435213  0.495676   \n",
       "169            0.193984  0.350272  0.162270  0.063109  0.710056  0.531423   \n",
       "170            0.428987  0.398853  0.325164  0.430801  0.428924  0.489261   \n",
       "171            0.011573  0.125511  0.038168  0.021424  0.476160  0.352179   \n",
       "172            0.271532  0.141284  0.169710  0.074488  0.268916  0.480453   \n",
       "173            0.085906  0.148910  0.057173  0.045037  0.411167  0.300986   \n",
       "174            0.122401  0.086998  0.039078  0.006200  0.192364  0.138401   \n",
       "175            0.970119  0.728078  0.891336  0.855435  0.772312  0.459785   \n",
       "176            0.124364  0.240255  0.108289  0.057490  0.613340  0.486935   \n",
       "177            0.548127  0.127916  0.502639  0.532559  0.197047  0.506081   \n",
       "178            0.050377  0.165452  0.060708  0.020644  0.521208  0.386048   \n",
       "179            0.113572  0.198191  0.069739  0.085985  0.495080  0.312069   \n",
       "180            0.023627  0.112506  0.026828  0.009726  0.414651  0.261029   \n",
       "181            0.294182  0.265157  0.199069  0.114448  0.417356  0.470486   \n",
       "182            0.567732  0.249824  0.529215  0.411167  0.356654  0.709945   \n",
       "183            0.446804  0.422132  0.344042  0.448278  0.419722  0.473452   \n",
       "184            0.697615  0.929689  0.522162  0.216727  0.777439  0.618846   \n",
       "185            0.047101  0.147634  0.064569  0.021641  0.444405  0.372508   \n",
       "186            0.482356  0.257551  0.484984  0.541190  0.579617  0.803037   \n",
       "187            0.852812  0.290984  0.847244  0.730920  0.426295  0.570417   \n",
       "188            0.098770  0.142637  0.054676  0.066041  0.420517  0.324368   \n",
       "189            0.153561  0.233146  0.117561  0.071364  0.483006  0.396386   \n",
       "190            0.490682  0.860006  0.623702  0.665884  0.776326  0.741387   \n",
       "191            0.808667  0.311832  0.825653  0.818722  0.493654  0.626898   \n",
       "192            0.050987  0.139915  0.044773  0.011418  0.448850  0.308036   \n",
       "193            0.174849  0.322473  0.177353  0.046490  0.668801  0.601540   \n",
       "194            0.126164  0.241203  0.119873  0.028485  0.595669  0.503300   \n",
       "195            0.160701  0.230659  0.140920  0.199346  0.511220  0.489412   \n",
       "196            0.615511  0.617823  0.688062  0.603715  0.690891  0.809813   \n",
       "197            0.573303  0.382859  0.265135  0.416812  0.173793  0.031885   \n",
       "198            0.566305  0.618787  0.681682  0.561207  0.671038  0.686257   \n",
       "199            0.661302  0.244477  0.476542  0.266252  0.389821  0.677589   \n",
       "200            0.068592  0.145840  0.054063  0.005795  0.464688  0.339510   \n",
       "201            0.177171  0.218874  0.148886  0.117074  0.421086  0.477927   \n",
       "\n",
       "        std_R  \n",
       "162  0.000000  \n",
       "163  0.294857  \n",
       "164  0.211591  \n",
       "165  0.154522  \n",
       "166  0.728693  \n",
       "167  0.576742  \n",
       "168  0.540223  \n",
       "169  0.248220  \n",
       "170  0.685704  \n",
       "171  0.169903  \n",
       "172  0.260380  \n",
       "173  0.174222  \n",
       "174  0.026030  \n",
       "175  0.682910  \n",
       "176  0.315547  \n",
       "177  0.593324  \n",
       "178  0.144966  \n",
       "179  0.325535  \n",
       "180  0.081890  \n",
       "181  0.359641  \n",
       "182  0.542708  \n",
       "183  0.672721  \n",
       "184  0.340381  \n",
       "185  0.142865  \n",
       "186  0.856679  \n",
       "187  0.621260  \n",
       "188  0.275003  \n",
       "189  0.262710  \n",
       "190  0.779577  \n",
       "191  0.716824  \n",
       "192  0.097947  \n",
       "193  0.225496  \n",
       "194  0.167518  \n",
       "195  0.576189  \n",
       "196  0.692345  \n",
       "197  0.333213  \n",
       "198  0.585089  \n",
       "199  0.456193  \n",
       "200  0.040803  \n",
       "201  0.403525  "
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162    0\n",
       "163    0\n",
       "164    0\n",
       "165    0\n",
       "166    0\n",
       "167    0\n",
       "168    3\n",
       "169    0\n",
       "170    3\n",
       "171    0\n",
       "172    0\n",
       "173    0\n",
       "174    0\n",
       "175    0\n",
       "176    0\n",
       "177    0\n",
       "178    0\n",
       "179    0\n",
       "180    0\n",
       "181    0\n",
       "182    0\n",
       "183    3\n",
       "184    3\n",
       "185    0\n",
       "186    0\n",
       "187    0\n",
       "188    0\n",
       "189    0\n",
       "190    2\n",
       "191    0\n",
       "192    0\n",
       "193    0\n",
       "194    0\n",
       "195    2\n",
       "196    0\n",
       "197    1\n",
       "198    0\n",
       "199    0\n",
       "200    0\n",
       "201    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 3 models are chosen by 5-fold cross-validation and that models are Support Vector Machine, Random Forerst Classifier and Adaboost Classifier.\n",
    "\n",
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svc = svm.SVC(kernel = 'linear',C=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svc.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_random = RandomForestClassifier(n_estimators = 100,criterion = 'entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_random.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = tree.DecisionTreeClassifier(min_samples_split = 10)\n",
    "model_ada = AdaBoostClassifier(base_estimator = dtree, n_estimators = 5000, learning_rate = 0.005, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=10,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=0.005, n_estimators=5000, random_state=42)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ada.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction using SVM , Random Forest Classifier and AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svc = model_svc.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_random = model_random.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ada = model_ada.predict(test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Ensemble prediction using Maximum Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(test_sample)):\n",
    "    final_pred = np.append(final_pred,stats.mode([pred_svc[i],pred_random[i],pred_ada[i]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 3., 0., 3., 0., 3., 0., 3., 0., 3., 0., 3., 3., 3., 0., 3., 3.,\n",
       "       3., 0., 3., 0., 3., 0., 3., 0., 2., 0., 3., 0., 3., 0., 3., 0., 3.,\n",
       "       0., 3., 0., 3., 0., 3., 0., 3., 3., 3., 3., 3., 0., 3., 0., 3., 0.,\n",
       "       3., 0., 3., 0., 3., 3., 3., 0., 3., 0., 3., 0., 3., 0., 3., 2., 3.,\n",
       "       0., 3., 1., 3., 0., 3., 0., 3., 0., 3., 0., 3.])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 2.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 1.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 3.0]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = final_pred.tolist()\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = prediction[0:len(prediction)-1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 2.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, item in enumerate(final):\n",
    "    final[index] = float(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = confusion_matrix(test_label,final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33,  0,  0,  0],\n",
       "       [ 0,  1,  0,  0],\n",
       "       [ 0,  0,  1,  1],\n",
       "       [ 0,  0,  0,  4]])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label,final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.975"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 97.50\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is {:.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(test_label,final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        33\n",
      "          1       1.00      1.00      1.00         1\n",
      "          2       1.00      0.50      0.67         2\n",
      "          3       0.80      1.00      0.89         4\n",
      "\n",
      "avg / total       0.98      0.97      0.97        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
